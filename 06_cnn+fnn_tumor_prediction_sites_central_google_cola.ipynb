{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06-cnn+fnn-tumor_prediction-sites-central-google-cola.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "conda_tensorflow_p36",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stomioka/phuse-tumor-ml/blob/master/06_cnn%2Bfnn_tumor_prediction_sites_central_google_cola.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eNny0V6f0qdU"
      },
      "source": [
        "# Response criteria prediction for tumor with CNN\n",
        "\n",
        "Sam Tomioka<br>\n",
        "2019-10-13\n",
        "\n",
        "Same data used in [notebook3](03-tumor_prediction-sites-central.ipynb) will be used here. \n",
        "\n",
        "- Model based on `central`+`site` with 85% of data from each. Test on remaining `central` assessments, Test on remaining `site` assessments independently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vvowRGjB0qdX",
        "outputId": "90e856e3-212c-4263-ae55-20270202131a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "#!pip install git+git://github.com/andirs/impyte.git\n",
        "#!pip install xgboost \n",
        "\n",
        "!git clone https://github.com/stomioka/phuse-tumor-ml.git\n",
        "!pip install git+git://github.com/andirs/impyte.git\n",
        "!mv phuse-tumor-ml phuse_tumor_ml"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'phuse-tumor-ml'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 115 (delta 55), reused 80 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (115/115), 3.43 MiB | 24.38 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n",
            "Collecting git+git://github.com/andirs/impyte.git\n",
            "  Cloning git://github.com/andirs/impyte.git to /tmp/pip-req-build-tb_xeqx4\n",
            "  Running command git clone -q git://github.com/andirs/impyte.git /tmp/pip-req-build-tb_xeqx4\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from impyte==0.1.0) (0.21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from impyte==0.1.0) (0.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from impyte==0.1.0) (1.16.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from impyte==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (from impyte==0.1.0) (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->impyte==0.1.0) (0.14.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->impyte==0.1.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->impyte==0.1.0) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->impyte==0.1.0) (1.12.0)\n",
            "Building wheels for collected packages: impyte\n",
            "  Building wheel for impyte (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for impyte: filename=impyte-0.1.0-cp36-none-any.whl size=21388 sha256=6ba00fd8c6af20d2ae66851e791e241289eabbf02a9db280d1c202c38081934e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v1nxdyjj/wheels/65/16/30/1a24d053bf050146af36c12fdca5e3f2362d892226909931e4\n",
            "Successfully built impyte\n",
            "Installing collected packages: impyte\n",
            "Successfully installed impyte-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sFHjN5wH0qdb",
        "outputId": "758586ec-acc6-493b-d5dc-1a02aa28d322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import os\n",
        "os.chdir('phuse_tumor_ml/notebooks')\n",
        "from lib.myutil import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import *\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.train import *\n",
        "print('tensorflow version: {}'.format(tf.__version__))\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score,roc_curve, auc\n",
        "print('sklearn version: {}'.format(sklearn.__version__))\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "#tf.keras.backend.clear_session() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 1.15.0-rc3\n",
            "sklearn version: 0.21.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bW6oQ5SN0qdj",
        "colab": {}
      },
      "source": [
        "central, site=load_data()\n",
        "\n",
        "tr_x, tr_y, ts_x, ts_y, ts_x2, ts_y2 = generate_tr_ts(df1=central, df2=site, m=3, method=None, h=3000, seed=2019)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hzaj0m-n0qdo",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder = LabelBinarizer()\n",
        "tr_y = encoder.fit_transform(tr_y)\n",
        "ts_y = encoder.fit_transform(ts_y)\n",
        "ts_y2 = encoder.fit_transform(ts_y2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7xnzgFYj0qd0",
        "outputId": "e88362de-98bb-401c-b949-563126ad1a9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tr_x.shape, tr_y.shape\n",
        "x_train, x_vl, y_train, y_vl = train_test_split(tr_x, tr_y, test_size=0.20, random_state=2019)\n",
        "print()\n",
        "x_train=np.array(x_train).reshape(x_train.shape[0],7,1)\n",
        "#y_train=np.array(y_train).reshape(y_train.shape[0],5,1)\n",
        "x_vl=np.array(x_vl).reshape(x_vl.shape[0],7,1)\n",
        "#y_vl=np.array(y_vl).reshape(y_vl.shape[0],5,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WnTEmXDl0qd4",
        "outputId": "d3dfd663-83d2-463d-ffc9-d1a9ee396cf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "tf.keras.backend.clear_session() \n",
        "i = Input(shape=(7,1),name='recest')\n",
        "x = Conv1D(64, 3, activation='relu', name='1Dconv_1')(i)\n",
        "x = Conv1D(64, 3, activation='relu', name='1Dconv_2')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='dense_1')(x)\n",
        "x1 = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='dense_2')(i)\n",
        "x2 = Add()([x, x1])\n",
        "x2 = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='dense_3')(x2)\n",
        "x2 = Dense(16, activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='dense_4')(x2)\n",
        "x2 = Flatten()(x2)\n",
        "outputs = Dense(5, activation='softmax', name='pred')(x2)\n",
        "\n",
        "model = Model(i, outputs)\n",
        "opt = AdamOptimizer(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "recest (InputLayer)             [(None, 7, 1)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "1Dconv_1 (Conv1D)               (None, 5, 64)        256         recest[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "1Dconv_2 (Conv1D)               (None, 3, 64)        12352       1Dconv_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 3, 64)        0           1Dconv_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 1, 64)        0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 64)           0           max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           4160        flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 7, 64)        128         recest[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 7, 64)        0           dense_1[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 7, 64)        4160        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 7, 16)        1040        dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 112)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "pred (Dense)                    (None, 5)            565         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 22,661\n",
            "Trainable params: 22,661\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SUsrNxCS0qd8",
        "outputId": "ffd7011e-42be-4f9f-a0a7-07653e650e36",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=16,\n",
        "                    epochs=300,\n",
        "\n",
        "                    validation_data=(x_vl, y_vl))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1098 samples, validate on 275 samples\n",
            "Epoch 1/300\n",
            "1098/1098 [==============================] - 1s 960us/sample - loss: 2.3382 - acc: 0.4800 - val_loss: 1.6835 - val_acc: 0.6582\n",
            "Epoch 2/300\n",
            "1098/1098 [==============================] - 0s 232us/sample - loss: 1.4563 - acc: 0.6913 - val_loss: 1.2524 - val_acc: 0.7745\n",
            "Epoch 3/300\n",
            "1098/1098 [==============================] - 0s 236us/sample - loss: 1.1240 - acc: 0.7432 - val_loss: 1.0507 - val_acc: 0.7709\n",
            "Epoch 4/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 1.0012 - acc: 0.7587 - val_loss: 0.9990 - val_acc: 0.7782\n",
            "Epoch 5/300\n",
            "1098/1098 [==============================] - 0s 232us/sample - loss: 0.9074 - acc: 0.7723 - val_loss: 0.9034 - val_acc: 0.7782\n",
            "Epoch 6/300\n",
            "1098/1098 [==============================] - 0s 255us/sample - loss: 0.8561 - acc: 0.7732 - val_loss: 0.8658 - val_acc: 0.7927\n",
            "Epoch 7/300\n",
            "1098/1098 [==============================] - 0s 238us/sample - loss: 0.7990 - acc: 0.8024 - val_loss: 0.8073 - val_acc: 0.7818\n",
            "Epoch 8/300\n",
            "1098/1098 [==============================] - 0s 246us/sample - loss: 0.7672 - acc: 0.7942 - val_loss: 0.7479 - val_acc: 0.8255\n",
            "Epoch 9/300\n",
            "1098/1098 [==============================] - 0s 225us/sample - loss: 0.7499 - acc: 0.7933 - val_loss: 0.7546 - val_acc: 0.8218\n",
            "Epoch 10/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.6965 - acc: 0.8233 - val_loss: 0.7241 - val_acc: 0.8364\n",
            "Epoch 11/300\n",
            "1098/1098 [==============================] - 0s 257us/sample - loss: 0.6784 - acc: 0.8406 - val_loss: 0.6624 - val_acc: 0.8291\n",
            "Epoch 12/300\n",
            "1098/1098 [==============================] - 0s 248us/sample - loss: 0.6346 - acc: 0.8406 - val_loss: 0.6959 - val_acc: 0.8182\n",
            "Epoch 13/300\n",
            "1098/1098 [==============================] - 0s 238us/sample - loss: 0.6348 - acc: 0.8397 - val_loss: 0.6224 - val_acc: 0.8327\n",
            "Epoch 14/300\n",
            "1098/1098 [==============================] - 0s 268us/sample - loss: 0.6028 - acc: 0.8452 - val_loss: 0.5943 - val_acc: 0.8691\n",
            "Epoch 15/300\n",
            "1098/1098 [==============================] - 0s 252us/sample - loss: 0.6025 - acc: 0.8534 - val_loss: 0.6018 - val_acc: 0.8582\n",
            "Epoch 16/300\n",
            "1098/1098 [==============================] - 0s 263us/sample - loss: 0.5749 - acc: 0.8488 - val_loss: 0.5876 - val_acc: 0.8727\n",
            "Epoch 17/300\n",
            "1098/1098 [==============================] - 0s 272us/sample - loss: 0.5531 - acc: 0.8625 - val_loss: 0.5750 - val_acc: 0.8691\n",
            "Epoch 18/300\n",
            "1098/1098 [==============================] - 0s 252us/sample - loss: 0.5723 - acc: 0.8625 - val_loss: 0.5722 - val_acc: 0.8473\n",
            "Epoch 19/300\n",
            "1098/1098 [==============================] - 0s 276us/sample - loss: 0.5420 - acc: 0.8643 - val_loss: 0.5318 - val_acc: 0.8873\n",
            "Epoch 20/300\n",
            "1098/1098 [==============================] - 0s 265us/sample - loss: 0.5477 - acc: 0.8515 - val_loss: 0.5334 - val_acc: 0.8691\n",
            "Epoch 21/300\n",
            "1098/1098 [==============================] - 0s 279us/sample - loss: 0.5154 - acc: 0.8807 - val_loss: 0.5363 - val_acc: 0.8655\n",
            "Epoch 22/300\n",
            "1098/1098 [==============================] - 0s 267us/sample - loss: 0.4962 - acc: 0.8816 - val_loss: 0.5462 - val_acc: 0.8364\n",
            "Epoch 23/300\n",
            "1098/1098 [==============================] - 0s 265us/sample - loss: 0.5077 - acc: 0.8689 - val_loss: 0.5139 - val_acc: 0.8727\n",
            "Epoch 24/300\n",
            "1098/1098 [==============================] - 0s 289us/sample - loss: 0.4867 - acc: 0.8916 - val_loss: 0.4874 - val_acc: 0.8836\n",
            "Epoch 25/300\n",
            "1098/1098 [==============================] - 0s 291us/sample - loss: 0.4831 - acc: 0.8889 - val_loss: 0.4963 - val_acc: 0.8982\n",
            "Epoch 26/300\n",
            "1098/1098 [==============================] - 0s 271us/sample - loss: 0.5019 - acc: 0.8734 - val_loss: 0.5239 - val_acc: 0.8436\n",
            "Epoch 27/300\n",
            "1098/1098 [==============================] - 0s 278us/sample - loss: 0.4593 - acc: 0.8871 - val_loss: 0.5211 - val_acc: 0.8618\n",
            "Epoch 28/300\n",
            "1098/1098 [==============================] - 0s 261us/sample - loss: 0.4589 - acc: 0.8953 - val_loss: 0.4750 - val_acc: 0.8873\n",
            "Epoch 29/300\n",
            "1098/1098 [==============================] - 0s 308us/sample - loss: 0.4567 - acc: 0.8743 - val_loss: 0.4661 - val_acc: 0.8982\n",
            "Epoch 30/300\n",
            "1098/1098 [==============================] - 0s 254us/sample - loss: 0.4644 - acc: 0.8862 - val_loss: 0.4704 - val_acc: 0.8873\n",
            "Epoch 31/300\n",
            "1098/1098 [==============================] - 0s 250us/sample - loss: 0.4496 - acc: 0.8843 - val_loss: 0.5575 - val_acc: 0.8436\n",
            "Epoch 32/300\n",
            "1098/1098 [==============================] - 0s 238us/sample - loss: 0.4666 - acc: 0.8770 - val_loss: 0.5068 - val_acc: 0.8582\n",
            "Epoch 33/300\n",
            "1098/1098 [==============================] - 0s 230us/sample - loss: 0.4532 - acc: 0.8862 - val_loss: 0.4606 - val_acc: 0.8873\n",
            "Epoch 34/300\n",
            "1098/1098 [==============================] - 0s 234us/sample - loss: 0.4395 - acc: 0.8889 - val_loss: 0.4630 - val_acc: 0.9091\n",
            "Epoch 35/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.4212 - acc: 0.8953 - val_loss: 0.4531 - val_acc: 0.8982\n",
            "Epoch 36/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.4215 - acc: 0.8880 - val_loss: 0.4482 - val_acc: 0.8945\n",
            "Epoch 37/300\n",
            "1098/1098 [==============================] - 0s 253us/sample - loss: 0.4269 - acc: 0.8825 - val_loss: 0.4445 - val_acc: 0.8764\n",
            "Epoch 38/300\n",
            "1098/1098 [==============================] - 0s 249us/sample - loss: 0.4173 - acc: 0.8916 - val_loss: 0.5592 - val_acc: 0.8364\n",
            "Epoch 39/300\n",
            "1098/1098 [==============================] - 0s 254us/sample - loss: 0.4190 - acc: 0.8944 - val_loss: 0.4317 - val_acc: 0.8982\n",
            "Epoch 40/300\n",
            "1098/1098 [==============================] - 0s 230us/sample - loss: 0.4192 - acc: 0.8916 - val_loss: 0.4470 - val_acc: 0.8909\n",
            "Epoch 41/300\n",
            "1098/1098 [==============================] - 0s 237us/sample - loss: 0.4139 - acc: 0.8862 - val_loss: 0.4845 - val_acc: 0.8727\n",
            "Epoch 42/300\n",
            "1098/1098 [==============================] - 0s 246us/sample - loss: 0.4094 - acc: 0.8907 - val_loss: 0.4256 - val_acc: 0.9055\n",
            "Epoch 43/300\n",
            "1098/1098 [==============================] - 0s 244us/sample - loss: 0.4076 - acc: 0.8925 - val_loss: 0.4138 - val_acc: 0.9091\n",
            "Epoch 44/300\n",
            "1098/1098 [==============================] - 0s 233us/sample - loss: 0.4119 - acc: 0.8962 - val_loss: 0.3994 - val_acc: 0.9164\n",
            "Epoch 45/300\n",
            "1098/1098 [==============================] - 0s 227us/sample - loss: 0.4140 - acc: 0.8934 - val_loss: 0.4104 - val_acc: 0.9164\n",
            "Epoch 46/300\n",
            "1098/1098 [==============================] - 0s 247us/sample - loss: 0.3926 - acc: 0.9016 - val_loss: 0.4178 - val_acc: 0.9127\n",
            "Epoch 47/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.3976 - acc: 0.9016 - val_loss: 0.4261 - val_acc: 0.8909\n",
            "Epoch 48/300\n",
            "1098/1098 [==============================] - 0s 234us/sample - loss: 0.3834 - acc: 0.8980 - val_loss: 0.4449 - val_acc: 0.8909\n",
            "Epoch 49/300\n",
            "1098/1098 [==============================] - 0s 239us/sample - loss: 0.4177 - acc: 0.8871 - val_loss: 0.3917 - val_acc: 0.9091\n",
            "Epoch 50/300\n",
            "1098/1098 [==============================] - 0s 224us/sample - loss: 0.3872 - acc: 0.8971 - val_loss: 0.4259 - val_acc: 0.8909\n",
            "Epoch 51/300\n",
            "1098/1098 [==============================] - 0s 239us/sample - loss: 0.3870 - acc: 0.9026 - val_loss: 0.3883 - val_acc: 0.9200\n",
            "Epoch 52/300\n",
            "1098/1098 [==============================] - 0s 238us/sample - loss: 0.4008 - acc: 0.8916 - val_loss: 0.4156 - val_acc: 0.9127\n",
            "Epoch 53/300\n",
            "1098/1098 [==============================] - 0s 245us/sample - loss: 0.3894 - acc: 0.9026 - val_loss: 0.4498 - val_acc: 0.8582\n",
            "Epoch 54/300\n",
            "1098/1098 [==============================] - 0s 237us/sample - loss: 0.3786 - acc: 0.9016 - val_loss: 0.4383 - val_acc: 0.8691\n",
            "Epoch 55/300\n",
            "1098/1098 [==============================] - 0s 252us/sample - loss: 0.3686 - acc: 0.9080 - val_loss: 0.4053 - val_acc: 0.8800\n",
            "Epoch 56/300\n",
            "1098/1098 [==============================] - 0s 247us/sample - loss: 0.3922 - acc: 0.8898 - val_loss: 0.4494 - val_acc: 0.8727\n",
            "Epoch 57/300\n",
            "1098/1098 [==============================] - 0s 249us/sample - loss: 0.3909 - acc: 0.8944 - val_loss: 0.4225 - val_acc: 0.8691\n",
            "Epoch 58/300\n",
            "1098/1098 [==============================] - 0s 226us/sample - loss: 0.3830 - acc: 0.9035 - val_loss: 0.4196 - val_acc: 0.8764\n",
            "Epoch 59/300\n",
            "1098/1098 [==============================] - 0s 250us/sample - loss: 0.3700 - acc: 0.8980 - val_loss: 0.3946 - val_acc: 0.8909\n",
            "Epoch 60/300\n",
            "1098/1098 [==============================] - 0s 213us/sample - loss: 0.3687 - acc: 0.9044 - val_loss: 0.4013 - val_acc: 0.8982\n",
            "Epoch 61/300\n",
            "1098/1098 [==============================] - 0s 213us/sample - loss: 0.3608 - acc: 0.9080 - val_loss: 0.4021 - val_acc: 0.8982\n",
            "Epoch 62/300\n",
            "1098/1098 [==============================] - 0s 239us/sample - loss: 0.3728 - acc: 0.8989 - val_loss: 0.3733 - val_acc: 0.9164\n",
            "Epoch 63/300\n",
            "1098/1098 [==============================] - 0s 240us/sample - loss: 0.3567 - acc: 0.9035 - val_loss: 0.3982 - val_acc: 0.8764\n",
            "Epoch 64/300\n",
            "1098/1098 [==============================] - 0s 237us/sample - loss: 0.3565 - acc: 0.9026 - val_loss: 0.3656 - val_acc: 0.9055\n",
            "Epoch 65/300\n",
            "1098/1098 [==============================] - 0s 232us/sample - loss: 0.3674 - acc: 0.9080 - val_loss: 0.4223 - val_acc: 0.8618\n",
            "Epoch 66/300\n",
            "1098/1098 [==============================] - 0s 253us/sample - loss: 0.3782 - acc: 0.8962 - val_loss: 0.4693 - val_acc: 0.8582\n",
            "Epoch 67/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.3596 - acc: 0.9053 - val_loss: 0.3741 - val_acc: 0.9018\n",
            "Epoch 68/300\n",
            "1098/1098 [==============================] - 0s 243us/sample - loss: 0.3479 - acc: 0.9026 - val_loss: 0.4225 - val_acc: 0.8800\n",
            "Epoch 69/300\n",
            "1098/1098 [==============================] - 0s 229us/sample - loss: 0.3706 - acc: 0.8971 - val_loss: 0.3647 - val_acc: 0.9091\n",
            "Epoch 70/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.3605 - acc: 0.9044 - val_loss: 0.3743 - val_acc: 0.9091\n",
            "Epoch 71/300\n",
            "1098/1098 [==============================] - 0s 224us/sample - loss: 0.3586 - acc: 0.8971 - val_loss: 0.3876 - val_acc: 0.8873\n",
            "Epoch 72/300\n",
            "1098/1098 [==============================] - 0s 237us/sample - loss: 0.3501 - acc: 0.9098 - val_loss: 0.3798 - val_acc: 0.9200\n",
            "Epoch 73/300\n",
            "1098/1098 [==============================] - 0s 229us/sample - loss: 0.3587 - acc: 0.9035 - val_loss: 0.3787 - val_acc: 0.9164\n",
            "Epoch 74/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.3748 - acc: 0.9016 - val_loss: 0.3787 - val_acc: 0.8982\n",
            "Epoch 75/300\n",
            "1098/1098 [==============================] - 0s 235us/sample - loss: 0.3356 - acc: 0.9199 - val_loss: 0.3609 - val_acc: 0.9018\n",
            "Epoch 76/300\n",
            "1098/1098 [==============================] - 0s 268us/sample - loss: 0.3424 - acc: 0.9117 - val_loss: 0.3872 - val_acc: 0.8873\n",
            "Epoch 77/300\n",
            "1098/1098 [==============================] - 0s 255us/sample - loss: 0.3807 - acc: 0.8944 - val_loss: 0.4389 - val_acc: 0.8582\n",
            "Epoch 78/300\n",
            "1098/1098 [==============================] - 0s 244us/sample - loss: 0.3444 - acc: 0.9144 - val_loss: 0.3760 - val_acc: 0.9018\n",
            "Epoch 79/300\n",
            "1098/1098 [==============================] - 0s 223us/sample - loss: 0.3548 - acc: 0.8953 - val_loss: 0.3605 - val_acc: 0.9127\n",
            "Epoch 80/300\n",
            "1098/1098 [==============================] - 0s 235us/sample - loss: 0.3414 - acc: 0.9053 - val_loss: 0.3713 - val_acc: 0.9091\n",
            "Epoch 81/300\n",
            "1098/1098 [==============================] - 0s 258us/sample - loss: 0.3608 - acc: 0.8971 - val_loss: 0.3588 - val_acc: 0.9127\n",
            "Epoch 82/300\n",
            "1098/1098 [==============================] - 0s 227us/sample - loss: 0.3348 - acc: 0.9126 - val_loss: 0.3890 - val_acc: 0.8945\n",
            "Epoch 83/300\n",
            "1098/1098 [==============================] - 0s 233us/sample - loss: 0.3521 - acc: 0.8989 - val_loss: 0.3486 - val_acc: 0.9200\n",
            "Epoch 84/300\n",
            "1098/1098 [==============================] - 0s 232us/sample - loss: 0.3368 - acc: 0.9016 - val_loss: 0.3494 - val_acc: 0.9200\n",
            "Epoch 85/300\n",
            "1098/1098 [==============================] - 0s 226us/sample - loss: 0.3304 - acc: 0.9098 - val_loss: 0.3640 - val_acc: 0.9091\n",
            "Epoch 86/300\n",
            "1098/1098 [==============================] - 0s 235us/sample - loss: 0.3535 - acc: 0.8962 - val_loss: 0.3727 - val_acc: 0.9018\n",
            "Epoch 87/300\n",
            "1098/1098 [==============================] - 0s 258us/sample - loss: 0.3445 - acc: 0.9053 - val_loss: 0.3845 - val_acc: 0.8909\n",
            "Epoch 88/300\n",
            "1098/1098 [==============================] - 0s 263us/sample - loss: 0.3591 - acc: 0.9026 - val_loss: 0.3503 - val_acc: 0.9091\n",
            "Epoch 89/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.3249 - acc: 0.9144 - val_loss: 0.4429 - val_acc: 0.8727\n",
            "Epoch 90/300\n",
            "1098/1098 [==============================] - 0s 222us/sample - loss: 0.3351 - acc: 0.9126 - val_loss: 0.3674 - val_acc: 0.9127\n",
            "Epoch 91/300\n",
            "1098/1098 [==============================] - 0s 246us/sample - loss: 0.3288 - acc: 0.9107 - val_loss: 0.3601 - val_acc: 0.9091\n",
            "Epoch 92/300\n",
            "1098/1098 [==============================] - 0s 235us/sample - loss: 0.3311 - acc: 0.9053 - val_loss: 0.3664 - val_acc: 0.9127\n",
            "Epoch 93/300\n",
            "1098/1098 [==============================] - 0s 235us/sample - loss: 0.3326 - acc: 0.9080 - val_loss: 0.3561 - val_acc: 0.9055\n",
            "Epoch 94/300\n",
            "1098/1098 [==============================] - 0s 245us/sample - loss: 0.3544 - acc: 0.8998 - val_loss: 0.3926 - val_acc: 0.8945\n",
            "Epoch 95/300\n",
            "1098/1098 [==============================] - 0s 236us/sample - loss: 0.3361 - acc: 0.9089 - val_loss: 0.3715 - val_acc: 0.9164\n",
            "Epoch 96/300\n",
            "1098/1098 [==============================] - 0s 251us/sample - loss: 0.3163 - acc: 0.9171 - val_loss: 0.3399 - val_acc: 0.9055\n",
            "Epoch 97/300\n",
            "1098/1098 [==============================] - 0s 221us/sample - loss: 0.3331 - acc: 0.9071 - val_loss: 0.3595 - val_acc: 0.9018\n",
            "Epoch 98/300\n",
            "1098/1098 [==============================] - 0s 227us/sample - loss: 0.3409 - acc: 0.9026 - val_loss: 0.3836 - val_acc: 0.9055\n",
            "Epoch 99/300\n",
            "1098/1098 [==============================] - 0s 246us/sample - loss: 0.3586 - acc: 0.8998 - val_loss: 0.3711 - val_acc: 0.8945\n",
            "Epoch 100/300\n",
            "1098/1098 [==============================] - 0s 239us/sample - loss: 0.3280 - acc: 0.9035 - val_loss: 0.3886 - val_acc: 0.8764\n",
            "Epoch 101/300\n",
            "1098/1098 [==============================] - 0s 247us/sample - loss: 0.3155 - acc: 0.9153 - val_loss: 0.3976 - val_acc: 0.9018\n",
            "Epoch 102/300\n",
            "1098/1098 [==============================] - 0s 221us/sample - loss: 0.3209 - acc: 0.9071 - val_loss: 0.3386 - val_acc: 0.9127\n",
            "Epoch 103/300\n",
            "1098/1098 [==============================] - 0s 234us/sample - loss: 0.3324 - acc: 0.9044 - val_loss: 0.3976 - val_acc: 0.8909\n",
            "Epoch 104/300\n",
            "1098/1098 [==============================] - 0s 226us/sample - loss: 0.3208 - acc: 0.9062 - val_loss: 0.3480 - val_acc: 0.9091\n",
            "Epoch 105/300\n",
            "1098/1098 [==============================] - 0s 243us/sample - loss: 0.3462 - acc: 0.9007 - val_loss: 0.3716 - val_acc: 0.9055\n",
            "Epoch 106/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.3215 - acc: 0.9144 - val_loss: 0.3761 - val_acc: 0.9018\n",
            "Epoch 107/300\n",
            "1098/1098 [==============================] - 0s 260us/sample - loss: 0.3424 - acc: 0.9007 - val_loss: 0.3343 - val_acc: 0.9127\n",
            "Epoch 108/300\n",
            "1098/1098 [==============================] - 0s 230us/sample - loss: 0.3333 - acc: 0.9053 - val_loss: 0.3775 - val_acc: 0.9127\n",
            "Epoch 109/300\n",
            "1098/1098 [==============================] - 0s 237us/sample - loss: 0.3539 - acc: 0.9044 - val_loss: 0.3464 - val_acc: 0.9200\n",
            "Epoch 110/300\n",
            "1098/1098 [==============================] - 0s 237us/sample - loss: 0.3314 - acc: 0.9053 - val_loss: 0.3539 - val_acc: 0.9127\n",
            "Epoch 111/300\n",
            "1098/1098 [==============================] - 0s 230us/sample - loss: 0.3203 - acc: 0.9062 - val_loss: 0.3446 - val_acc: 0.9127\n",
            "Epoch 112/300\n",
            "1098/1098 [==============================] - 0s 249us/sample - loss: 0.3195 - acc: 0.9080 - val_loss: 0.3300 - val_acc: 0.9091\n",
            "Epoch 113/300\n",
            "1098/1098 [==============================] - 0s 238us/sample - loss: 0.3117 - acc: 0.9144 - val_loss: 0.3531 - val_acc: 0.9055\n",
            "Epoch 114/300\n",
            "1098/1098 [==============================] - 0s 240us/sample - loss: 0.3136 - acc: 0.9126 - val_loss: 0.3532 - val_acc: 0.9055\n",
            "Epoch 115/300\n",
            "1098/1098 [==============================] - 0s 246us/sample - loss: 0.3157 - acc: 0.9107 - val_loss: 0.3807 - val_acc: 0.8945\n",
            "Epoch 116/300\n",
            "1098/1098 [==============================] - 0s 228us/sample - loss: 0.3129 - acc: 0.9135 - val_loss: 0.3473 - val_acc: 0.9200\n",
            "Epoch 117/300\n",
            "1098/1098 [==============================] - 0s 237us/sample - loss: 0.3049 - acc: 0.9135 - val_loss: 0.3464 - val_acc: 0.9127\n",
            "Epoch 118/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.3424 - acc: 0.8971 - val_loss: 0.3515 - val_acc: 0.9236\n",
            "Epoch 119/300\n",
            "1098/1098 [==============================] - 0s 236us/sample - loss: 0.3136 - acc: 0.9071 - val_loss: 0.3355 - val_acc: 0.9273\n",
            "Epoch 120/300\n",
            "1098/1098 [==============================] - 0s 252us/sample - loss: 0.3159 - acc: 0.9062 - val_loss: 0.3973 - val_acc: 0.8764\n",
            "Epoch 121/300\n",
            "1098/1098 [==============================] - 0s 228us/sample - loss: 0.3210 - acc: 0.9080 - val_loss: 0.3511 - val_acc: 0.9164\n",
            "Epoch 122/300\n",
            "1098/1098 [==============================] - 0s 237us/sample - loss: 0.3175 - acc: 0.9053 - val_loss: 0.3838 - val_acc: 0.8800\n",
            "Epoch 123/300\n",
            "1098/1098 [==============================] - 0s 246us/sample - loss: 0.3386 - acc: 0.8934 - val_loss: 0.3552 - val_acc: 0.8982\n",
            "Epoch 124/300\n",
            "1098/1098 [==============================] - 0s 237us/sample - loss: 0.3117 - acc: 0.9089 - val_loss: 0.3515 - val_acc: 0.9236\n",
            "Epoch 125/300\n",
            "1098/1098 [==============================] - 0s 235us/sample - loss: 0.3100 - acc: 0.9144 - val_loss: 0.3597 - val_acc: 0.8982\n",
            "Epoch 126/300\n",
            "1098/1098 [==============================] - 0s 238us/sample - loss: 0.3264 - acc: 0.9080 - val_loss: 0.3878 - val_acc: 0.9018\n",
            "Epoch 127/300\n",
            "1098/1098 [==============================] - 0s 230us/sample - loss: 0.2989 - acc: 0.9189 - val_loss: 0.3315 - val_acc: 0.9164\n",
            "Epoch 128/300\n",
            "1098/1098 [==============================] - 0s 251us/sample - loss: 0.3112 - acc: 0.9144 - val_loss: 0.3583 - val_acc: 0.8982\n",
            "Epoch 129/300\n",
            "1098/1098 [==============================] - 0s 238us/sample - loss: 0.3062 - acc: 0.9071 - val_loss: 0.3452 - val_acc: 0.9055\n",
            "Epoch 130/300\n",
            "1098/1098 [==============================] - 0s 239us/sample - loss: 0.3110 - acc: 0.9126 - val_loss: 0.4026 - val_acc: 0.8800\n",
            "Epoch 131/300\n",
            "1098/1098 [==============================] - 0s 227us/sample - loss: 0.3308 - acc: 0.8971 - val_loss: 0.5687 - val_acc: 0.8545\n",
            "Epoch 132/300\n",
            "1098/1098 [==============================] - 0s 222us/sample - loss: 0.3372 - acc: 0.9044 - val_loss: 0.3534 - val_acc: 0.9236\n",
            "Epoch 133/300\n",
            "1098/1098 [==============================] - 0s 240us/sample - loss: 0.3043 - acc: 0.9153 - val_loss: 0.3384 - val_acc: 0.9091\n",
            "Epoch 134/300\n",
            "1098/1098 [==============================] - 0s 241us/sample - loss: 0.3072 - acc: 0.9144 - val_loss: 0.3373 - val_acc: 0.9091\n",
            "Epoch 135/300\n",
            "1098/1098 [==============================] - 0s 234us/sample - loss: 0.2931 - acc: 0.9199 - val_loss: 0.3594 - val_acc: 0.9018\n",
            "Epoch 136/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.3052 - acc: 0.9162 - val_loss: 0.3683 - val_acc: 0.9127\n",
            "Epoch 137/300\n",
            "1098/1098 [==============================] - 0s 245us/sample - loss: 0.3195 - acc: 0.9062 - val_loss: 0.3348 - val_acc: 0.9091\n",
            "Epoch 138/300\n",
            "1098/1098 [==============================] - 0s 243us/sample - loss: 0.3174 - acc: 0.9053 - val_loss: 0.3302 - val_acc: 0.9127\n",
            "Epoch 139/300\n",
            "1098/1098 [==============================] - 0s 232us/sample - loss: 0.3169 - acc: 0.9026 - val_loss: 0.3428 - val_acc: 0.9091\n",
            "Epoch 140/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.3157 - acc: 0.9071 - val_loss: 0.3429 - val_acc: 0.9091\n",
            "Epoch 141/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.3018 - acc: 0.9135 - val_loss: 0.3575 - val_acc: 0.9091\n",
            "Epoch 142/300\n",
            "1098/1098 [==============================] - 0s 228us/sample - loss: 0.2932 - acc: 0.9199 - val_loss: 0.3377 - val_acc: 0.9091\n",
            "Epoch 143/300\n",
            "1098/1098 [==============================] - 0s 248us/sample - loss: 0.2998 - acc: 0.9062 - val_loss: 0.3201 - val_acc: 0.9200\n",
            "Epoch 144/300\n",
            "1098/1098 [==============================] - 0s 241us/sample - loss: 0.3055 - acc: 0.9107 - val_loss: 0.3306 - val_acc: 0.9200\n",
            "Epoch 145/300\n",
            "1098/1098 [==============================] - 0s 240us/sample - loss: 0.3081 - acc: 0.9080 - val_loss: 0.3442 - val_acc: 0.8909\n",
            "Epoch 146/300\n",
            "1098/1098 [==============================] - 0s 238us/sample - loss: 0.3179 - acc: 0.9071 - val_loss: 0.3228 - val_acc: 0.9200\n",
            "Epoch 147/300\n",
            "1098/1098 [==============================] - 0s 249us/sample - loss: 0.3108 - acc: 0.9098 - val_loss: 0.3387 - val_acc: 0.9055\n",
            "Epoch 148/300\n",
            "1098/1098 [==============================] - 0s 241us/sample - loss: 0.3048 - acc: 0.9053 - val_loss: 0.3323 - val_acc: 0.9127\n",
            "Epoch 149/300\n",
            "1098/1098 [==============================] - 0s 239us/sample - loss: 0.3267 - acc: 0.9053 - val_loss: 0.3451 - val_acc: 0.9018\n",
            "Epoch 150/300\n",
            "1098/1098 [==============================] - 0s 224us/sample - loss: 0.3081 - acc: 0.9035 - val_loss: 0.3908 - val_acc: 0.8909\n",
            "Epoch 151/300\n",
            "1098/1098 [==============================] - 0s 234us/sample - loss: 0.3011 - acc: 0.9080 - val_loss: 0.3379 - val_acc: 0.9127\n",
            "Epoch 152/300\n",
            "1098/1098 [==============================] - 0s 250us/sample - loss: 0.3011 - acc: 0.9126 - val_loss: 0.3235 - val_acc: 0.9164\n",
            "Epoch 153/300\n",
            "1098/1098 [==============================] - 0s 226us/sample - loss: 0.2952 - acc: 0.9144 - val_loss: 0.3617 - val_acc: 0.8982\n",
            "Epoch 154/300\n",
            "1098/1098 [==============================] - 0s 229us/sample - loss: 0.3002 - acc: 0.9107 - val_loss: 0.3286 - val_acc: 0.9127\n",
            "Epoch 155/300\n",
            "1098/1098 [==============================] - 0s 232us/sample - loss: 0.2927 - acc: 0.9107 - val_loss: 0.3242 - val_acc: 0.9200\n",
            "Epoch 156/300\n",
            "1098/1098 [==============================] - 0s 250us/sample - loss: 0.3164 - acc: 0.9062 - val_loss: 0.3288 - val_acc: 0.9164\n",
            "Epoch 157/300\n",
            "1098/1098 [==============================] - 0s 241us/sample - loss: 0.2983 - acc: 0.9107 - val_loss: 0.3901 - val_acc: 0.8836\n",
            "Epoch 158/300\n",
            "1098/1098 [==============================] - 0s 250us/sample - loss: 0.3057 - acc: 0.9035 - val_loss: 0.3405 - val_acc: 0.9055\n",
            "Epoch 159/300\n",
            "1098/1098 [==============================] - 0s 246us/sample - loss: 0.2977 - acc: 0.9126 - val_loss: 0.3965 - val_acc: 0.8836\n",
            "Epoch 160/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.2961 - acc: 0.9107 - val_loss: 0.3329 - val_acc: 0.9018\n",
            "Epoch 161/300\n",
            "1098/1098 [==============================] - 0s 228us/sample - loss: 0.3095 - acc: 0.9153 - val_loss: 0.3371 - val_acc: 0.9200\n",
            "Epoch 162/300\n",
            "1098/1098 [==============================] - 0s 225us/sample - loss: 0.2950 - acc: 0.9162 - val_loss: 0.3502 - val_acc: 0.9018\n",
            "Epoch 163/300\n",
            "1098/1098 [==============================] - 0s 234us/sample - loss: 0.2896 - acc: 0.9135 - val_loss: 0.3406 - val_acc: 0.9091\n",
            "Epoch 164/300\n",
            "1098/1098 [==============================] - 0s 226us/sample - loss: 0.2909 - acc: 0.9189 - val_loss: 0.3548 - val_acc: 0.8800\n",
            "Epoch 165/300\n",
            "1098/1098 [==============================] - 0s 235us/sample - loss: 0.3020 - acc: 0.9071 - val_loss: 0.3408 - val_acc: 0.8982\n",
            "Epoch 166/300\n",
            "1098/1098 [==============================] - 0s 230us/sample - loss: 0.3006 - acc: 0.9144 - val_loss: 0.3283 - val_acc: 0.9164\n",
            "Epoch 167/300\n",
            "1098/1098 [==============================] - 0s 257us/sample - loss: 0.2951 - acc: 0.9144 - val_loss: 0.3257 - val_acc: 0.9164\n",
            "Epoch 168/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.2838 - acc: 0.9208 - val_loss: 0.3277 - val_acc: 0.9164\n",
            "Epoch 169/300\n",
            "1098/1098 [==============================] - 0s 241us/sample - loss: 0.2930 - acc: 0.9080 - val_loss: 0.3256 - val_acc: 0.9018\n",
            "Epoch 170/300\n",
            "1098/1098 [==============================] - 0s 232us/sample - loss: 0.2930 - acc: 0.9144 - val_loss: 0.3256 - val_acc: 0.9127\n",
            "Epoch 171/300\n",
            "1098/1098 [==============================] - 0s 241us/sample - loss: 0.2804 - acc: 0.9199 - val_loss: 0.3411 - val_acc: 0.9164\n",
            "Epoch 172/300\n",
            "1098/1098 [==============================] - 0s 225us/sample - loss: 0.2952 - acc: 0.9098 - val_loss: 0.3207 - val_acc: 0.9018\n",
            "Epoch 173/300\n",
            "1098/1098 [==============================] - 0s 229us/sample - loss: 0.2958 - acc: 0.9144 - val_loss: 0.3352 - val_acc: 0.9200\n",
            "Epoch 174/300\n",
            "1098/1098 [==============================] - 0s 225us/sample - loss: 0.2903 - acc: 0.9171 - val_loss: 0.3569 - val_acc: 0.8945\n",
            "Epoch 175/300\n",
            "1098/1098 [==============================] - 0s 241us/sample - loss: 0.2831 - acc: 0.9199 - val_loss: 0.3391 - val_acc: 0.8982\n",
            "Epoch 176/300\n",
            "1098/1098 [==============================] - 0s 235us/sample - loss: 0.2989 - acc: 0.9098 - val_loss: 0.3762 - val_acc: 0.8909\n",
            "Epoch 177/300\n",
            "1098/1098 [==============================] - 0s 270us/sample - loss: 0.2922 - acc: 0.9107 - val_loss: 0.3266 - val_acc: 0.9200\n",
            "Epoch 178/300\n",
            "1098/1098 [==============================] - 0s 235us/sample - loss: 0.2935 - acc: 0.9117 - val_loss: 0.3248 - val_acc: 0.9200\n",
            "Epoch 179/300\n",
            "1098/1098 [==============================] - 0s 241us/sample - loss: 0.2874 - acc: 0.9180 - val_loss: 0.3254 - val_acc: 0.9091\n",
            "Epoch 180/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.2978 - acc: 0.9144 - val_loss: 0.3972 - val_acc: 0.8800\n",
            "Epoch 181/300\n",
            "1098/1098 [==============================] - 0s 233us/sample - loss: 0.3038 - acc: 0.9117 - val_loss: 0.3275 - val_acc: 0.9164\n",
            "Epoch 182/300\n",
            "1098/1098 [==============================] - 0s 254us/sample - loss: 0.3024 - acc: 0.9117 - val_loss: 0.3450 - val_acc: 0.9091\n",
            "Epoch 183/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.2988 - acc: 0.9071 - val_loss: 0.3210 - val_acc: 0.9200\n",
            "Epoch 184/300\n",
            "1098/1098 [==============================] - 0s 230us/sample - loss: 0.2778 - acc: 0.9162 - val_loss: 0.3174 - val_acc: 0.9127\n",
            "Epoch 185/300\n",
            "1098/1098 [==============================] - 0s 219us/sample - loss: 0.2922 - acc: 0.9144 - val_loss: 0.3399 - val_acc: 0.9055\n",
            "Epoch 186/300\n",
            "1098/1098 [==============================] - 0s 243us/sample - loss: 0.2829 - acc: 0.9162 - val_loss: 0.3435 - val_acc: 0.8982\n",
            "Epoch 187/300\n",
            "1098/1098 [==============================] - 0s 224us/sample - loss: 0.2783 - acc: 0.9226 - val_loss: 0.3372 - val_acc: 0.9164\n",
            "Epoch 188/300\n",
            "1098/1098 [==============================] - 0s 236us/sample - loss: 0.2937 - acc: 0.9107 - val_loss: 0.3294 - val_acc: 0.9127\n",
            "Epoch 189/300\n",
            "1098/1098 [==============================] - 0s 255us/sample - loss: 0.2772 - acc: 0.9144 - val_loss: 0.3426 - val_acc: 0.9091\n",
            "Epoch 190/300\n",
            "1098/1098 [==============================] - 0s 281us/sample - loss: 0.2846 - acc: 0.9126 - val_loss: 0.3809 - val_acc: 0.8873\n",
            "Epoch 191/300\n",
            "1098/1098 [==============================] - 0s 226us/sample - loss: 0.2866 - acc: 0.9189 - val_loss: 0.3204 - val_acc: 0.9236\n",
            "Epoch 192/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.2988 - acc: 0.9071 - val_loss: 0.3248 - val_acc: 0.9164\n",
            "Epoch 193/300\n",
            "1098/1098 [==============================] - 0s 223us/sample - loss: 0.2787 - acc: 0.9162 - val_loss: 0.3234 - val_acc: 0.9236\n",
            "Epoch 194/300\n",
            "1098/1098 [==============================] - 0s 243us/sample - loss: 0.2884 - acc: 0.9153 - val_loss: 0.4322 - val_acc: 0.8800\n",
            "Epoch 195/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.2920 - acc: 0.9144 - val_loss: 0.3298 - val_acc: 0.9091\n",
            "Epoch 196/300\n",
            "1098/1098 [==============================] - 0s 241us/sample - loss: 0.2927 - acc: 0.9135 - val_loss: 0.3782 - val_acc: 0.8909\n",
            "Epoch 197/300\n",
            "1098/1098 [==============================] - 0s 230us/sample - loss: 0.2900 - acc: 0.9089 - val_loss: 0.3462 - val_acc: 0.8982\n",
            "Epoch 198/300\n",
            "1098/1098 [==============================] - 0s 255us/sample - loss: 0.3138 - acc: 0.9007 - val_loss: 0.3512 - val_acc: 0.9018\n",
            "Epoch 199/300\n",
            "1098/1098 [==============================] - 0s 233us/sample - loss: 0.2775 - acc: 0.9171 - val_loss: 0.3519 - val_acc: 0.9018\n",
            "Epoch 200/300\n",
            "1098/1098 [==============================] - 0s 248us/sample - loss: 0.2979 - acc: 0.9080 - val_loss: 0.3570 - val_acc: 0.9055\n",
            "Epoch 201/300\n",
            "1098/1098 [==============================] - 0s 251us/sample - loss: 0.2817 - acc: 0.9253 - val_loss: 0.3253 - val_acc: 0.9164\n",
            "Epoch 202/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.2763 - acc: 0.9208 - val_loss: 0.3319 - val_acc: 0.9055\n",
            "Epoch 203/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.2840 - acc: 0.9144 - val_loss: 0.3936 - val_acc: 0.8982\n",
            "Epoch 204/300\n",
            "1098/1098 [==============================] - 0s 240us/sample - loss: 0.2911 - acc: 0.9171 - val_loss: 0.3404 - val_acc: 0.9055\n",
            "Epoch 205/300\n",
            "1098/1098 [==============================] - 0s 243us/sample - loss: 0.2952 - acc: 0.9098 - val_loss: 0.3770 - val_acc: 0.8982\n",
            "Epoch 206/300\n",
            "1098/1098 [==============================] - 0s 227us/sample - loss: 0.2945 - acc: 0.9126 - val_loss: 0.3681 - val_acc: 0.8945\n",
            "Epoch 207/300\n",
            "1098/1098 [==============================] - 0s 230us/sample - loss: 0.2798 - acc: 0.9189 - val_loss: 0.3186 - val_acc: 0.9273\n",
            "Epoch 208/300\n",
            "1098/1098 [==============================] - 0s 221us/sample - loss: 0.2759 - acc: 0.9189 - val_loss: 0.3265 - val_acc: 0.9091\n",
            "Epoch 209/300\n",
            "1098/1098 [==============================] - 0s 243us/sample - loss: 0.2804 - acc: 0.9153 - val_loss: 0.4953 - val_acc: 0.8582\n",
            "Epoch 210/300\n",
            "1098/1098 [==============================] - 0s 236us/sample - loss: 0.2974 - acc: 0.9107 - val_loss: 0.3600 - val_acc: 0.9055\n",
            "Epoch 211/300\n",
            "1098/1098 [==============================] - 0s 221us/sample - loss: 0.2812 - acc: 0.9135 - val_loss: 0.3346 - val_acc: 0.9091\n",
            "Epoch 212/300\n",
            "1098/1098 [==============================] - 0s 236us/sample - loss: 0.2739 - acc: 0.9208 - val_loss: 0.3678 - val_acc: 0.8909\n",
            "Epoch 213/300\n",
            "1098/1098 [==============================] - 0s 245us/sample - loss: 0.2843 - acc: 0.9098 - val_loss: 0.4283 - val_acc: 0.8873\n",
            "Epoch 214/300\n",
            "1098/1098 [==============================] - 0s 241us/sample - loss: 0.2753 - acc: 0.9244 - val_loss: 0.3470 - val_acc: 0.9091\n",
            "Epoch 215/300\n",
            "1098/1098 [==============================] - 0s 233us/sample - loss: 0.2680 - acc: 0.9199 - val_loss: 0.3877 - val_acc: 0.8836\n",
            "Epoch 216/300\n",
            "1098/1098 [==============================] - 0s 255us/sample - loss: 0.2797 - acc: 0.9144 - val_loss: 0.3269 - val_acc: 0.9127\n",
            "Epoch 217/300\n",
            "1098/1098 [==============================] - 0s 243us/sample - loss: 0.2890 - acc: 0.9171 - val_loss: 0.3533 - val_acc: 0.8945\n",
            "Epoch 218/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.2810 - acc: 0.9208 - val_loss: 0.3306 - val_acc: 0.9091\n",
            "Epoch 219/300\n",
            "1098/1098 [==============================] - 0s 243us/sample - loss: 0.2822 - acc: 0.9208 - val_loss: 0.3249 - val_acc: 0.9164\n",
            "Epoch 220/300\n",
            "1098/1098 [==============================] - 0s 227us/sample - loss: 0.2803 - acc: 0.9153 - val_loss: 0.3524 - val_acc: 0.8982\n",
            "Epoch 221/300\n",
            "1098/1098 [==============================] - 0s 243us/sample - loss: 0.2759 - acc: 0.9244 - val_loss: 0.3350 - val_acc: 0.9164\n",
            "Epoch 222/300\n",
            "1098/1098 [==============================] - 0s 249us/sample - loss: 0.2751 - acc: 0.9153 - val_loss: 0.3592 - val_acc: 0.8909\n",
            "Epoch 223/300\n",
            "1098/1098 [==============================] - 0s 250us/sample - loss: 0.2689 - acc: 0.9208 - val_loss: 0.3409 - val_acc: 0.8982\n",
            "Epoch 224/300\n",
            "1098/1098 [==============================] - 0s 232us/sample - loss: 0.2759 - acc: 0.9162 - val_loss: 0.3343 - val_acc: 0.9127\n",
            "Epoch 225/300\n",
            "1098/1098 [==============================] - 0s 239us/sample - loss: 0.2783 - acc: 0.9153 - val_loss: 0.3499 - val_acc: 0.9091\n",
            "Epoch 226/300\n",
            "1098/1098 [==============================] - 0s 236us/sample - loss: 0.2801 - acc: 0.9180 - val_loss: 0.3362 - val_acc: 0.9018\n",
            "Epoch 227/300\n",
            "1098/1098 [==============================] - 0s 239us/sample - loss: 0.2787 - acc: 0.9180 - val_loss: 0.3476 - val_acc: 0.9055\n",
            "Epoch 228/300\n",
            "1098/1098 [==============================] - 0s 254us/sample - loss: 0.2691 - acc: 0.9235 - val_loss: 0.3517 - val_acc: 0.9055\n",
            "Epoch 229/300\n",
            "1098/1098 [==============================] - 0s 234us/sample - loss: 0.2809 - acc: 0.9126 - val_loss: 0.3412 - val_acc: 0.9018\n",
            "Epoch 230/300\n",
            "1098/1098 [==============================] - 0s 229us/sample - loss: 0.2766 - acc: 0.9153 - val_loss: 0.3648 - val_acc: 0.8945\n",
            "Epoch 231/300\n",
            "1098/1098 [==============================] - 0s 239us/sample - loss: 0.2821 - acc: 0.9089 - val_loss: 0.4049 - val_acc: 0.8873\n",
            "Epoch 232/300\n",
            "1098/1098 [==============================] - 0s 238us/sample - loss: 0.2768 - acc: 0.9153 - val_loss: 0.3284 - val_acc: 0.9091\n",
            "Epoch 233/300\n",
            "1098/1098 [==============================] - 0s 239us/sample - loss: 0.2772 - acc: 0.9135 - val_loss: 0.3246 - val_acc: 0.9236\n",
            "Epoch 234/300\n",
            "1098/1098 [==============================] - 0s 228us/sample - loss: 0.2993 - acc: 0.9080 - val_loss: 0.3470 - val_acc: 0.9091\n",
            "Epoch 235/300\n",
            "1098/1098 [==============================] - 0s 286us/sample - loss: 0.3040 - acc: 0.8962 - val_loss: 0.3285 - val_acc: 0.9164\n",
            "Epoch 236/300\n",
            "1098/1098 [==============================] - 0s 234us/sample - loss: 0.2711 - acc: 0.9244 - val_loss: 0.3356 - val_acc: 0.9200\n",
            "Epoch 237/300\n",
            "1098/1098 [==============================] - 0s 227us/sample - loss: 0.2753 - acc: 0.9098 - val_loss: 0.3476 - val_acc: 0.9018\n",
            "Epoch 238/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.2798 - acc: 0.9162 - val_loss: 0.3386 - val_acc: 0.9127\n",
            "Epoch 239/300\n",
            "1098/1098 [==============================] - 0s 227us/sample - loss: 0.2650 - acc: 0.9208 - val_loss: 0.4093 - val_acc: 0.8800\n",
            "Epoch 240/300\n",
            "1098/1098 [==============================] - 0s 270us/sample - loss: 0.2662 - acc: 0.9180 - val_loss: 0.3253 - val_acc: 0.9091\n",
            "Epoch 241/300\n",
            "1098/1098 [==============================] - 0s 256us/sample - loss: 0.2764 - acc: 0.9171 - val_loss: 0.3795 - val_acc: 0.8982\n",
            "Epoch 242/300\n",
            "1098/1098 [==============================] - 0s 244us/sample - loss: 0.2739 - acc: 0.9208 - val_loss: 0.3251 - val_acc: 0.9127\n",
            "Epoch 243/300\n",
            "1098/1098 [==============================] - 0s 247us/sample - loss: 0.2804 - acc: 0.9180 - val_loss: 0.3519 - val_acc: 0.9055\n",
            "Epoch 244/300\n",
            "1098/1098 [==============================] - 0s 232us/sample - loss: 0.2643 - acc: 0.9199 - val_loss: 0.3642 - val_acc: 0.8982\n",
            "Epoch 245/300\n",
            "1098/1098 [==============================] - 0s 226us/sample - loss: 0.2787 - acc: 0.9162 - val_loss: 0.3451 - val_acc: 0.9055\n",
            "Epoch 246/300\n",
            "1098/1098 [==============================] - 0s 252us/sample - loss: 0.2704 - acc: 0.9180 - val_loss: 0.3782 - val_acc: 0.8909\n",
            "Epoch 247/300\n",
            "1098/1098 [==============================] - 0s 227us/sample - loss: 0.2594 - acc: 0.9208 - val_loss: 0.3375 - val_acc: 0.9091\n",
            "Epoch 248/300\n",
            "1098/1098 [==============================] - 0s 235us/sample - loss: 0.2682 - acc: 0.9271 - val_loss: 0.3585 - val_acc: 0.9018\n",
            "Epoch 249/300\n",
            "1098/1098 [==============================] - 0s 223us/sample - loss: 0.2727 - acc: 0.9171 - val_loss: 0.3637 - val_acc: 0.8909\n",
            "Epoch 250/300\n",
            "1098/1098 [==============================] - 0s 241us/sample - loss: 0.2626 - acc: 0.9199 - val_loss: 0.3349 - val_acc: 0.9164\n",
            "Epoch 251/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.2698 - acc: 0.9189 - val_loss: 0.3976 - val_acc: 0.9018\n",
            "Epoch 252/300\n",
            "1098/1098 [==============================] - 0s 245us/sample - loss: 0.2632 - acc: 0.9162 - val_loss: 0.3596 - val_acc: 0.8945\n",
            "Epoch 253/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.2634 - acc: 0.9189 - val_loss: 0.3443 - val_acc: 0.9091\n",
            "Epoch 254/300\n",
            "1098/1098 [==============================] - 0s 244us/sample - loss: 0.2583 - acc: 0.9208 - val_loss: 0.3349 - val_acc: 0.9164\n",
            "Epoch 255/300\n",
            "1098/1098 [==============================] - 0s 241us/sample - loss: 0.2787 - acc: 0.9162 - val_loss: 0.3488 - val_acc: 0.9018\n",
            "Epoch 256/300\n",
            "1098/1098 [==============================] - 0s 278us/sample - loss: 0.2738 - acc: 0.9162 - val_loss: 0.3327 - val_acc: 0.9018\n",
            "Epoch 257/300\n",
            "1098/1098 [==============================] - 0s 254us/sample - loss: 0.2868 - acc: 0.9098 - val_loss: 0.3266 - val_acc: 0.9091\n",
            "Epoch 258/300\n",
            "1098/1098 [==============================] - 0s 238us/sample - loss: 0.2596 - acc: 0.9208 - val_loss: 0.3494 - val_acc: 0.8945\n",
            "Epoch 259/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.2755 - acc: 0.9180 - val_loss: 0.3497 - val_acc: 0.9055\n",
            "Epoch 260/300\n",
            "1098/1098 [==============================] - 0s 239us/sample - loss: 0.2835 - acc: 0.9135 - val_loss: 0.3302 - val_acc: 0.9127\n",
            "Epoch 261/300\n",
            "1098/1098 [==============================] - 0s 230us/sample - loss: 0.2587 - acc: 0.9226 - val_loss: 0.3351 - val_acc: 0.9164\n",
            "Epoch 262/300\n",
            "1098/1098 [==============================] - 0s 237us/sample - loss: 0.2658 - acc: 0.9199 - val_loss: 0.3641 - val_acc: 0.9018\n",
            "Epoch 263/300\n",
            "1098/1098 [==============================] - 0s 239us/sample - loss: 0.2728 - acc: 0.9217 - val_loss: 0.3385 - val_acc: 0.9164\n",
            "Epoch 264/300\n",
            "1098/1098 [==============================] - 0s 244us/sample - loss: 0.2842 - acc: 0.9162 - val_loss: 0.3283 - val_acc: 0.9164\n",
            "Epoch 265/300\n",
            "1098/1098 [==============================] - 0s 262us/sample - loss: 0.2896 - acc: 0.9089 - val_loss: 0.3336 - val_acc: 0.9200\n",
            "Epoch 266/300\n",
            "1098/1098 [==============================] - 0s 235us/sample - loss: 0.2725 - acc: 0.9171 - val_loss: 0.3696 - val_acc: 0.8945\n",
            "Epoch 267/300\n",
            "1098/1098 [==============================] - 0s 253us/sample - loss: 0.2559 - acc: 0.9235 - val_loss: 0.3418 - val_acc: 0.9200\n",
            "Epoch 268/300\n",
            "1098/1098 [==============================] - 0s 249us/sample - loss: 0.2561 - acc: 0.9208 - val_loss: 0.3382 - val_acc: 0.9127\n",
            "Epoch 269/300\n",
            "1098/1098 [==============================] - 0s 247us/sample - loss: 0.2632 - acc: 0.9208 - val_loss: 0.3386 - val_acc: 0.9055\n",
            "Epoch 270/300\n",
            "1098/1098 [==============================] - 0s 242us/sample - loss: 0.2830 - acc: 0.9126 - val_loss: 0.3433 - val_acc: 0.9164\n",
            "Epoch 271/300\n",
            "1098/1098 [==============================] - 0s 244us/sample - loss: 0.3024 - acc: 0.9080 - val_loss: 0.3665 - val_acc: 0.8945\n",
            "Epoch 272/300\n",
            "1098/1098 [==============================] - 0s 240us/sample - loss: 0.2771 - acc: 0.9117 - val_loss: 0.3358 - val_acc: 0.9127\n",
            "Epoch 273/300\n",
            "1098/1098 [==============================] - 0s 259us/sample - loss: 0.2674 - acc: 0.9189 - val_loss: 0.3418 - val_acc: 0.9055\n",
            "Epoch 274/300\n",
            "1098/1098 [==============================] - 0s 229us/sample - loss: 0.2569 - acc: 0.9217 - val_loss: 0.3370 - val_acc: 0.9164\n",
            "Epoch 275/300\n",
            "1098/1098 [==============================] - 0s 237us/sample - loss: 0.2572 - acc: 0.9199 - val_loss: 0.3301 - val_acc: 0.9200\n",
            "Epoch 276/300\n",
            "1098/1098 [==============================] - 0s 253us/sample - loss: 0.2686 - acc: 0.9153 - val_loss: 0.3308 - val_acc: 0.9164\n",
            "Epoch 277/300\n",
            "1098/1098 [==============================] - 0s 229us/sample - loss: 0.2582 - acc: 0.9171 - val_loss: 0.3401 - val_acc: 0.9164\n",
            "Epoch 278/300\n",
            "1098/1098 [==============================] - 0s 241us/sample - loss: 0.2732 - acc: 0.9126 - val_loss: 0.3465 - val_acc: 0.9127\n",
            "Epoch 279/300\n",
            "1098/1098 [==============================] - 0s 260us/sample - loss: 0.2834 - acc: 0.9117 - val_loss: 0.4793 - val_acc: 0.8618\n",
            "Epoch 280/300\n",
            "1098/1098 [==============================] - 0s 226us/sample - loss: 0.2781 - acc: 0.9135 - val_loss: 0.3477 - val_acc: 0.9055\n",
            "Epoch 281/300\n",
            "1098/1098 [==============================] - 0s 248us/sample - loss: 0.2719 - acc: 0.9153 - val_loss: 0.3465 - val_acc: 0.9127\n",
            "Epoch 282/300\n",
            "1098/1098 [==============================] - 0s 236us/sample - loss: 0.2552 - acc: 0.9253 - val_loss: 0.3355 - val_acc: 0.9127\n",
            "Epoch 283/300\n",
            "1098/1098 [==============================] - 0s 252us/sample - loss: 0.2621 - acc: 0.9226 - val_loss: 0.4083 - val_acc: 0.8945\n",
            "Epoch 284/300\n",
            "1098/1098 [==============================] - 0s 229us/sample - loss: 0.2503 - acc: 0.9253 - val_loss: 0.3278 - val_acc: 0.9164\n",
            "Epoch 285/300\n",
            "1098/1098 [==============================] - 0s 231us/sample - loss: 0.2614 - acc: 0.9171 - val_loss: 0.3846 - val_acc: 0.8945\n",
            "Epoch 286/300\n",
            "1098/1098 [==============================] - 0s 252us/sample - loss: 0.2648 - acc: 0.9199 - val_loss: 0.3813 - val_acc: 0.8945\n",
            "Epoch 287/300\n",
            "1098/1098 [==============================] - 0s 235us/sample - loss: 0.2629 - acc: 0.9189 - val_loss: 0.3285 - val_acc: 0.9127\n",
            "Epoch 288/300\n",
            "1098/1098 [==============================] - 0s 232us/sample - loss: 0.2497 - acc: 0.9226 - val_loss: 0.3559 - val_acc: 0.8873\n",
            "Epoch 289/300\n",
            "1098/1098 [==============================] - 0s 243us/sample - loss: 0.2728 - acc: 0.9162 - val_loss: 0.3436 - val_acc: 0.9091\n",
            "Epoch 290/300\n",
            "1098/1098 [==============================] - 0s 251us/sample - loss: 0.2932 - acc: 0.9117 - val_loss: 0.3543 - val_acc: 0.9091\n",
            "Epoch 291/300\n",
            "1098/1098 [==============================] - 0s 244us/sample - loss: 0.2724 - acc: 0.9162 - val_loss: 0.3362 - val_acc: 0.9127\n",
            "Epoch 292/300\n",
            "1098/1098 [==============================] - 0s 225us/sample - loss: 0.2515 - acc: 0.9244 - val_loss: 0.3417 - val_acc: 0.9091\n",
            "Epoch 293/300\n",
            "1098/1098 [==============================] - 0s 233us/sample - loss: 0.2588 - acc: 0.9235 - val_loss: 0.3837 - val_acc: 0.8873\n",
            "Epoch 294/300\n",
            "1098/1098 [==============================] - 0s 247us/sample - loss: 0.2538 - acc: 0.9253 - val_loss: 0.3468 - val_acc: 0.8982\n",
            "Epoch 295/300\n",
            "1098/1098 [==============================] - 0s 243us/sample - loss: 0.2631 - acc: 0.9162 - val_loss: 0.3468 - val_acc: 0.9091\n",
            "Epoch 296/300\n",
            "1098/1098 [==============================] - 0s 244us/sample - loss: 0.2569 - acc: 0.9162 - val_loss: 0.3572 - val_acc: 0.9127\n",
            "Epoch 297/300\n",
            "1098/1098 [==============================] - 0s 259us/sample - loss: 0.2632 - acc: 0.9199 - val_loss: 0.3410 - val_acc: 0.9091\n",
            "Epoch 298/300\n",
            "1098/1098 [==============================] - 0s 239us/sample - loss: 0.2593 - acc: 0.9162 - val_loss: 0.3741 - val_acc: 0.8982\n",
            "Epoch 299/300\n",
            "1098/1098 [==============================] - 0s 238us/sample - loss: 0.2696 - acc: 0.9189 - val_loss: 0.3218 - val_acc: 0.9164\n",
            "Epoch 300/300\n",
            "1098/1098 [==============================] - 0s 243us/sample - loss: 0.2785 - acc: 0.9107 - val_loss: 0.3475 - val_acc: 0.9018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KqMl5V5y0qeB",
        "outputId": "5f529706-26f1-46bf-b479-c07acbed867f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plot_hist(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0pBJQZI0ZFKQJA39PwCMpPsXJhvuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8E/f5wPHPI1seeGDABgM2mL1H\nwIWELLKBNKslCRnNTprRpmmaZjTtL2nSNqNtmh1CEgKE7L0gG8hgQ9h7T2Nj8MRL0vf3x/dkC2Mb\nM2TZ6Hm/XnpJujvdPaez77nvuK/EGINSSikF4Ap1AEoppRoPTQpKKaUqaVJQSilVSZOCUkqpSpoU\nlFJKVdKkoJRSqpImBRV0IpIhIkZEIuux7DUi8uORrudoEZFHROQO5/VwEdnWQNvdJCJnHoX1FIlI\n56MRUzCIyFwR6RPqOFQVTQpqP87JqFxEkqtN/9k5IWeEJrKGJyIpwFXAi0dhXQ2e0ACMMfHGmA3B\n3IaIjBOR1SLiE5FrapjfWUQ+E5FCEdktIo8HzP4P8FAw41OHRpOCqslG4DL/GxHpBzQLXTghcw0w\nxRhTEupAGrnFwK3AwuozRCQK+Br4DkgF0oDJAYt8ApwmIqkNEKeqB00KqiavYa+Q/a4GJgUuICLN\nRWSSiOSIyGYR+auIuJx5ESLyH+eqcANwbg2ffUVEdorIdhH5h4hEHGqQItJORD4RkT0isk5EbgyY\nN0RE5otIgYjsEpEnnOkxIjJZRHJFJE9E5olIm1o2MRKYUcN2/+Ls2yYRuSJg+rlOiapARLaKyIMB\nH/veec5zqnROcD5zo4isdK6iV4jIoIDPDBSRJSKSLyJvi0hMLd9DVxGZ4Sy3W0TeDphnnPntnO36\nH/tExAQsd50Tx14R+VJEOtb2vVdnjHnOGPMtUFrD7GuAHcaYJ4wxxcaYUmPMkoDPlgILgHPquz0V\nXJoUVE1mA4ki0ss5WY9h/6s7gGeA5kBn4FRsErnWmXcj8EvgOCATGF3tsxMAD9DVWeZs4IbDiPMt\nYBvQztnGv0TkdGfeU8BTxphEoAvwjjP9aifudKAVcDNQW0mgH7C62rRUIBlo76xrnIj0cOYVY7+H\nJGwivEVELnTmneI8JzlVOrNE5GLgQeczicD5QG7Ati4BRgCdgP7YE2xNHga+Alpgr8Sfqb6AMWaH\ns914Y0w88CH2+0NELgD+AvwKSAF+AN70f9ap+rm3lm0fzPHAJhGZ6iSs6U7JM9BKYMBhrl8dZZoU\nVG38pYWzsP+02/0zAhLFfcaYQmPMJuC/wG+cRS4BnjTGbDXG7AEeCfhsG2AUcIdz5ZgN/M9ZX72J\nSDpwInCPc/W5CHiZqhJOBdBVRJKNMUXGmNkB01sBXY0xXmPMAmNMQS2bSQIKa5j+N2NMmTFmBvC5\ns78YY6YbY5YaY3zO1fCb2IRZmxuAx40x84y1zhizOWD+087JfA/wKTCwlvVUAB2Bds53UWNDvZ+I\n3AP0BK5zJt0MPGKMWWmM8QD/wpZSOjr79UtjzKN1rbMOadhj+zQ2eX8OfOxUK/kVYr9r1QhoUlC1\neQ24HHt1OqnavGTADQSewDZjr57B/vNvrTbPr6Pz2Z1O9U0etiG39SHG1w7YY4wJPGkHxnA90B1Y\n5VQR/TJgv74E3hKRHSLyuIi4a9nGXiCh+jRjTHG1bbYDEJGhIjLNqVLLx55sk6ldOrC+jvlZAa/3\nAfG1LHc3IMBcEVkuItfVshwiMhL4A3BhQFtJR+CpgOOxx1lf+1pWcyhKgB+NMVONMeXYhuVWQK+A\nZRKAvKOwLXUUaFJQNXKuWDdir+o/qDZ7N1VXp34dqCpN7MSe8ALn+W0FyoBkY0yS80g0xhxqt8Qd\nQEsRCTxpV8ZgjFlrjLkMm2weA94TkThjTIUx5u/GmN7AMGw111XUbAk2sQRqISJx1ba5w3n9Brbh\nNN0Y0xwYiz25AtQ0HPFWbNXWETHGZBljbjTGtAN+CzwvIl2rL+dUc00ELjHGBCbtrcBvA45HkjEm\n1hgz80hjw36HBxuKuRe2sVo1ApoUVF2uB06vdmWMMcaLraP/p4gkONUMd1LV7vAOcLuIpIlIC+De\ngM/uxNZ//1dEEkXEJSJdRKSuapYDOCe1mcAjTuNxfyfeyQAicqWIpBhjfFRdhfpE5DQR6edUgRVg\nk5uvls1Moebqn7+LSJSInIxNKu860xOwpZdSERmCLWn55TjbCbxn4GXgLhEZLFbXQ2ng9RORi0Uk\nzXm7F3sS9lVbJhH4GLi/huqlscB94twvILYjwMWHsP0opxFcALdzPPznlsnA8SJypvOd34G9qFjp\nfDYGGIztoaQaA2OMPvRR+QA2AWfWMD0Se7LJcN63wP7D52CvNP8PcAUs+z9so+lG4Dbns5HO/ObA\nC9hG4nzgZ2CMM+8abHVDTbFlVFtPGvAZtrpjPXBzwLKTgWygCFiOrS4B29V2NbZReBe2rjuylu0l\nOzHGOu+HO+/vx57YtgC/CVh+NLY6qdCJ61lgcsD8h5zvKw843pl2sxNPEbAMOK6m44BtkJ5cS5yP\nY0tIRc73cFPAPINt0B/uvC4KfAQs9xtgKTZRbgXGB8ybCvyljr+Z6c66Ax/DA+b/CljnrHs60Cdg\n3sXAB6H+u9dH1UOcA6OUqoGI/AvINsY8GepYjkUiMge43hizLNSxKEuTglJKqUrapqCUUqqSJgWl\nlFKVNCkopZSq1KAjNh4NycnJJiMjI9RhKKVUk7JgwYLdxpiUgy3X5JJCRkYG8+fPD3UYSinVpIjI\n5oMvpdVHSimlAmhSUEopVUmTglJKqUpNrk2hJhUVFWzbto3S0pp+4+PYFBMTQ1paGm53bQN8KqXU\noTsmksK2bdtISEggIyMDETn4B5o4Ywy5ubls27aNTp06hTocpdQx5JioPiotLaVVq1ZhkRAARIRW\nrVqFVclIKdUwjomkAIRNQvALt/1VSjWMYyYpHExphZes/FIqvLUNna+UUiqskkJ2YSle39EfFTY3\nN5eBAwcycOBAUlNTad++feX78vLyeq3j2muvZfXq6r8Rr5RSDeuYaGiuD39tSzBGCm/VqhWLFi0C\n4MEHHyQ+Pp677rprv2X8P2DhctWch1999dWjH5hSSh2isCkp1P1TucGxbt06evfuzRVXXEGfPn3Y\nuXMnN910E5mZmfTp04eHHnqoctmTTjqJRYsW4fF4SEpK4t5772XAgAGccMIJZGdnN1jMSqnwdsyV\nFP7+6XJW7Cg4YLrXZyit8BIbFYHrEBtpe7dL5IHzDvV35a1Vq1YxadIkMjMzAXj00Udp2bIlHo+H\n0047jdGjR9O7d+/9PpOfn8+pp57Ko48+yp133sn48eO59957a1q9UkodVWFUUgiNLl26VCYEgDff\nfJNBgwYxaNAgVq5cyYoVKw74TGxsLCNHjgRg8ODBbNq0qaHCVUqFuWOupFDbFX1haQUbdxfTJSWe\nuOiG2+24uLjK12vXruWpp55i7ty5JCUlceWVV9Z4r0FUVFTl64iICDweT4PEqpRSYVNSaPgWhQMV\nFBSQkJBAYmIiO3fu5MsvvwxhNEopdaBjrqRQq2B2P6qnQYMG0bt3b3r27EnHjh058cQTQxaLUkrV\nREwIT5KHIzMz01T/kZ2VK1fSq1evOj9XXOZhfU4RnZLjSIg5NgaRq89+K6UUgIgsMMZkHmy5sKk+\nUkopdXBhkxQaQe2RUko1euGTFEIdgFJKNQFhkxT8acGEtP+RUko1bmGTFLT6SCmlDi5skoJSSqmD\nC5ukEMyb147G0NkA48ePJysrKwgRKqVU/YTRzWvOc4iGzq6P8ePHM2jQIFJTU492iEopVS9hkxRC\nNczFxIkTee655ygvL2fYsGE8++yz+Hw+rr32WhYtWoQxhptuuok2bdqwaNEiLr30UmJjY5k7d+5+\nYyAppVRDOPaSwtR7IWvpAZMjjaFzuZdotwtq+aGbWqX2g5GPHnIoy5Yt48MPP2TmzJlERkZy0003\n8dZbb9GlSxd2797N0qU2zry8PJKSknjmmWd49tlnGThw4CFvSymljoZjLynUJgRFhW+++YZ58+ZV\nDp1dUlJCeno655xzDqtXr+b222/n3HPP5eyzz264oJRSqg7HXlKo5Yre6/WxYWcB7ZJiSY6PbpBQ\njDFcd911PPzwwwfMW7JkCVOnTuW5557j/fffZ9y4cQ0Sk1JK1SXseh81pDPPPJN33nmH3bt3A7aX\n0pYtW8jJycEYw8UXX8xDDz3EwoULAUhISKCwsDAEkSqllHXslRRqE4Kb1/r168cDDzzAmWeeic/n\nw+12M3bsWCIiIrj++usxxiAiPPbYYwBce+213HDDDdrQrJQKmbAZOtvrMyzfkU/b5jGkJMQEM8QG\no0NnK6XqS4fOrqYx/PKaUko1dmGTFDQrKKXUwR0zSeFg1WDHWk5oatV+Sqmm4ZhICjExMeTm5obN\nidIYQ25uLjExx0bbiFKq8Tgmeh+lpaWxbds2cnJy6lwue28JJTGR7Ilt+r/RHBMTQ1paWqjDUEod\nY4KWFEQkHZgEtMHW2owzxjxVbRkBngJGAfuAa4wxCw91W263m06dOh10ufPvn8INJ3fmnhE9D3UT\nSikVFoJZUvAAfzLGLBSRBGCBiHxtjFkRsMxIoJvzGAq84DwHhUsEny88qpiUUupwBK1NwRiz03/V\nb4wpBFYC7astdgEwyVizgSQRaRusmCJcgleTglJK1apBGppFJAM4DphTbVZ7YGvA+20cmDgQkZtE\nZL6IzD9Yu0FdIkTwhkljtFJKHY6gJwURiQfeB+4wxhQczjqMMeOMMZnGmMyUlJTDjsXl0uojpZSq\nS1CTgoi4sQnhdWPMBzUssh1ID3if5kwLigiXlhSUUqouQUsKTs+iV4CVxpgnalnsE+AqsY4H8o0x\nO4MVk0sEry9Ya1dKqaYvmL2PTgR+AywVkUXOtL8AHQCMMWOBKdjuqOuwXVKvDWI8RLoEr0+zglJK\n1SZoScEY8yMH+RkDY29Bvi1YMVRnex811NaUUqrpOSaGuagvlwt82qaglFK1CqukECF6n4JSStUl\nrJKCS3sfKaVUncIqKUToMBdKKVWn8EoKOsyFUkrVKaySgktEG5qVUqoOYZUUIiMEj5YUlFKqVmGV\nFFza+0gppeoUVkkhwqXVR0opVZfwSgpaUlBKqTqFVVJwuUCHPlJKqdqFVVLQobOVUqpuYZUUtKFZ\nKaXqFlZJQRualVKqbmGVFCJdgserSUEppWoTVklB72hWSqm6hVVS0LGPlFKqbmGVFHTobKWUqltY\nJQUdOlsppeoWXklBSwpKKVWnsEoKLhG9o1kppeoQVkkhwoU2NCulVB3CLCm4tPpIKaXqED5JIWsp\no3Y+R6I3L9SRKKVUoxU+SSF3PSfnvEmST5OCUkrVJnySQkQUAJGmIsSBKKVU4xU+SSHSJgWXJgWl\nlKpV+CSFypJCeYgDUUqpxisMk4InxIEopVTjFXZJIUKrj5RSqlZhlxQijQej9yoopVSNwicpREYD\nEIVH72pWSqlahE9SiHADECUVelezUkrVIoySgq0+cuPRQfGUUqoWYZQUbPWRG4+WFJRSqhZhlBSc\n6iNtU1BKqVqFT1IIaGjWX19TSqmahU9ScGlDs1JKHUzQkoKIjBeRbBFZVsv84SKSLyKLnMf/BSsW\nAFwufBLpNDRrUlBKqZpEBnHdE4BngUl1LPODMeaXQYxhP16XGzdePJoUlFKqRkErKRhjvgf2BGv9\nh8PnchNFhTY0K6VULULdpnCCiCwWkaki0ifYG/O5omxDs7YpKKVUjYJZfXQwC4GOxpgiERkFfAR0\nq2lBEbkJuAmgQ4cOh71B43ITJdolVSmlahOykoIxpsAYU+S8ngK4RSS5lmXHGWMyjTGZKSkph71N\nn8ttG5q1pKCUUjUKWVIQkVQREef1ECeW3GBu00REO20KwdyKUko1XUGrPhKRN4HhQLKIbAMeANwA\nxpixwGjgFhHxACXAGBPkMa39JQWPDn6klFI1ClpSMMZcdpD5z2K7rDacCNvQXOHV6iOllKpJqHsf\nNayIKKLEQ2mFN9SRKKVUoxRWSUEibfVRmUerj5RSqiZhlRRwGprLtKSglFI1Cquk4IqMwo1XSwpK\nKVWLsEoK4o7BjbYpKKVUbcIqKbgio4iWCi0pKKVULeqVFESki4hEO6+Hi8jtIpIU3NCOvojIKG1o\nVkqpOtS3pPA+4BWRrsA4IB14I2hRBYnLHUMUHso8Wn2klFI1qW9S8BljPMBFwDPGmD8DbYMXVnBE\nuKOcNgUtKSilVE3qmxQqROQy4GrgM2eaOzghBY9ERmtJQSml6lDfpHAtcALwT2PMRhHpBLwWvLCC\nxLmjuaxck4JSStWkXmMfGWNWALcDiEgLIMEY81gwAwuKCFu48VSUhTgQpZRqnOrb+2i6iCSKSEvs\nj+O8JCJPBDe0IIiIBsBbrklBKaVqUt/qo+bGmALgV8AkY8xQ4MzghRUkEVEAeD2aFJRSqib1TQqR\nItIWuISqhuamJ9JJClp9pJRSNapvUngI+BJYb4yZJyKdgbXBCytIIjQpKKVUXerb0Pwu8G7A+w3A\nr4MVVNA4ScGn1UdKKVWj+jY0p4nIhyKS7TzeF5G0YAd31DlJwXjKQxyIUko1TvWtPnoV+ARo5zw+\ndaY1Le5YAKSiJMSBKKVU41TfpJBijHnVGONxHhOAlCDGFRzRCQBEeotDHIhSSjVO9U0KuSJypYhE\nOI8rgdxgBhYUTlKI8mhSUEqpmtQ3KVyH7Y6aBewERgPXBCmm4ImKt09aUlBKqRrVKykYYzYbY843\nxqQYY1obYy6kKfY+ik4ENCkopVRtjuSX1+48alE0lGhbUojx7cMYE+JglFKq8TmSpCBHLYqGEhmN\nV9zEUYLHp0lBKaWqO5Kk0CTPquWRccRToj/JqZRSNajzjmYRKaTmk78AsUGJKMg8kfHESwmlFV7i\no+t1Q7dSSoWNOs+KxpiEhgqkoXjcccRTqiUFpZSqwZFUHzVJXne8rT6q0F9fU0qp6sIuKfjc8cSJ\ntikopVRNwi4pEJ1APCUUlnpCHYlSSjU6YZcU3LHNSZAScot0+GyllKou7LrfRMU3J5pSdhfr8NlK\nKVVd2CWFmLjmREgZewp1qAullKou7KqPImLs+EeF+XkhjkQppRqfsEsK/uGz9xVqUlBKqerCMCnY\nQfFKizQpKKVUdeGXFBLaAhBbvC3EgSilVOMTfkkhtR8+XKSXrgp1JEop1egELSmIyHgRyRaRZbXM\nFxF5WkTWicgSERkUrFj2ExXHnrgu9PKupcyjQ10opVSgYJYUJgAj6pg/EujmPG4CXghiLPvJb9GP\n/q4N7NEb2JRSaj9BSwrGmO+BPXUscgEwyVizgSQRaRuseAKVtR5ACykif8e6hticUko1GaFsU2gP\nbA14v82ZdgARuUlE5ovI/JycnCPecFS7PgDs27HyiNellFLHkibR0GyMGWeMyTTGZKakpBzx+lq0\n7QxA6R7tgaSUUoFCmRS2A+kB79OcaUHXok0HvEbw5WtSUEqpQKFMCp8AVzm9kI4H8o0xOxtiw65I\nN7mulkQW7miIzSmlVJMRtAHxRORNYDiQLCLbgAcAN4AxZiwwBRgFrAP2AdcGK5aa5EemEFu6qyE3\nqZRSjV7QkoIx5rKDzDfAbcHa/sEUx7ShRZH2PlJKqUBNoqE5GDzx7Ujx7cbr1Z/lVEopv7BNCtI8\njWZSRs5urUJSSim/sE0K0a1sx6fd29eHOBKllGo8wjYppHY9DoD8tbNDHIlSSjUeYZsUkjP6sZNk\nErZOC3UoSinVaIRtUkCENQnH07VoPnjKQx2NUko1CuGbFIDiDqfRjFKKNswKdShKKdUohHVSaNlj\nGADZa+aGOBKllGocwjopdO/chd0mkYrtS0IdilJKNQphnRRaxkezwZVB7F79aU6llIIwTwoAexN6\nkFq6EbyeUIeilFIhF/ZJwde6N1FUULZrdahDUUqpkAv7pJCYYW9i27FmfogjUUqp0Av7pNCjXybl\nJoLstQtCHYpSSoVc2CeF5OYJ7HR3gKxl2NG8lVIqfIV9UgDwte5DB89GFm/LD3UoSikVUpoUgNTu\nmbSVPWS9cQu+4j2hDkcppUJGkwIQmz4QgBElU9j0xVMhjkYppUJHkwJAp1MoH/kES3ydab7uI9C2\nBaVUmNKkAOCKIGro9UyPG0Grkk2QtTTUESmlVEhoUgiQn34GAGbzzBBHopRSoaFJIUBGRhf2mnj2\nbVumVUhKqbCkSSFA//QWrDFp+NZPg8c6wobpoQ5JKaUalCaFAP3aNyc3risJJdugNB+2zAl1SEop\n1aA0KQRwuYR+g4ZVTchdF7pglFIqBDQpVJPWfVDVmz3rQxeIUkqFgCaFaiTtF3yWfB3fygmY3HXa\n4KyUCiuaFKqLiCQv8w5mlndBSvOpKNod6oiUUqrBaFKowYldk9lEKgBfff9TiKNRSqmGo0mhBp2S\n4/jrVecDsG3VvBBHo5RSDUeTQi06de/P3tiOHJf/NbOWrcPj8YY6JKWUCjpNCrURwQy8giGu1Qx5\nN5MVE/8Q6oiUUiroNCnUoeWwq/HEJrM9Mp3+W1/DLH4r1CEppVRQaVKoS0IqkXevY96IT5jt64X5\n5Ha2fv44hUWFoY5MKaWCQpPCwYgwckA690X8iXWkkz7vnyx6/a9Hb/0+L3grjt76VP0YA88PgyXv\nhjoSpRoVTQr10Cwqkl+fPJCzix9irq8HrbJ+wOs7hJvaPr0Dvvl7zfO+uBcm//roBKrqr6wQspdD\n1pJQR6JUo6JJoZ6uGpZBz9QEclJOoKdvAyc/+D7vTZ8Lr10Ey96v+8NrvoQl79Q8b9dyyF559ANW\ndSvNs8/lRaGNQ6lGJjLUATQViTFuvrjjFMo2ROCaNIH/mX/Ta8Z2MIWwLxf61nK17ymHwp2AgYId\nkNhu//lFu+znfT5waY5uMKX59rlMk4JSgYJ6FhKRESKyWkTWici9Ncy/RkRyRGSR87ghmPEcDdEd\nh0CbfvSKK2K6py+FvcbAzsWwZ6Nd4Mv74f0bYMfP9n3BNsCpatpWw41wRdlgvFVXrqphlGhJQama\nBC0piEgE8BwwEugNXCYivWtY9G1jzEDn8XKw4jlqItxwy48U3zyf2yt+z5uxlwHgWfoB7F4Ls56F\npe/Cd/+wy+dtqfrs1rn7r6t8H5QV2NfFOQ0QvKpUWVLQnmRKBQpmSWEIsM4Ys8EYUw68BVwQxO01\nqLbNYxnRJ5X/zStlvunB3h9fgQUT8EoEOWln2QTg80LeVvuBhHYHlhSKswNe68B7DaqyTaE4tHEo\n1cgEMym0B7YGvN/mTKvu1yKyRETeE5H0mlYkIjeJyHwRmZ+T03iuqO8d2ROPz8ebvrNIqdiOb/ZY\nvvYM4q3CgbYEkL3SlhTEBb3Phx2LbBuDX1FgUmg8+xUW/CUFrT46PN//B14+K9RRqCAIdcvmp0CG\nMaY/8DUwsaaFjDHjjDGZxpjMlJSUBg2wLhnJcUy5/WTu+P2fyKIVy71pPFBxNR/sdnLbllmQv9WW\nEjoOA28ZZC2tWkHRrqrXxTnw7cPwyjkNuxPhyt+moA3Nh2fXctuWpr83cqDSApjzYpP9boKZFLYD\ngVf+ac60SsaYXGNMmfP2ZWBwEOMJim5tEkhv3ZLy387ih+HvcOkZQ9nobUVZs7YwZyy+rXPxNU9n\ne1w/+4FtAe0KhVlVr4t3w5K3Yevs4NZzeytg+mOwb0/wttEUaJfUI1Oaby9ytPrtQKs+g6l328TZ\nBAUzKcwDuolIJxGJAsYAnwQuICJtA96eDzTZDvsd2rbh1tN7cOPJnXCJ8GDk7ezLy6ZszzaezhvG\n+ZPWk01Le7Paq6OgONepPhKIbg6bf7KlCoBdK4IX6MbvYfq/YPWU4G2jKQisPmqiV3Qh5U+q+3JD\nG0dj5K8KbqJVwkFLCsYYD/A74Evsyf4dY8xyEXlIRM53FrtdRJaLyGLgduCaYMXTUBJi3FwxtCMz\nvb34RckzXNRsAk/mDCavpIKnfJcwLfo0zPYF8Gym7aUUlwwJbWDTD1Ur2bX0wBVXlByYLHJWw4e3\nQFEO7N0MH9128OqQrXPsc/72upc7XD6vfTR2/uoj47PfrTo0/qS6TztIHMDfaaSJJsyg3rxmjJkC\nTKk27f8CXt8H3BfMGELh4Qv7AlDh9RHpEsbO2ECLZm6Smg3i2skLuLv/Fdwa+Sms+hzaZ0LJXvvB\n9oMhd13Nxc5XR9p7H+7bDtHxdtqs52DxG7BrGXQ/BxZNhrTBkHld7cH5k0LBtvrtzDcPQrezbZtI\nfbx/vW1YHz2+fsuHiv+kBra0ENUsdLGEis8HIvZxqCqTQphXQ9bEnwyaaI/CUDc0H9PcES5EhFuG\nd2HMkA6M6JvK9Sd14vElzZg56AneP+073u/xH0xktP3AeU9Dm777N0YDbPyh6ma4dd/YQdx8XlsF\nlNDOjt8ze6ydP/9V+89eE68Hts23r/O32xJGXVUnRdnw4//g58n13+kdP8PWJvBrdYE3C4brvQqv\njoBvaxmTqy7GBCQF5wS4eVbt43uFG/93oiUFVR93nNmNjxft4PKX51RO+yz5NmKjd5P7cSH/TBpA\n15XPUzFvIvOSRpG2ZiIdFjwK7mZQsY/S928lxlcMnlJbZ3nhWJh6D5TlQ3wbmyCe6g/XfQHN0/bf\neM4qe1XsctuT9xO97BV97/Op0faF9jm7nm0cPp9NNj4PVJSCO+YwvqEGUpoPsS2hZE94NjYbAzuX\nQFTcoX+2ogS8Ttdq/9Xwwomw+E045a7DW+expLL6SEsKqh4SYty8/dvjeeC83rxxw1DuPKs7Zc0z\niOp0IjvzSxn58/HMkgHw+R8pm/RrOsx7mH0dT4c/LmdvZLJNCABf/RUTGQM9z4Weo+y0kY/BRePs\nGEtzxto2hx0/V5UGdi62z51OtidDXwVsmV17sNsX2OfsVbWXPgIV59h1YiBv82F9Pw2mJA+aO7fN\nhGMPmrIC8JRAwc5D/2xg1Zv/athf5bn3CI+71wPzXrEXFTXxlMHLZ8KG6Ue2nWDyJwN/cijYYQfO\nLG4aJQdNCiHQJSWea0/sxLBSk+QJAAAgAElEQVSuydx+RjfeuPF4nhxzHNPuGs6Tlw9hSo9/UehO\n4bSIxTztHc1Fubdx03sbWFiRUbWS0jw+Lv8F320qgcHXYlr3YaavL+vajoJe59n2hueGwLjhMH88\nvHQ6LP/Qljg6nVK1nrqGjt7hlBQ8JZC36eA7lh/QTpG7vup1wQ6boKozBmY+C5/+AdZ/Z8eMOpKe\nQCV58NYV+w8tUpOyQrtPSR2d90ehpFBRWns1lM9nT2bbF8DXDxzd3k4VpfDutZCz5tA+5+8OXbij\n7uVyVlddTPhVTwpejy2FAuzddGhxVLf2S/j8ztp7x+1ea0cGWD+t/uv85u+w8LUji+tQ+NtZ/Alz\nw3T79721jguwRkSTQiMS4RLO7d+Wh8ecRMubp8DFEyg64S7W7y7m65W7mOXpQSlRfOizJ/X3OYOb\nJy/kh7LOvNx3Mpe/voYzn/ie5zznYVpkwBkPQLNkmPJne0Ja9zW06QPNA24f2bXMnrRfOQd+fNK+\nLiuybRbbF+Jp1cMu5x/e2xgYPxKmPbJ/8Cs/tfdZ+O3ZUPX649vglbPtTT1gE8bqqTD9Ufjqflgw\nwbaJLH13/88dTPWr0s0/2T7iyz6AeS9Xba+sEMaPsPXeUHVVm5Zpn8uPQpvC53fCxPNqnjfrGXh6\nkE3OPz25/53sR2rXMlj+Aaz69ODLFuyw421BVVIoza+aVpPP/2STdaDA9ph9ubZzhL86ac5YmDy6\nfiXLmvhP9rX9HeSutc95W2yiPViC9fnsjWQ/PXV48RwqT1nAeGZOSSF3nX3OXmlvUF31ec2fNca2\n34W48V6TQmPVqgv0uYh7RvRk4f+dxV1n92Ba84vYdPmPLOx2O1M63s1//3QznZPjuHHSfF6YsZ7M\nji244aRO/HtJLPenT2LPoN/h6fNrOwqrY2ez7tz8qXMndVxrKNmLeel0e1PdNw/AE70wj6RRMOky\nKNnD33NPt8vu+NmeTNd/C1tm2hO438LX4O0rYe6L9n1ENOxxSgplhbahvDTPnjAAPrgJ3hwD3/8b\n4pw71Nd9Y583TLM9nt6/wV5djRtedXIPtPJT23YSOMigv+1j5tP2ZObf3rIP7N3lqz6z7/0N+R2c\nHlWBJQVjDv1K3hgb/45FNce66Sfb22ulc+LOOYLbcfbtgTfGVCVE/wln97q6P+cphxdOhBmP2veB\nd9O/OtKWYKozxn5Xu9fAjMfh3Wvs9v0lBXecTQrZAb3lNs6wFx+HW324wZ8UNtY837+fOattm9iC\nCVXzfD5bteTvdAGQvwUqim0yOZxSjKe8qvtyffhLBy53VTWS/xjNewV++A+8dbn9264ua6m9gJr9\n/P7T57xoS0gNRJNCIxfhEhJj3Nx2Wle+vfssenbvwcO/OYtR195P6+axvH7DUDonx7OnuJzbTuvK\nX3/ZmxtP7sQbc7Yw+B9fc9OKAWzxpTAnZTQAz69qxo8FrVni6sXmfr8HQAp3su3sFzFXfsD3Pe5n\nlrcXiZu+pCwmhTdLT2BexEBbzTP2ZMxkux72rLdXazMeh09+Z0skfqn9YN23tlrj8S62naF5B3uS\n3jwTts/HxKVgYlvA1c6J0p+4pt5jezwtfRe++ptNRjVVJcx7xT4H/sCR/z4O/z/motfticLfeypr\nib2jO2uJbWRO6W6n+xuaty+A//W1+xToYIli70bnJGvsuvO2wJaqjgSVpSz/yTR7Ve3rOphVn8Ga\nqVUJzn/CyT3ISWPrbNuO5O88EHg3/c5FsODV/cflAvs7IP5SwbR/2urHt39TtR8tO9vveudikAhI\n7lH12Zo6JxhTdxtG3paq/TlYSSF7ud32xhm2+mraIzB3nK1aWvqO7Vk3499VfycAa7+ufdt+676x\nJTq/bx6E54baEoDfyk9tG4HXc+Dn/X97rbraBOrzQq6zL4FVdf5Sa6CN39vnNV9WTctZbe+OnjP2\nwOWDRHsfNXGt4qN5+7fHs3BLHqd0syfm+0b24tTurflo0XbeWwDZ7V9l49Zd3OfOY2XzU3j4jEGc\n//bfaDnLcL8ZzqeeoUz/OI5fZMSyaGtfUnypfBVxD/NaXognL5Lbi6/nq9i/UBbfkcSCteyK6kB6\nxUYKPr6bxI1T2dz+PBZ1vY0LZoywQZ1+P7x3va0i8tp/piltb2XUqnvhg99CTBJ/S3+NORtymNKq\nB+74NvakKi7bc6nnL+1Jb9cyACo++j2uzbOIOP1+e2KZ/i97RemKtP+gJ/7BuVJfaE9OxmtLIHs3\nwWsX2lJQdCJs/xn+29NewXU6FaISbLylBfZE99qv7Elw1rNw6t22/35FqV1Hcjc4/5maD0LgP/iO\nn2H2C/ZK8M/r7f7kV2vjyF5hG7d3Lbf7M+9l20mgWcvaD/SuFfDetYBzT4F/xN3KksIau67a7jnw\nl8R2LbPLBSYFsPv/5X22B9uKT2zVWq9f7r9MQjtbSux6hn3fuies/Mwu33EYxDSH3U7b0fKP7JXv\nKXfb0YCXf2iHnZ/yZ7j2C7v+Xcsgtb898W36wUkEYtflb5MK3CdPedX+Vn7fi+CLe+x3WDntZxh3\nKhQE3KCZ2N6WKgZdbau6xGXvTSncZeNM7gZJHWDK3baU030EJLSFFR9BUZat8un7K3uS//oBe1G0\ncTp0PXP/ePxVRik9bImweHdVqRkgpZfdn7Vf2dLroKttYjvxD1U3sGYtgdVfwNQ/Q2wLO237Qvud\ntOgU9B/j0qRwDEiIcXNq96qBAl0u4aRuyZzULZm/ntuL6MgIxv+0kazyfrwwLIOUhGg25BTzzHfr\n2Hz64zycmc4ni3fwxNdrGNalFSd368HxU56meEMM3VrHszYbTix5gqKSWDIki9zyRL6Iupe2G6dS\nktyPUZsupnj9Hk6LjmWTaUt66km0uH0h+LwUb5zLX95bwBeLUjknIZ6I/C1sHHg3k2fvASL4ad1u\nhrfpa5NC9xGY1VO5cfu5PNdyHdF7VlHgak6iLx8WToAN39mb/VZ8BK37QL/Rtp/9E72qvoy+o23J\n4sIXKJo7mbgt3yHH32oblb+4p6r9ICkdIiIxrfvAgglIaZ5NCENvgTkv2H/C7fNtSWTrHPsP3P9S\nyDjJ1k9HREP/S+wV5JovICYJouLtshumQ8U+eyKOb2O353QpJj7VngzfutwuFxlrG72Lc+CK9yAi\n4F+yfJ/dl94X2Cv1nIASxjanZ5i/OqU0H8aeBCMfh4wTYe039kTc8QQYcBms+couV7LXJoSiLJs4\nA4diCDyx7lpq77YHe2Iq2WuT/ce3VfX8ybzeluj2boTjb3WGaRFo1sperYMtNa6fBvNegogoewf5\n1D9Dx5Ng9nPQ9Sxb3eTX6zxoO9C2D+1cAhPOhQuetSW7Ny6x32FMUlUJZu9GG3fGyfak6r/AKNgO\nfS6y30HzDjDiEXj7Ctv2s3GGvUi48Tt4fbQ9CSe0g4teqDqBL5hgL078iWX283bdG6Y7ywj89LQt\n9fX9lf1FxdJ8WDipar9XfAT/dUqj/phT+9nkuOh1O92fCHavsYk/faj9G3rzUjvd32li1zLbWWTA\nGHsBEURimti4L5mZmWb+/PmhDqPJM8YwZ+MeBndsgTvCXnnsKS4nKdZNVkEpwx61dZ7PXn4cm3YX\n075FLBNmbmZAWnNen7OFvtE5tPDsYhHdKfC4ufGUzlBRyviZW6ggkpO7JXNGz9bMWJPDtNU5JDVz\n82jUeE52LeP4/H/SKimRPcXlnNmrDU+0nopn5nO8OPB9VqxYwue57Xg4ZjK/YQqXld9P94gs9jbL\n4CnvvxBPCQy8Ei58zl45LpzIsg3byF3+HadGLLH3bQwYw7zNe7l47Cz+eVFfrhjakYpNc3BPONv+\n03U+Dfr+mnErI/jsyy/5MOr/iDAV0O0cuGgs/LsrtMiw//zN02HQVfafPSYJht4En/zellKap9ke\nVz4P3hPvJGLvBlty8VeF9bnIJpHP/wTDfg/LP7ZX2QtetfMzTrb/7IOvsVVmQ34LJ99pry5bdrJV\naT+/Bv3HwJK37Il084/Q5XRbErlzFTwzyF7h+hNGxxNh1L/hhWFViSipo736HXCZvZfgivft9ozP\nnhDj29hkUpYPPUZB1jJ4xbkCjk+1d8vv3QQXT4DHO9np7jj4y3Z46TR7ZX7nSltK27XM/sCUv+da\n2wGwZ5PT+Gqg38VV7VExze2JtMco6DHSDtQ4ZrLd1rvXQLvj7LrjUmyJLcJtq8AGX2NP2u44217g\nctvtL37DHt/Jo+2d/aNfhf90hy6nwRXvwld/hZnP2GPn81R9n8f9xn7PsS1skm8/2G43faj9noff\nC9MDOlZ0PcvGtPgN+z4iGn5xgy295qyGYb+D4X+xiXHKn+09Rf4EdfY/IDIGptwF7QbZv6H4NjZp\nSgRc9bE9VsU5tjT79pXQuldVSe+aKTbpHwYRWWCMyTzocpoUVE0+XrSdTslx9E9LOmDe2/O20KFl\nHOVeHw98vIwTuiTzyK/6YYyh0322/j8hJpLCUg8JMZFcPqQD3dokcM+7C4lxeemZ3oaXrsrk31+u\n5v2F2/jLWZ2Y+O0CNpbbbcW4XbTx7ODetj8zo+0NDO+Vys2TF3Bf2wVcXfwqruum4G7Tk9IKH7FR\nEfzujYV8s2QTdyT9yJlX3ssnK/OYtiqbpdvz6ZmawDOXHcclz03j25aP0fLcB6HbWcxan8tlL9ku\ngqe0zGPSyGh7kk5ow4bPnyBt8VOUtD+RovNfol1SM2T5h071DZB+PGbHQsRbDj1G8VOW8KjrJj64\nuBXu8WfaKoZ+o+0JGPAltMN15wpbbbB5li1p9L+kqjrCFWGrLfwN9YGi4m2bR/MOcMuPtuG+YKc9\nabvctr3mlD/bRnu/1P62KuaOpc6Inffa0sY5/6w6qYM9URXvtsuP+FfVdGPg0Y42SQy9GUY8aqe5\nXLaNaN9um4juWGrvkN++0CZLv49utVfCp94DM5yr2gvH2gR60h9t1dfKT2yVyfppNo7AGx2zV8Hz\nQ+3rjifZKqu0IfZGS58H3LHwn2626mXhRPv5iydUfT5rqa36iUuGJe/YBJ8+xO7Dotdt+9fmH22C\nSEyD23+Gj26BTT/CWQ/ZLtuTLrDtFyfcZk/kBTtstV9CO2jT275fPRU6nGAb71d8bEtIo8dD5+FV\nsRTn2uTRdiBM/CVc96U9pmNPhEsn25KRz2d77qUPsR1MAhnnnp+nBtiqp1tnHd6wJGhSUA3IGIM4\nf6izN+RS7vExuGMLCkorSE2MQUTw+QznP/cj67OL+eqPp5Deshm5RWVc9PxMtuzZR5eUOM7t15ZZ\nG3K58eTOTJi5iZevzqRZlK1OeX3OZv7+6Qo8Hg/tWsRRUu4lt7icrq3jWZddRGJMJAWl+zf8DUhP\nYvHWPNonxbI9r4Q+7RI5uVsKGa2aMXHWZvL2lXPdiZ3455SVvHDFIE7unsKKHQVc9tJsvJVdKoUz\ne7XmxSsHE/HOFXg9FUzv/xg/fjQOl6eE4oE38NY8O7rtX0b15KbWq+yVbub1sPhNZixYyuO7Mpl4\n56+JcUcQHx3JroJS5m7cwy/7t6383vD57JXm7jX2KjRvsy2ZtB0In94O5z1V1YXWGFj6nq3icTeD\nob+11QzN02H8OXYdJ/7BnuDAVkO5Y+3JZNKF9o7k5mlw3BW21AQgwt8+WkbrhGh+f0Y321C+L9de\nwQeehKb82TboXv4udD+75j+I0gLbWyZtsB3yJGux/T4O5WS2ZY7t6Tbkt7YNIL61TZ5+S9+zJ+/1\n39k2iKQO9V+3387F9vtL7nZge0xZka3uqT4qQG0qSiEyuu59zF5l22HAJpXEdvVbtzG25NT/Enuz\n6mHSpKAandyiMvYUl9OtTULltO15JSzaksfZfdpUVmPVxuczfLNyFxNnbSItqRltk2J4bdZmcovL\n+ffo/qzOKqR9i1jO7d+W3KJy0lrE8vs3f2bJtnz6pzVn+uqq+vPoSBdPjTmOQR2SGPrItxgDgzok\nsXVvCfHRkfzn4v7sLipn0dY8Xpi+nmuGZdC7XSL//nI1OYVldGzVjIHpSXy8aAcJMZH0T2vOT+ty\nObFrK3q0SaRHajx5+yr43zdrKK3wkRAdSYXPx11n9+Dd+dtYvauQf13Uj8uHdmDm+t2MnbGBtokx\nXHtSBj1TE/fb76z8UorKPHRJiaPCa/jo5+0M75FC68QYjDFMnr2ZsTM2EO12cXKXltzZv4LmHfpB\nZFSN3+O01dl0SY6nQ6uqQQBXZxVyzpPf0zIuindvPgG3y7Xf/NIKL3uKy2ndzEWkSyAyioLSCrIL\nSunaOqGmzRwxj9fHf75awyeLtvPEpQM5vnOroGznUE1blc27C7by9JjjiDzI32xjoklBhYXiMg/T\nV+cwom8qEa7ar9Ly9pXzq+dnMmZIOpkZLenYshmt4u1AhFOX7mTp9nyen76exJhI3rtlGN2dxGWM\n4e+frmDCzE0AHNchiduGd2VY11Y0i4pkweY9iAi9UhN58ps1/LB2N2t2FeLxVf1fnTegHT+uzaFT\nchwLt+ThEuiRmsiaXYWc2j2Fmet30zzWTXGZl5IKL1cM7cDUZVnEuiMY1a8tL36/HmPstrumxPPu\ngm1ER7qIjnTRrU0CCzbvZUinliTGRDJjTQ7De7TG4/Vxeq82nNe/LZe9NIdfD2rP6MFpfLBwOw99\ntoJebRO5ZXgX3p63hc25+yit8LG7yPYUi3G7iI+O5Os/nkqz6Aie/W4dE2ZuorDUQ8/UBN6/ZRix\n7ghGj53Jsu0FTPnDSXRJiafc6yM60l7Nr91VyIw1OVx5fEdi3AFX+Ifg3flb+fN79o77Cwe248kx\nxx3WemqTlV+KwdC2eSywf4nX4/Xx6ZId7Cv3csXQjpWfKa3wcsZ/Z7A9r4SxVw5mRN/UGtcduK66\n7Mwv4TevzOWhC/owrEvyQZc/EpoUlKrmYP+o7y3YRs/UBPq2b37A5z5dspMIEUb1Sz3oP/vWPfvI\nLiylqMxLVn4Jl2Sm4zPgElibXUR0pIukZlH87+s1zFiTQ5eUeB79dT8iXcINE+czf/NeBndsQVZ+\nKdvzSsjs2IJz+7fl+enrySks45w+bWidEEN+SQWfL93JjSd35p4RPRARHpm6khdnVPXxT02MIaug\nFHeE4I5wsa/cW1mdBtA5OY4B6Uls27uPzIyWjPt+A16fIcIlDOqQRGGph1VZhZzbry390prz2Ber\nOKVbCu2SYnhz7laiIlx0aR1PWotY5mzI5enLjiPWHcENE+dTWOYhOT6K6MgIerVN4Jf929GtTTxd\nW8fz1fJdLNuez6bcYtJbNOOcvqk8+906OiXHMX/zHk7qmsLUZTuJi4qkT7tEvliWxdOXH8dXy7O4\n6oQMerVNZOGWvewr8/LRou1cdFx7Nu4upkdqAr/IqKNrL/Dtyl1szt3Hs9PWkdTMzaTrhnDn24uJ\ndruYdN0Qyjw+bpw0nx/W2u6lk64bwilO774XZ6znkamrSIiOpE/7RN688fgD/h5e/mEDT32zlsuH\nduCW4V1IalZziQ3gbx8t47XZm+nTLpHPfn9SrX9bXp/hsS9WMbJvKsd1aFHn/tVGk4JSTVBhaQXT\nVucwsm8qm3YX89y0ddw9oiftkmLJ21fOp4t3cNGgNOKjbVtLaYV3vyvxvcXljB47kyuP70iZx8cb\nc7bwq0HteXf+NjqnxHHr8K4M7tiCW19fSFqLWP56bq/9qkB++9p8Il0uhvdI4R+fr8QdITz6q/6c\n2dt2rX35hw3856vVlHt8XPqLdM7uncrv3/yZojIP7ZNi2ZFfQnSki/ZJsdwyvCvTVmcT6RLmbtzD\nznw7yF2LZm727qsgKsJFestYtuzZR4XXEB3poszjo0ebBFbvKiQqwsWLV9lf6L321arh2Du2asY5\nfVIZ931V8otxuyit8OES+Pv5fSgu9zJx5iYGdWxBSnw0reKiuPC49ojAWU98T0mFFxFbXd+imZu8\nkgqMgScuGcAbc7Ywf/NeHjyvN5Nmb6bC6+PLO06hrMLHKf+eRmbHFpzYNZl/fL6S607sxF/P7cXG\n3GI+WbSDpGZu/v7pCrq3iWdtdhHNY928d/MwuraOrzxeK3YWkJYUi9cYTn18Om2TYticu4+xVw5i\nRN+2lctFR7oo9/owBu58ZxFTlmbxhzO68cezuh/W35YmBaXCVE0lIv/V/6F8vszjxSVyQFtPcZmH\n0gpvZfXbzvwStu21DfmPTl3Fgs17efnqzMpqGbDVMauyCpm5fjdfLMvi1uFdObVHCu4IF3M37uGZ\n79Zy38hedGzVjLjoSPL2lRMZYauxKrw+nvxmDd3bJJAcH83V4+fi8Rl+Nag9I/u2Jcbt4roJ8/hF\nRkti3RF8u8qOLTUwPYlFW/MqT/5A5Xfw9Jjj6NCyGZe/PJvCUg8v/mYwd727mMJSD4kxkTx8YV8u\nGNieORtyuXTcbM7t15Yd+SUs3prH1D+cQrfW8Tz0ma1WPLNXa5Zsyye70Fa/ndQ1mYnXDWF1ViGX\nvTSb+OhISiq8XHl8R179aSOFpR5cAj2dKsRv/3Qq102wSe/kbinER0fy8o8b6NbaJscIEUoqvNw/\nqpft+n2YNCkopY5JuwpKKff4SG9Z1RC+JXcfrROjEYF/fLaSHqkJXDG0Az+u202LZlGUVnhZm13E\ntyuzGZDW3PawAt6au4XCUg83ntKZybM3s3DLXu4Z0ZM2iVVdZB/+bAWv/LiRpGZuHrqgL+cPsL2G\njDE88906np++jpSEaK4c2pHpq3N4cszAys9/+PM2/vj2YlISoskpLKNnagK3n9GN12ZtZtaGXC7N\nTOex0f35bMkOfvfGz7gEfAZ6t02kuNxD33bNiXAJI/qmMqpf4E/aHzpNCkopdZTk7SunWVQkUZGH\n3tuooLSCco+PSbM2c9UJHUmOjyZvXzljZ2zguhMzaJ0Yg89n+ODn7Qzt1JL8kgq6tYmvbLQ/WjQp\nKKWUqlTfpNB0OtkqpZQKOk0KSimlKmlSUEopVUmTglJKqUqaFJRSSlXSpKCUUqqSJgWllFKVNCko\npZSq1ORuXhORHGDzYX48Gdh9FMMJJd2Xxkn3pXHSfYGOxpiUgy3U5JLCkRCR+fW5o68p0H1pnHRf\nGifdl/rT6iOllFKVNCkopZSqFG5JYVyoAziKdF8aJ92Xxkn3pZ7Cqk1BKaVU3cKtpKCUUqoOmhSU\nUkpVCpukICIjRGS1iKwTkXtDHc+hEpFNIrJURBaJyHxnWksR+VpE1jrPLUIdZ01EZLyIZIvIsoBp\nNcYu1tPOcVoiIoNCF/mBatmXB0Vku3NsFonIqIB59zn7slpEzglN1AcSkXQRmSYiK0RkuYj8wZne\n5I5LHfvSFI9LjIjMFZHFzr783ZneSUTmODG/LSJRzvRo5/06Z37GEQdhjDnmH0AEsB7oDEQBi4He\noY7rEPdhE5BcbdrjwL3O63uBx0IdZy2xnwIMApYdLHZgFDAVEOB4YE6o46/HvjwI3FXDsr2dv7Vo\noJPzNxgR6n1wYmsLDHJeJwBrnHib3HGpY1+a4nERIN557QbmON/3O8AYZ/pY4Bbn9a3AWOf1GODt\nI40hXEoKQ4B1xpgNxphy4C3gghDHdDRcAEx0Xk8ELgxhLLUyxnwP7Kk2ubbYLwAmGWs2kCQiR/aL\n5UdRLftSmwuAt4wxZcaYjcA67N9iyBljdhpjFjqvC4GVQHua4HGpY19q05iPizHGFDlv3c7DAKcD\n7znTqx8X//F6DzhDRORIYgiXpNAe2Brwfht1/9E0Rgb4SkQWiMhNzrQ2xpidzussoE1oQjsstcXe\nVI/V75xqlfEB1XhNYl+cKofjsFelTfq4VNsXaILHRUQiRGQRkA18jS3J5BljPM4igfFW7oszPx9o\ndSTbD5ekcCw4yRgzCBgJ3CYipwTONLb82CT7Fzfl2B0vAF2AgcBO4L+hDaf+RCQeeB+4wxhTEDiv\nqR2XGvalSR4XY4zXGDMQSMOWYHo25PbDJSlsB9ID3qc505oMY8x25zkb+BD7x7LLX4R3nrNDF+Eh\nqy32JnesjDG7nH9kH/ASVVURjXpfRMSNPYm+boz5wJncJI9LTfvSVI+LnzEmD5gGnICtrot0ZgXG\nW7kvzvzmQO6RbDdcksI8oJvTgh+FbZD5JMQx1ZuIxIlIgv81cDawDLsPVzuLXQ18HJoID0ttsX8C\nXOX0djkeyA+ozmiUqtWtX4Q9NmD3ZYzTQ6QT0A2Y29Dx1cSpd34FWGmMeSJgVpM7LrXtSxM9Liki\nkuS8jgXOwraRTANGO4tVPy7+4zUa+M4p4R2+ULe2N9QD23tiDbZ+7v5Qx3OIsXfG9pZYDCz3x4+t\nO/wWWAt8A7QMday1xP8mtvhega0Pvb622LG9L55zjtNSIDPU8ddjX15zYl3i/JO2DVj+fmdfVgMj\nQx1/QFwnYauGlgCLnMeopnhc6tiXpnhc+gM/OzEvA/7Pmd4Zm7jWAe8C0c70GOf9Omd+5yONQYe5\nUEopVSlcqo+UUkrVgyYFpZRSlTQpKKWUqqRJQSmlVCVNCkoppSppUlCqGhHxBoysuUiO4qi6IpIR\nOMKqUo1N5MEXUSrslBg7zIBSYUdLCkrVk9jftHhc7O9azBWRrs70DBH5zhl47VsR6eBMbyMiHzpj\n4y8WkWHOqiJE5CVnvPyvnDtXlWoUNCkodaDYatVHlwbMyzfG9AOeBZ50pj0DTDTG9AdeB552pj8N\nzDDGDMD+BsNyZ3o34DljTB8gD/h1kPdHqXrTO5qVqkZEiowx8TVM3wScbozZ4AzAlmWMaSUiu7FD\nKFQ403caY5JFJAdIM8aUBawjA/jaGNPNeX8P4DbG/CP4e6bUwWlJQalDY2p5fSjKAl570bY91Yho\nUlDq0Fwa8DzLeT0TO/IuwBXAD87rb4FboPKHU5o3VJBKHS69QlHqQLHOL1/5fWGM8XdLbSEiS7BX\n+5c5034PvCoifwZygOVPRbgAAABYSURBVGud6X8AxonI9dgSwS3YEVaVarS0TUGpenLaFDKNMbtD\nHYtSwaLVR0oppSppSUEppVQlLSkopZSqpElBKaVUJU0KSimlKmlSUEopVUmTglJKqUr/D3/T0NeF\nChaUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N14_-C010qeD",
        "outputId": "3ca9c5ca-3793-4e8e-ce19-b4ccc68f544c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ts_x=np.array(ts_x).reshape(ts_x.shape[0],7,1)\n",
        "results1=model.evaluate(ts_x, ts_y, batch_size=32)\n",
        "print('\\nm=3, test=C\\n test loss: {}\\n  test acc: {}'.format(results1[0],results1[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "138/138 [==============================] - 0s 1ms/sample - loss: 0.4039 - acc: 0.8696\n",
            "\n",
            "m=3, test=C\n",
            " test loss: 0.40389979069215665\n",
            "  test acc: 0.8695651888847351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q9gBF63g0qeF",
        "outputId": "ddfb0643-4fbf-4a8e-8dbf-2411537f38e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ts_x2=np.array(ts_x2).reshape(ts_x2.shape[0],7,1)\n",
        "results2=model.evaluate(ts_x2, ts_y2, batch_size=32)\n",
        "print('\\nm=3, test=D\\n test loss: {}\\n  test acc: {}'.format(results2[0],results2[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104/104 [==============================] - 0s 1ms/sample - loss: 0.2331 - acc: 0.9712\n",
            "\n",
            "m=3, test=D\n",
            " test loss: 0.23311538650439337\n",
            "  test acc: 0.9711538553237915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sFYFLr6u0qeH",
        "colab": {}
      },
      "source": [
        "## check where model did not predict correctly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5zto9F3RQL6",
        "colab_type": "code",
        "outputId": "7fa22b26-bfa5-4af0-c2f6-2b214591da5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "_, _, ts_x_df, ts_y_lbl, ts_x2_df, ts_y2_lbl = generate_tr_ts(df1=central, df2=site, m=3, method=None, h=3000, seed=2019, normalize=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-f4c44fa2fe30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_x_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_y_lbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_x2_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_y2_lbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_tr_ts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcentral\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2019\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: generate_tr_ts() got an unexpected keyword argument 'normalize'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt61WyvfRQL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction(encoder, model, test_x):\n",
        "    pred=model.predict(test_x)\n",
        "    return encoder.inverse_transform(np.round(pred))\n",
        "def return_predict(encoder, model, test_x, test_y):\n",
        "    pred=prediction(encoder, model, test_x)\n",
        "    results=[pred==true for pred, true in list(zip(pred,test_y))]\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-sA6a81RQL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts_x_df['Label']=ts_y_lbl['TRGRESP']\n",
        "ts_x_df['Pred']=prediction(encoder, model, ts_x)\n",
        "ts_x_df['Correct']=return_predict(encoder, model, ts_x, ts_y_lbl['TRGRESP'])\n",
        "ts_x_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMav1ZBNRQMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts_x2_df['Label']=ts_y2_lbl['TRGRESP']\n",
        "ts_x2_df['Pred']=prediction(encoder, model, ts_x2)\n",
        "ts_x2_df['Correct']=return_predict(encoder, model, ts_x2, ts_y2_lbl['TRGRESP'])\n",
        "ts_x2_df"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}