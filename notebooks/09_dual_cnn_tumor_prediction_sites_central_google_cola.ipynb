{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/stomioka/phuse-tumor-ml/blob/master/07_dual_cnn_tumor_prediction_sites_central_google_cola.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eNny0V6f0qdU"
   },
   "source": [
    "# Response criteria prediction for tumor with parallel-CNN\n",
    "\n",
    "Sam Tomioka<br>\n",
    "2019-10-13\n",
    "\n",
    "Same data used in [notebook3](03-tumor_prediction-sites-central.ipynb) will be used here. \n",
    "\n",
    "- Model based on `central`+`site` with 85% of data from each. Test on remaining `central` assessments, Test on remaining `site` assessments independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "vvowRGjB0qdX",
    "outputId": "4b13d89b-711a-46fc-c841-2b1bc9db67dc"
   },
   "outputs": [],
   "source": [
    "#!pip install git+git://github.com/andirs/impyte.git\n",
    "#!pip install xgboost \n",
    "\n",
    "!git clone https://github.com/stomioka/phuse-tumor-ml.git\n",
    "!pip install git+git://github.com/andirs/impyte.git\n",
    "!mv phuse-tumor-ml phuse_tumor_ml\n",
    "import os\n",
    "#os.chdir('phuse_tumor_ml/notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "sFHjN5wH0qdb",
    "outputId": "49cff90b-5323-48a2-cadd-ab0fd4989594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 1.14.0\n",
      "sklearn version: 0.21.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from lib.myutil import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.train import *\n",
    "print('tensorflow version: {}'.format(tf.__version__))\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score,roc_curve, auc\n",
    "print('sklearn version: {}'.format(sklearn.__version__))\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "#tf.keras.backend.clear_session() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bW6oQ5SN0qdj"
   },
   "outputs": [],
   "source": [
    "central, site=load_data()\n",
    "\n",
    "tr_x, tr_y, ts_x, ts_y, ts_x2, ts_y2 = generate_tr_ts(df1=central, df2=site, m=4, method=None, h=3000, seed=2019, normalize=False,scaling_method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzaj0m-n0qdo"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "tr_y = encoder.fit_transform(tr_y)\n",
    "ts_y = encoder.fit_transform(ts_y)\n",
    "ts_y2 = encoder.fit_transform(ts_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7xnzgFYj0qd0",
    "outputId": "d20bd2f3-5f61-4ebf-bbd8-603043d42535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tr_x.shape, tr_y.shape\n",
    "x_train, x_vl, y_train, y_vl = train_test_split(tr_x, tr_y, test_size=0.20, random_state=2019)\n",
    "print()\n",
    "x_train=np.array(x_train).reshape(x_train.shape[0],7,1)\n",
    "#y_train=np.array(y_train).reshape(y_train.shape[0],5,1)\n",
    "x_vl=np.array(x_vl).reshape(x_vl.shape[0],7,1)\n",
    "#y_vl=np.array(y_vl).reshape(y_vl.shape[0],5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "WnTEmXDl0qd4",
    "outputId": "34caf640-360d-4f1e-d2b8-b29bded91df5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "recest (InputLayer)             [(None, 7, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "1Dconv_1 (Conv1D)               (None, 5, 64)        256         recest[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "2Dconv_1 (Conv1D)               (None, 5, 128)       512         recest[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "1Dconv_2 (Conv1D)               (None, 3, 64)        12352       1Dconv_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "2Dconv_2 (Conv1D)               (None, 3, 128)       49280       2Dconv_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "1Dropout (Dropout)              (None, 3, 64)        0           1Dconv_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "2Dropout (Dropout)              (None, 3, 128)       0           2Dconv_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "1maxpool (MaxPooling1D)         (None, 1, 64)        0           1Dropout[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "2maxpool (MaxPooling1D)         (None, 1, 128)       0           2Dropout[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           1maxpool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           2maxpool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "1out (Dense)                    (None, 64)           4160        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "2out (Dense)                    (None, 64)           8256        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64)           0           1out[0][0]                       \n",
      "                                                                 2out[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pred (Dense)                    (None, 5)            325         flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 79,301\n",
      "Trainable params: 79,301\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() \n",
    "i = Input(shape=(7,1),name='recest')\n",
    "\n",
    "x0 = Conv1D(64, 3, activation='relu', name='1Dconv_1')(i)\n",
    "x0 = Conv1D(64, 3, activation='relu', name='1Dconv_2')(x0)\n",
    "x0 = Dropout(0.5, name='1Dropout')(x0)\n",
    "x0 = MaxPooling1D(pool_size=2, name='1maxpool')(x0)\n",
    "x0 = Flatten()(x0)\n",
    "x0 = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='1out')(x0)\n",
    "\n",
    "x1 = Conv1D(128, 3, activation='relu', name='2Dconv_1')(i)\n",
    "x1 = Conv1D(128, 3, activation='relu', name='2Dconv_2')(x1)\n",
    "x1 = Dropout(0.5, name='2Dropout')(x1)\n",
    "x1 = MaxPooling1D(pool_size=2, name='2maxpool')(x1)\n",
    "x1 = Flatten()(x1)\n",
    "x1 = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='2out')(x1)\n",
    "\n",
    "\n",
    "#x1 = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='dense_2')(i)\n",
    "x2 = Add()([x0, x1])\n",
    "x2 = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='dense_1')(x2)\n",
    "#x2 = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='dense_2')(x2)\n",
    "#x2 = Dense(16, activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='dense_3')(x2)\n",
    "x2 = Flatten()(x2)\n",
    "outputs = Dense(5, activation='softmax', name='pred')(x2)\n",
    "\n",
    "model = Model(i, outputs)\n",
    "opt = AdamOptimizer(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SUsrNxCS0qd8",
    "outputId": "9c0823d2-e198-4225-f2b9-db9850fd1eb0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1027 22:59:24.803376 140550692259648 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 515 samples, validate on 129 samples\n",
      "Epoch 1/500\n",
      "515/515 [==============================] - 3s 6ms/sample - loss: 5.4481 - acc: 0.5068 - val_loss: 3.1595 - val_acc: 0.6589\n",
      "Epoch 2/500\n",
      "515/515 [==============================] - 0s 823us/sample - loss: 3.5052 - acc: 0.6447 - val_loss: 2.7730 - val_acc: 0.7519\n",
      "Epoch 3/500\n",
      "515/515 [==============================] - 0s 782us/sample - loss: 3.1534 - acc: 0.6816 - val_loss: 2.6803 - val_acc: 0.7364\n",
      "Epoch 4/500\n",
      "515/515 [==============================] - 0s 778us/sample - loss: 2.9871 - acc: 0.7184 - val_loss: 2.4982 - val_acc: 0.7442\n",
      "Epoch 5/500\n",
      "515/515 [==============================] - 0s 745us/sample - loss: 2.8474 - acc: 0.7029 - val_loss: 2.4180 - val_acc: 0.7674\n",
      "Epoch 6/500\n",
      "515/515 [==============================] - 0s 814us/sample - loss: 2.7703 - acc: 0.7049 - val_loss: 2.3507 - val_acc: 0.7597\n",
      "Epoch 7/500\n",
      "515/515 [==============================] - 0s 868us/sample - loss: 2.6644 - acc: 0.7184 - val_loss: 2.2814 - val_acc: 0.7442\n",
      "Epoch 8/500\n",
      "515/515 [==============================] - 0s 842us/sample - loss: 2.6729 - acc: 0.6777 - val_loss: 2.2221 - val_acc: 0.7442\n",
      "Epoch 9/500\n",
      "515/515 [==============================] - 0s 767us/sample - loss: 2.4943 - acc: 0.7379 - val_loss: 2.1674 - val_acc: 0.7442\n",
      "Epoch 10/500\n",
      "515/515 [==============================] - 0s 806us/sample - loss: 2.3746 - acc: 0.7495 - val_loss: 2.0941 - val_acc: 0.7752\n",
      "Epoch 11/500\n",
      "515/515 [==============================] - 0s 954us/sample - loss: 2.2819 - acc: 0.7553 - val_loss: 2.0015 - val_acc: 0.8062\n",
      "Epoch 12/500\n",
      "515/515 [==============================] - 0s 878us/sample - loss: 2.2703 - acc: 0.7573 - val_loss: 1.9195 - val_acc: 0.8217\n",
      "Epoch 13/500\n",
      "515/515 [==============================] - 0s 903us/sample - loss: 2.2082 - acc: 0.7728 - val_loss: 1.9423 - val_acc: 0.8062\n",
      "Epoch 14/500\n",
      "515/515 [==============================] - 0s 752us/sample - loss: 2.1294 - acc: 0.7786 - val_loss: 1.8827 - val_acc: 0.8527\n",
      "Epoch 15/500\n",
      "515/515 [==============================] - 0s 774us/sample - loss: 2.0716 - acc: 0.7359 - val_loss: 1.6149 - val_acc: 0.8140\n",
      "Epoch 16/500\n",
      "515/515 [==============================] - 0s 866us/sample - loss: 2.1781 - acc: 0.6796 - val_loss: 1.8683 - val_acc: 0.8372\n",
      "Epoch 17/500\n",
      "515/515 [==============================] - 0s 794us/sample - loss: 1.9401 - acc: 0.7709 - val_loss: 1.5609 - val_acc: 0.8372\n",
      "Epoch 18/500\n",
      "515/515 [==============================] - 0s 773us/sample - loss: 2.0750 - acc: 0.7184 - val_loss: 1.8745 - val_acc: 0.8450\n",
      "Epoch 19/500\n",
      "515/515 [==============================] - 0s 834us/sample - loss: 1.8318 - acc: 0.7786 - val_loss: 1.4399 - val_acc: 0.8372\n",
      "Epoch 20/500\n",
      "515/515 [==============================] - 0s 815us/sample - loss: 1.6292 - acc: 0.7786 - val_loss: 1.4178 - val_acc: 0.8992\n",
      "Epoch 21/500\n",
      "515/515 [==============================] - 0s 843us/sample - loss: 1.5745 - acc: 0.7883 - val_loss: 1.4580 - val_acc: 0.8295\n",
      "Epoch 22/500\n",
      "515/515 [==============================] - 0s 754us/sample - loss: 1.5357 - acc: 0.8000 - val_loss: 1.3955 - val_acc: 0.8915\n",
      "Epoch 23/500\n",
      "515/515 [==============================] - 0s 827us/sample - loss: 1.3541 - acc: 0.8408 - val_loss: 1.3388 - val_acc: 0.9070\n",
      "Epoch 24/500\n",
      "515/515 [==============================] - 0s 750us/sample - loss: 1.2923 - acc: 0.8544 - val_loss: 1.3309 - val_acc: 0.8760\n",
      "Epoch 25/500\n",
      "515/515 [==============================] - 0s 763us/sample - loss: 1.4375 - acc: 0.7728 - val_loss: 1.3587 - val_acc: 0.8450\n",
      "Epoch 26/500\n",
      "515/515 [==============================] - 0s 769us/sample - loss: 1.3098 - acc: 0.8466 - val_loss: 1.3384 - val_acc: 0.8527\n",
      "Epoch 27/500\n",
      "515/515 [==============================] - 0s 847us/sample - loss: 1.2172 - acc: 0.8505 - val_loss: 1.2687 - val_acc: 0.8837\n",
      "Epoch 28/500\n",
      "515/515 [==============================] - 0s 836us/sample - loss: 1.1863 - acc: 0.8621 - val_loss: 1.2361 - val_acc: 0.8837\n",
      "Epoch 29/500\n",
      "515/515 [==============================] - 0s 785us/sample - loss: 1.1531 - acc: 0.8485 - val_loss: 1.2184 - val_acc: 0.8992\n",
      "Epoch 30/500\n",
      "515/515 [==============================] - 0s 823us/sample - loss: 1.1437 - acc: 0.8466 - val_loss: 1.2264 - val_acc: 0.8527\n",
      "Epoch 31/500\n",
      "515/515 [==============================] - 0s 774us/sample - loss: 1.1554 - acc: 0.8330 - val_loss: 1.1548 - val_acc: 0.8760\n",
      "Epoch 32/500\n",
      "515/515 [==============================] - 0s 849us/sample - loss: 1.1478 - acc: 0.8427 - val_loss: 1.1512 - val_acc: 0.8915\n",
      "Epoch 33/500\n",
      "515/515 [==============================] - 0s 759us/sample - loss: 1.0429 - acc: 0.8524 - val_loss: 1.1692 - val_acc: 0.8450\n",
      "Epoch 34/500\n",
      "515/515 [==============================] - 0s 806us/sample - loss: 1.0842 - acc: 0.8641 - val_loss: 1.1319 - val_acc: 0.8837\n",
      "Epoch 35/500\n",
      "515/515 [==============================] - 0s 772us/sample - loss: 1.0003 - acc: 0.8816 - val_loss: 1.0886 - val_acc: 0.8837\n",
      "Epoch 36/500\n",
      "515/515 [==============================] - 0s 855us/sample - loss: 0.9907 - acc: 0.8447 - val_loss: 1.0668 - val_acc: 0.8605\n",
      "Epoch 37/500\n",
      "515/515 [==============================] - 0s 756us/sample - loss: 1.0008 - acc: 0.8641 - val_loss: 1.0587 - val_acc: 0.8760\n",
      "Epoch 38/500\n",
      "515/515 [==============================] - 0s 698us/sample - loss: 0.9868 - acc: 0.8680 - val_loss: 1.0810 - val_acc: 0.8605\n",
      "Epoch 39/500\n",
      "515/515 [==============================] - 0s 839us/sample - loss: 0.9124 - acc: 0.8680 - val_loss: 1.0101 - val_acc: 0.8915\n",
      "Epoch 40/500\n",
      "515/515 [==============================] - 0s 806us/sample - loss: 0.9405 - acc: 0.8641 - val_loss: 0.9878 - val_acc: 0.8837\n",
      "Epoch 41/500\n",
      "515/515 [==============================] - 0s 754us/sample - loss: 0.9321 - acc: 0.8641 - val_loss: 0.9862 - val_acc: 0.8915\n",
      "Epoch 42/500\n",
      "515/515 [==============================] - 0s 807us/sample - loss: 0.8946 - acc: 0.8680 - val_loss: 0.9378 - val_acc: 0.8682\n",
      "Epoch 43/500\n",
      "515/515 [==============================] - 0s 807us/sample - loss: 0.9211 - acc: 0.8602 - val_loss: 0.9629 - val_acc: 0.8760\n",
      "Epoch 44/500\n",
      "515/515 [==============================] - 0s 869us/sample - loss: 0.8648 - acc: 0.8660 - val_loss: 0.9293 - val_acc: 0.8605\n",
      "Epoch 45/500\n",
      "515/515 [==============================] - 0s 836us/sample - loss: 0.8428 - acc: 0.8796 - val_loss: 0.9064 - val_acc: 0.8992\n",
      "Epoch 46/500\n",
      "515/515 [==============================] - 0s 789us/sample - loss: 0.8339 - acc: 0.8660 - val_loss: 0.8955 - val_acc: 0.8992\n",
      "Epoch 47/500\n",
      "515/515 [==============================] - 0s 803us/sample - loss: 0.8518 - acc: 0.8621 - val_loss: 0.8745 - val_acc: 0.8682\n",
      "Epoch 48/500\n",
      "515/515 [==============================] - 0s 901us/sample - loss: 0.7889 - acc: 0.8913 - val_loss: 0.8708 - val_acc: 0.8527\n",
      "Epoch 49/500\n",
      "515/515 [==============================] - 0s 721us/sample - loss: 0.8091 - acc: 0.8738 - val_loss: 0.8502 - val_acc: 0.8915\n",
      "Epoch 50/500\n",
      "515/515 [==============================] - 0s 787us/sample - loss: 0.8088 - acc: 0.8621 - val_loss: 0.8381 - val_acc: 0.9070\n",
      "Epoch 51/500\n",
      "515/515 [==============================] - 0s 827us/sample - loss: 0.7854 - acc: 0.8699 - val_loss: 0.8226 - val_acc: 0.9070\n",
      "Epoch 52/500\n",
      "515/515 [==============================] - 0s 716us/sample - loss: 0.7537 - acc: 0.8718 - val_loss: 0.8039 - val_acc: 0.8915\n",
      "Epoch 53/500\n",
      "515/515 [==============================] - 0s 698us/sample - loss: 0.7603 - acc: 0.8660 - val_loss: 0.7942 - val_acc: 0.9070\n",
      "Epoch 54/500\n",
      "515/515 [==============================] - 0s 706us/sample - loss: 0.7073 - acc: 0.8835 - val_loss: 0.7793 - val_acc: 0.8760\n",
      "Epoch 55/500\n",
      "515/515 [==============================] - 0s 782us/sample - loss: 0.7532 - acc: 0.8563 - val_loss: 0.7969 - val_acc: 0.8682\n",
      "Epoch 56/500\n",
      "515/515 [==============================] - 0s 808us/sample - loss: 0.7179 - acc: 0.8699 - val_loss: 0.7724 - val_acc: 0.8682\n",
      "Epoch 57/500\n",
      "515/515 [==============================] - 0s 847us/sample - loss: 0.6942 - acc: 0.8816 - val_loss: 0.7807 - val_acc: 0.8605\n",
      "Epoch 58/500\n",
      "515/515 [==============================] - 0s 886us/sample - loss: 0.6868 - acc: 0.8738 - val_loss: 0.7454 - val_acc: 0.8837\n",
      "Epoch 59/500\n",
      "515/515 [==============================] - 0s 853us/sample - loss: 0.7397 - acc: 0.8563 - val_loss: 0.7601 - val_acc: 0.8527\n",
      "Epoch 60/500\n",
      "515/515 [==============================] - 0s 813us/sample - loss: 0.6934 - acc: 0.8680 - val_loss: 0.7393 - val_acc: 0.8760\n",
      "Epoch 61/500\n",
      "515/515 [==============================] - 0s 815us/sample - loss: 0.6547 - acc: 0.8835 - val_loss: 0.7283 - val_acc: 0.8605\n",
      "Epoch 62/500\n",
      "515/515 [==============================] - 0s 830us/sample - loss: 0.6376 - acc: 0.8718 - val_loss: 0.7543 - val_acc: 0.8527\n",
      "Epoch 63/500\n",
      "515/515 [==============================] - 0s 799us/sample - loss: 0.6815 - acc: 0.8505 - val_loss: 0.6875 - val_acc: 0.8992\n",
      "Epoch 64/500\n",
      "515/515 [==============================] - 0s 740us/sample - loss: 0.6305 - acc: 0.8718 - val_loss: 0.6621 - val_acc: 0.8915\n",
      "Epoch 65/500\n",
      "515/515 [==============================] - 0s 877us/sample - loss: 0.6436 - acc: 0.8757 - val_loss: 0.6793 - val_acc: 0.8915\n",
      "Epoch 66/500\n",
      "515/515 [==============================] - 0s 899us/sample - loss: 0.6422 - acc: 0.8835 - val_loss: 0.6928 - val_acc: 0.8760\n",
      "Epoch 67/500\n",
      "515/515 [==============================] - 0s 761us/sample - loss: 0.6163 - acc: 0.8796 - val_loss: 0.6888 - val_acc: 0.8992\n",
      "Epoch 68/500\n",
      "515/515 [==============================] - 0s 748us/sample - loss: 0.6144 - acc: 0.8718 - val_loss: 0.6748 - val_acc: 0.8915\n",
      "Epoch 69/500\n",
      "515/515 [==============================] - 0s 781us/sample - loss: 0.6403 - acc: 0.8874 - val_loss: 0.7094 - val_acc: 0.8682\n",
      "Epoch 70/500\n",
      "515/515 [==============================] - 0s 662us/sample - loss: 0.6317 - acc: 0.8583 - val_loss: 0.6786 - val_acc: 0.8760\n",
      "Epoch 71/500\n",
      "515/515 [==============================] - 0s 741us/sample - loss: 0.6185 - acc: 0.8835 - val_loss: 0.6356 - val_acc: 0.9070\n",
      "Epoch 72/500\n",
      "515/515 [==============================] - 0s 853us/sample - loss: 0.5690 - acc: 0.8816 - val_loss: 0.6495 - val_acc: 0.8837\n",
      "Epoch 73/500\n",
      "515/515 [==============================] - 0s 768us/sample - loss: 0.5735 - acc: 0.8699 - val_loss: 0.6110 - val_acc: 0.9070\n",
      "Epoch 74/500\n",
      "515/515 [==============================] - 0s 743us/sample - loss: 0.5463 - acc: 0.8874 - val_loss: 0.6714 - val_acc: 0.8217\n",
      "Epoch 75/500\n",
      "515/515 [==============================] - 0s 828us/sample - loss: 0.6168 - acc: 0.8602 - val_loss: 0.6724 - val_acc: 0.8605\n",
      "Epoch 76/500\n",
      "515/515 [==============================] - 0s 787us/sample - loss: 0.6442 - acc: 0.8544 - val_loss: 0.6997 - val_acc: 0.8760\n",
      "Epoch 77/500\n",
      "515/515 [==============================] - 0s 717us/sample - loss: 0.5862 - acc: 0.8699 - val_loss: 0.6685 - val_acc: 0.8992\n",
      "Epoch 78/500\n",
      "515/515 [==============================] - 0s 817us/sample - loss: 0.5775 - acc: 0.8583 - val_loss: 0.6116 - val_acc: 0.9070\n",
      "Epoch 79/500\n",
      "515/515 [==============================] - 0s 779us/sample - loss: 0.6533 - acc: 0.8757 - val_loss: 0.6338 - val_acc: 0.8915\n",
      "Epoch 80/500\n",
      "515/515 [==============================] - 0s 859us/sample - loss: 0.5733 - acc: 0.8718 - val_loss: 0.6091 - val_acc: 0.8760\n",
      "Epoch 81/500\n",
      "515/515 [==============================] - 0s 870us/sample - loss: 0.5304 - acc: 0.8893 - val_loss: 0.6214 - val_acc: 0.8760\n",
      "Epoch 82/500\n",
      "515/515 [==============================] - 0s 738us/sample - loss: 0.5299 - acc: 0.8932 - val_loss: 0.6191 - val_acc: 0.8837\n",
      "Epoch 83/500\n",
      "515/515 [==============================] - 0s 791us/sample - loss: 0.5467 - acc: 0.8757 - val_loss: 0.6137 - val_acc: 0.8837\n",
      "Epoch 84/500\n",
      "515/515 [==============================] - 0s 887us/sample - loss: 0.5071 - acc: 0.8854 - val_loss: 0.6051 - val_acc: 0.8837\n",
      "Epoch 85/500\n",
      "515/515 [==============================] - 0s 806us/sample - loss: 0.5463 - acc: 0.8835 - val_loss: 0.6263 - val_acc: 0.8217\n",
      "Epoch 86/500\n",
      "515/515 [==============================] - 0s 733us/sample - loss: 0.6914 - acc: 0.8291 - val_loss: 0.7219 - val_acc: 0.8062\n",
      "Epoch 87/500\n",
      "515/515 [==============================] - 0s 830us/sample - loss: 0.6427 - acc: 0.8641 - val_loss: 0.7053 - val_acc: 0.8140\n",
      "Epoch 88/500\n",
      "515/515 [==============================] - 0s 693us/sample - loss: 0.5630 - acc: 0.8777 - val_loss: 0.6319 - val_acc: 0.8605\n",
      "Epoch 89/500\n",
      "515/515 [==============================] - 0s 874us/sample - loss: 0.5608 - acc: 0.8699 - val_loss: 0.5997 - val_acc: 0.8837\n",
      "Epoch 90/500\n",
      "515/515 [==============================] - 0s 866us/sample - loss: 0.5476 - acc: 0.8777 - val_loss: 0.5817 - val_acc: 0.8992\n",
      "Epoch 91/500\n",
      "515/515 [==============================] - 0s 854us/sample - loss: 0.5567 - acc: 0.8699 - val_loss: 0.5752 - val_acc: 0.8915\n",
      "Epoch 92/500\n",
      "515/515 [==============================] - 0s 899us/sample - loss: 0.5054 - acc: 0.8777 - val_loss: 0.5952 - val_acc: 0.8527\n",
      "Epoch 93/500\n",
      "515/515 [==============================] - 0s 858us/sample - loss: 0.5183 - acc: 0.8621 - val_loss: 0.5806 - val_acc: 0.8992\n",
      "Epoch 94/500\n",
      "515/515 [==============================] - 0s 772us/sample - loss: 0.5120 - acc: 0.8660 - val_loss: 0.5926 - val_acc: 0.8915\n",
      "Epoch 95/500\n",
      "515/515 [==============================] - 0s 800us/sample - loss: 0.4966 - acc: 0.8854 - val_loss: 0.5896 - val_acc: 0.8915\n",
      "Epoch 96/500\n",
      "515/515 [==============================] - 0s 856us/sample - loss: 0.4994 - acc: 0.8757 - val_loss: 0.5633 - val_acc: 0.9070\n",
      "Epoch 97/500\n",
      "515/515 [==============================] - 0s 866us/sample - loss: 0.4943 - acc: 0.8816 - val_loss: 0.5591 - val_acc: 0.8915\n",
      "Epoch 98/500\n",
      "515/515 [==============================] - 0s 828us/sample - loss: 0.4764 - acc: 0.8932 - val_loss: 0.5845 - val_acc: 0.8915\n",
      "Epoch 99/500\n",
      "515/515 [==============================] - 0s 774us/sample - loss: 0.4583 - acc: 0.8777 - val_loss: 0.5620 - val_acc: 0.8837\n",
      "Epoch 100/500\n",
      "515/515 [==============================] - 0s 767us/sample - loss: 0.4985 - acc: 0.8738 - val_loss: 0.5755 - val_acc: 0.8992\n",
      "Epoch 101/500\n",
      "515/515 [==============================] - 0s 812us/sample - loss: 0.4520 - acc: 0.8854 - val_loss: 0.5497 - val_acc: 0.8837\n",
      "Epoch 102/500\n",
      "515/515 [==============================] - 0s 819us/sample - loss: 0.4721 - acc: 0.8757 - val_loss: 0.5621 - val_acc: 0.9070\n",
      "Epoch 103/500\n",
      "515/515 [==============================] - 0s 711us/sample - loss: 0.4707 - acc: 0.8835 - val_loss: 0.5941 - val_acc: 0.8450\n",
      "Epoch 104/500\n",
      "515/515 [==============================] - 0s 810us/sample - loss: 0.4508 - acc: 0.8971 - val_loss: 0.5327 - val_acc: 0.8992\n",
      "Epoch 105/500\n",
      "515/515 [==============================] - 0s 726us/sample - loss: 0.4450 - acc: 0.8971 - val_loss: 0.5802 - val_acc: 0.8682\n",
      "Epoch 106/500\n",
      "515/515 [==============================] - 0s 756us/sample - loss: 0.4380 - acc: 0.8796 - val_loss: 0.5287 - val_acc: 0.8605\n",
      "Epoch 107/500\n",
      "515/515 [==============================] - 0s 829us/sample - loss: 0.4529 - acc: 0.8854 - val_loss: 0.5261 - val_acc: 0.8837\n",
      "Epoch 108/500\n",
      "515/515 [==============================] - 0s 783us/sample - loss: 0.4184 - acc: 0.8835 - val_loss: 0.5082 - val_acc: 0.8915\n",
      "Epoch 109/500\n",
      "515/515 [==============================] - 0s 794us/sample - loss: 0.4296 - acc: 0.8854 - val_loss: 0.5144 - val_acc: 0.8992\n",
      "Epoch 110/500\n",
      "515/515 [==============================] - 0s 685us/sample - loss: 0.4439 - acc: 0.8816 - val_loss: 0.5290 - val_acc: 0.8760\n",
      "Epoch 111/500\n",
      "515/515 [==============================] - 0s 751us/sample - loss: 0.4440 - acc: 0.8777 - val_loss: 0.4981 - val_acc: 0.9225\n",
      "Epoch 112/500\n",
      "515/515 [==============================] - 0s 798us/sample - loss: 0.4266 - acc: 0.8913 - val_loss: 0.5320 - val_acc: 0.8915\n",
      "Epoch 113/500\n",
      "515/515 [==============================] - 0s 892us/sample - loss: 0.4067 - acc: 0.8835 - val_loss: 0.5306 - val_acc: 0.8992\n",
      "Epoch 114/500\n",
      "515/515 [==============================] - 0s 938us/sample - loss: 0.4289 - acc: 0.8874 - val_loss: 0.5098 - val_acc: 0.8992\n",
      "Epoch 115/500\n",
      "515/515 [==============================] - 0s 922us/sample - loss: 0.4316 - acc: 0.8816 - val_loss: 0.4997 - val_acc: 0.8915\n",
      "Epoch 116/500\n",
      "515/515 [==============================] - 0s 824us/sample - loss: 0.4416 - acc: 0.8796 - val_loss: 0.5029 - val_acc: 0.9070\n",
      "Epoch 117/500\n",
      "515/515 [==============================] - 0s 749us/sample - loss: 0.4265 - acc: 0.8796 - val_loss: 0.5360 - val_acc: 0.8760\n",
      "Epoch 118/500\n",
      "515/515 [==============================] - 0s 734us/sample - loss: 0.4337 - acc: 0.8796 - val_loss: 0.4982 - val_acc: 0.8915\n",
      "Epoch 119/500\n",
      "515/515 [==============================] - 0s 821us/sample - loss: 0.4119 - acc: 0.8854 - val_loss: 0.5075 - val_acc: 0.8450\n",
      "Epoch 120/500\n",
      "515/515 [==============================] - 0s 809us/sample - loss: 0.4067 - acc: 0.8990 - val_loss: 0.4961 - val_acc: 0.8915\n",
      "Epoch 121/500\n",
      "515/515 [==============================] - 0s 844us/sample - loss: 0.4091 - acc: 0.8796 - val_loss: 0.4896 - val_acc: 0.8992\n",
      "Epoch 122/500\n",
      "515/515 [==============================] - 0s 817us/sample - loss: 0.4014 - acc: 0.8874 - val_loss: 0.5213 - val_acc: 0.8682\n",
      "Epoch 123/500\n",
      "515/515 [==============================] - 0s 778us/sample - loss: 0.4091 - acc: 0.8835 - val_loss: 0.4825 - val_acc: 0.8837\n",
      "Epoch 124/500\n",
      "515/515 [==============================] - 0s 821us/sample - loss: 0.4235 - acc: 0.8854 - val_loss: 0.5116 - val_acc: 0.8450\n",
      "Epoch 125/500\n",
      "515/515 [==============================] - 0s 819us/sample - loss: 0.4190 - acc: 0.8777 - val_loss: 0.4754 - val_acc: 0.9070\n",
      "Epoch 126/500\n",
      "515/515 [==============================] - 0s 903us/sample - loss: 0.3844 - acc: 0.8835 - val_loss: 0.4709 - val_acc: 0.8837\n",
      "Epoch 127/500\n",
      "515/515 [==============================] - 0s 865us/sample - loss: 0.3943 - acc: 0.8777 - val_loss: 0.4789 - val_acc: 0.8915\n",
      "Epoch 128/500\n",
      "515/515 [==============================] - 0s 878us/sample - loss: 0.3978 - acc: 0.8816 - val_loss: 0.4438 - val_acc: 0.9070\n",
      "Epoch 129/500\n",
      "515/515 [==============================] - 0s 838us/sample - loss: 0.3980 - acc: 0.8777 - val_loss: 0.4538 - val_acc: 0.8915\n",
      "Epoch 130/500\n",
      "515/515 [==============================] - 0s 873us/sample - loss: 0.3817 - acc: 0.8874 - val_loss: 0.4425 - val_acc: 0.8837\n",
      "Epoch 131/500\n",
      "515/515 [==============================] - 0s 791us/sample - loss: 0.3819 - acc: 0.8874 - val_loss: 0.4814 - val_acc: 0.8605\n",
      "Epoch 132/500\n",
      "515/515 [==============================] - 0s 806us/sample - loss: 0.4197 - acc: 0.8602 - val_loss: 0.4578 - val_acc: 0.8992\n",
      "Epoch 133/500\n",
      "515/515 [==============================] - 0s 760us/sample - loss: 0.3831 - acc: 0.8835 - val_loss: 0.4628 - val_acc: 0.8682\n",
      "Epoch 134/500\n",
      "515/515 [==============================] - 0s 747us/sample - loss: 0.3777 - acc: 0.8854 - val_loss: 0.4588 - val_acc: 0.9070\n",
      "Epoch 135/500\n",
      "515/515 [==============================] - 0s 815us/sample - loss: 0.4037 - acc: 0.8835 - val_loss: 0.4974 - val_acc: 0.8760\n",
      "Epoch 136/500\n",
      "515/515 [==============================] - 0s 759us/sample - loss: 0.3867 - acc: 0.8854 - val_loss: 0.4563 - val_acc: 0.8915\n",
      "Epoch 137/500\n",
      "515/515 [==============================] - 0s 819us/sample - loss: 0.3735 - acc: 0.8835 - val_loss: 0.4495 - val_acc: 0.8837\n",
      "Epoch 138/500\n",
      "515/515 [==============================] - 0s 773us/sample - loss: 0.3672 - acc: 0.8874 - val_loss: 0.4332 - val_acc: 0.9070\n",
      "Epoch 139/500\n",
      "515/515 [==============================] - 0s 905us/sample - loss: 0.3477 - acc: 0.8990 - val_loss: 0.4956 - val_acc: 0.8760\n",
      "Epoch 140/500\n",
      "515/515 [==============================] - 0s 807us/sample - loss: 0.4046 - acc: 0.8680 - val_loss: 0.4545 - val_acc: 0.8915\n",
      "Epoch 141/500\n",
      "515/515 [==============================] - 0s 758us/sample - loss: 0.3612 - acc: 0.8932 - val_loss: 0.4541 - val_acc: 0.8760\n",
      "Epoch 142/500\n",
      "515/515 [==============================] - 0s 763us/sample - loss: 0.3698 - acc: 0.8913 - val_loss: 0.4206 - val_acc: 0.8992\n",
      "Epoch 143/500\n",
      "515/515 [==============================] - 0s 813us/sample - loss: 0.3505 - acc: 0.8913 - val_loss: 0.4138 - val_acc: 0.9070\n",
      "Epoch 144/500\n",
      "515/515 [==============================] - 0s 805us/sample - loss: 0.3510 - acc: 0.8854 - val_loss: 0.4467 - val_acc: 0.8992\n",
      "Epoch 145/500\n",
      "515/515 [==============================] - 0s 745us/sample - loss: 0.3461 - acc: 0.8951 - val_loss: 0.4703 - val_acc: 0.9070\n",
      "Epoch 146/500\n",
      "515/515 [==============================] - 0s 774us/sample - loss: 0.3579 - acc: 0.8854 - val_loss: 0.4727 - val_acc: 0.8915\n",
      "Epoch 147/500\n",
      "515/515 [==============================] - 0s 759us/sample - loss: 0.3446 - acc: 0.8951 - val_loss: 0.4411 - val_acc: 0.8915\n",
      "Epoch 148/500\n",
      "515/515 [==============================] - 0s 797us/sample - loss: 0.3558 - acc: 0.8854 - val_loss: 0.4239 - val_acc: 0.8682\n",
      "Epoch 149/500\n",
      "515/515 [==============================] - 1s 1ms/sample - loss: 0.3613 - acc: 0.8874 - val_loss: 0.4341 - val_acc: 0.8992\n",
      "Epoch 150/500\n",
      "515/515 [==============================] - 1s 1ms/sample - loss: 0.3662 - acc: 0.8796 - val_loss: 0.4473 - val_acc: 0.8682\n",
      "Epoch 151/500\n",
      "515/515 [==============================] - 1s 2ms/sample - loss: 0.3551 - acc: 0.8835 - val_loss: 0.4339 - val_acc: 0.8915\n",
      "Epoch 152/500\n",
      "515/515 [==============================] - 1s 2ms/sample - loss: 0.3339 - acc: 0.8951 - val_loss: 0.4280 - val_acc: 0.8915\n",
      "Epoch 153/500\n",
      "515/515 [==============================] - 1s 2ms/sample - loss: 0.3571 - acc: 0.8971 - val_loss: 0.4244 - val_acc: 0.8992\n",
      "Epoch 154/500\n",
      "515/515 [==============================] - 1s 1ms/sample - loss: 0.3428 - acc: 0.8854 - val_loss: 0.4418 - val_acc: 0.9070\n",
      "Epoch 155/500\n",
      "515/515 [==============================] - 0s 796us/sample - loss: 0.3202 - acc: 0.9049 - val_loss: 0.4081 - val_acc: 0.8992\n",
      "Epoch 156/500\n",
      "515/515 [==============================] - 0s 793us/sample - loss: 0.3389 - acc: 0.8971 - val_loss: 0.3996 - val_acc: 0.8760\n",
      "Epoch 157/500\n",
      "515/515 [==============================] - 0s 726us/sample - loss: 0.3373 - acc: 0.8893 - val_loss: 0.4131 - val_acc: 0.8837\n",
      "Epoch 158/500\n",
      "515/515 [==============================] - 0s 736us/sample - loss: 0.3620 - acc: 0.8738 - val_loss: 0.4103 - val_acc: 0.9070\n",
      "Epoch 159/500\n",
      "515/515 [==============================] - 0s 776us/sample - loss: 0.3274 - acc: 0.9010 - val_loss: 0.3897 - val_acc: 0.8992\n",
      "Epoch 160/500\n",
      "515/515 [==============================] - 0s 748us/sample - loss: 0.3298 - acc: 0.8874 - val_loss: 0.4012 - val_acc: 0.8915\n",
      "Epoch 161/500\n",
      "515/515 [==============================] - 0s 841us/sample - loss: 0.3657 - acc: 0.8932 - val_loss: 0.4677 - val_acc: 0.8837\n",
      "Epoch 162/500\n",
      "515/515 [==============================] - 0s 790us/sample - loss: 0.3369 - acc: 0.8913 - val_loss: 0.3963 - val_acc: 0.9070\n",
      "Epoch 163/500\n",
      "515/515 [==============================] - 0s 797us/sample - loss: 0.3631 - acc: 0.8854 - val_loss: 0.3934 - val_acc: 0.9070\n",
      "Epoch 164/500\n",
      "515/515 [==============================] - 0s 804us/sample - loss: 0.3206 - acc: 0.8913 - val_loss: 0.4226 - val_acc: 0.9070\n",
      "Epoch 165/500\n",
      "515/515 [==============================] - 0s 779us/sample - loss: 0.3279 - acc: 0.8932 - val_loss: 0.4093 - val_acc: 0.8760\n",
      "Epoch 166/500\n",
      "515/515 [==============================] - 0s 780us/sample - loss: 0.3530 - acc: 0.8854 - val_loss: 0.3933 - val_acc: 0.9147\n",
      "Epoch 167/500\n",
      "515/515 [==============================] - 0s 749us/sample - loss: 0.3391 - acc: 0.8932 - val_loss: 0.3879 - val_acc: 0.8915\n",
      "Epoch 168/500\n",
      "515/515 [==============================] - 0s 769us/sample - loss: 0.3179 - acc: 0.8951 - val_loss: 0.3803 - val_acc: 0.9070\n",
      "Epoch 169/500\n",
      "515/515 [==============================] - 0s 790us/sample - loss: 0.3295 - acc: 0.8913 - val_loss: 0.4709 - val_acc: 0.8760\n",
      "Epoch 170/500\n",
      "515/515 [==============================] - 0s 783us/sample - loss: 0.3724 - acc: 0.8854 - val_loss: 0.4767 - val_acc: 0.8915\n",
      "Epoch 171/500\n",
      "515/515 [==============================] - 0s 927us/sample - loss: 0.3488 - acc: 0.8777 - val_loss: 0.4282 - val_acc: 0.8682\n",
      "Epoch 172/500\n",
      "515/515 [==============================] - 0s 956us/sample - loss: 0.3352 - acc: 0.8913 - val_loss: 0.4344 - val_acc: 0.8915\n",
      "Epoch 173/500\n",
      "515/515 [==============================] - 0s 833us/sample - loss: 0.3316 - acc: 0.8757 - val_loss: 0.3882 - val_acc: 0.9147\n",
      "Epoch 174/500\n",
      "515/515 [==============================] - 0s 891us/sample - loss: 0.3249 - acc: 0.8893 - val_loss: 0.4219 - val_acc: 0.8837\n",
      "Epoch 175/500\n",
      "515/515 [==============================] - 0s 772us/sample - loss: 0.3291 - acc: 0.8854 - val_loss: 0.4037 - val_acc: 0.8837\n",
      "Epoch 176/500\n",
      "515/515 [==============================] - 0s 790us/sample - loss: 0.3926 - acc: 0.8660 - val_loss: 0.4134 - val_acc: 0.8915\n",
      "Epoch 177/500\n",
      "515/515 [==============================] - 0s 745us/sample - loss: 0.3797 - acc: 0.8854 - val_loss: 0.3796 - val_acc: 0.8915\n",
      "Epoch 178/500\n",
      "515/515 [==============================] - 0s 844us/sample - loss: 0.3370 - acc: 0.8893 - val_loss: 0.4116 - val_acc: 0.8682\n",
      "Epoch 179/500\n",
      "515/515 [==============================] - 0s 814us/sample - loss: 0.3337 - acc: 0.8913 - val_loss: 0.4032 - val_acc: 0.8760\n",
      "Epoch 180/500\n",
      "515/515 [==============================] - 0s 807us/sample - loss: 0.3452 - acc: 0.8816 - val_loss: 0.3844 - val_acc: 0.8992\n",
      "Epoch 181/500\n",
      "515/515 [==============================] - 0s 805us/sample - loss: 0.3328 - acc: 0.8893 - val_loss: 0.3849 - val_acc: 0.8992\n",
      "Epoch 182/500\n",
      "515/515 [==============================] - 0s 767us/sample - loss: 0.3114 - acc: 0.8951 - val_loss: 0.3996 - val_acc: 0.8992\n",
      "Epoch 183/500\n",
      "515/515 [==============================] - 0s 921us/sample - loss: 0.3144 - acc: 0.9068 - val_loss: 0.3909 - val_acc: 0.9070\n",
      "Epoch 184/500\n",
      "515/515 [==============================] - 0s 838us/sample - loss: 0.3320 - acc: 0.8951 - val_loss: 0.4011 - val_acc: 0.9070\n",
      "Epoch 185/500\n",
      "515/515 [==============================] - 0s 849us/sample - loss: 0.3367 - acc: 0.8913 - val_loss: 0.3905 - val_acc: 0.8992\n",
      "Epoch 186/500\n",
      "515/515 [==============================] - 0s 883us/sample - loss: 0.3137 - acc: 0.8893 - val_loss: 0.3693 - val_acc: 0.9070\n",
      "Epoch 187/500\n",
      "515/515 [==============================] - 0s 825us/sample - loss: 0.3191 - acc: 0.8874 - val_loss: 0.3898 - val_acc: 0.8992\n",
      "Epoch 188/500\n",
      "515/515 [==============================] - 0s 825us/sample - loss: 0.3341 - acc: 0.8874 - val_loss: 0.4014 - val_acc: 0.8760\n",
      "Epoch 189/500\n",
      "515/515 [==============================] - 0s 824us/sample - loss: 0.3390 - acc: 0.8816 - val_loss: 0.4479 - val_acc: 0.8760\n",
      "Epoch 190/500\n",
      "515/515 [==============================] - 0s 753us/sample - loss: 0.3012 - acc: 0.8971 - val_loss: 0.3772 - val_acc: 0.9147\n",
      "Epoch 191/500\n",
      "515/515 [==============================] - 0s 842us/sample - loss: 0.3127 - acc: 0.8854 - val_loss: 0.4010 - val_acc: 0.9147\n",
      "Epoch 192/500\n",
      "515/515 [==============================] - 0s 780us/sample - loss: 0.3220 - acc: 0.8971 - val_loss: 0.3911 - val_acc: 0.8915\n",
      "Epoch 193/500\n",
      "515/515 [==============================] - 0s 787us/sample - loss: 0.3393 - acc: 0.8738 - val_loss: 0.3913 - val_acc: 0.8915\n",
      "Epoch 194/500\n",
      "515/515 [==============================] - 0s 795us/sample - loss: 0.3191 - acc: 0.8913 - val_loss: 0.3731 - val_acc: 0.8915\n",
      "Epoch 195/500\n",
      "515/515 [==============================] - 0s 789us/sample - loss: 0.2855 - acc: 0.9010 - val_loss: 0.3896 - val_acc: 0.8605\n",
      "Epoch 196/500\n",
      "515/515 [==============================] - 0s 783us/sample - loss: 0.3039 - acc: 0.8990 - val_loss: 0.3586 - val_acc: 0.8915\n",
      "Epoch 197/500\n",
      "515/515 [==============================] - 0s 826us/sample - loss: 0.2868 - acc: 0.8971 - val_loss: 0.3714 - val_acc: 0.8992\n",
      "Epoch 198/500\n",
      "515/515 [==============================] - 0s 810us/sample - loss: 0.2986 - acc: 0.8874 - val_loss: 0.3607 - val_acc: 0.8992\n",
      "Epoch 199/500\n",
      "515/515 [==============================] - 0s 714us/sample - loss: 0.3028 - acc: 0.8932 - val_loss: 0.3429 - val_acc: 0.8915\n",
      "Epoch 200/500\n",
      "515/515 [==============================] - 0s 700us/sample - loss: 0.3155 - acc: 0.8796 - val_loss: 0.3855 - val_acc: 0.8915\n",
      "Epoch 201/500\n",
      "515/515 [==============================] - 0s 866us/sample - loss: 0.2860 - acc: 0.8913 - val_loss: 0.3613 - val_acc: 0.8760\n",
      "Epoch 202/500\n",
      "515/515 [==============================] - 0s 875us/sample - loss: 0.3361 - acc: 0.8738 - val_loss: 0.3698 - val_acc: 0.8992\n",
      "Epoch 203/500\n",
      "515/515 [==============================] - 0s 834us/sample - loss: 0.2957 - acc: 0.9107 - val_loss: 0.3446 - val_acc: 0.9070\n",
      "Epoch 204/500\n",
      "515/515 [==============================] - 0s 835us/sample - loss: 0.2889 - acc: 0.9029 - val_loss: 0.3495 - val_acc: 0.8992\n",
      "Epoch 205/500\n",
      "515/515 [==============================] - 0s 794us/sample - loss: 0.3032 - acc: 0.9068 - val_loss: 0.3681 - val_acc: 0.8837\n",
      "Epoch 206/500\n",
      "515/515 [==============================] - 0s 807us/sample - loss: 0.3079 - acc: 0.8874 - val_loss: 0.3857 - val_acc: 0.8682\n",
      "Epoch 207/500\n",
      "515/515 [==============================] - 0s 751us/sample - loss: 0.3266 - acc: 0.8854 - val_loss: 0.3754 - val_acc: 0.8527\n",
      "Epoch 208/500\n",
      "515/515 [==============================] - 0s 781us/sample - loss: 0.3133 - acc: 0.8913 - val_loss: 0.3742 - val_acc: 0.8992\n",
      "Epoch 209/500\n",
      "515/515 [==============================] - 0s 765us/sample - loss: 0.2823 - acc: 0.9049 - val_loss: 0.3609 - val_acc: 0.9070\n",
      "Epoch 210/500\n",
      "515/515 [==============================] - 0s 801us/sample - loss: 0.3220 - acc: 0.8854 - val_loss: 0.4073 - val_acc: 0.8992\n",
      "Epoch 211/500\n",
      "515/515 [==============================] - 0s 885us/sample - loss: 0.3093 - acc: 0.8932 - val_loss: 0.3756 - val_acc: 0.8915\n",
      "Epoch 212/500\n",
      "515/515 [==============================] - 0s 786us/sample - loss: 0.2758 - acc: 0.9010 - val_loss: 0.3363 - val_acc: 0.8992\n",
      "Epoch 213/500\n",
      "515/515 [==============================] - 0s 848us/sample - loss: 0.2950 - acc: 0.8990 - val_loss: 0.3463 - val_acc: 0.8992\n",
      "Epoch 214/500\n",
      "515/515 [==============================] - 0s 879us/sample - loss: 0.3126 - acc: 0.8951 - val_loss: 0.3565 - val_acc: 0.8915\n",
      "Epoch 215/500\n",
      "515/515 [==============================] - 0s 748us/sample - loss: 0.2899 - acc: 0.8971 - val_loss: 0.3390 - val_acc: 0.8915\n",
      "Epoch 216/500\n",
      "515/515 [==============================] - 0s 794us/sample - loss: 0.2947 - acc: 0.8932 - val_loss: 0.3502 - val_acc: 0.8992\n",
      "Epoch 217/500\n",
      "515/515 [==============================] - 0s 736us/sample - loss: 0.2903 - acc: 0.8932 - val_loss: 0.3464 - val_acc: 0.8760\n",
      "Epoch 218/500\n",
      "515/515 [==============================] - 0s 815us/sample - loss: 0.3026 - acc: 0.8971 - val_loss: 0.3893 - val_acc: 0.8837\n",
      "Epoch 219/500\n",
      "515/515 [==============================] - 0s 771us/sample - loss: 0.2792 - acc: 0.8990 - val_loss: 0.3585 - val_acc: 0.9070\n",
      "Epoch 220/500\n",
      "515/515 [==============================] - 0s 786us/sample - loss: 0.2828 - acc: 0.8971 - val_loss: 0.3921 - val_acc: 0.8837\n",
      "Epoch 221/500\n",
      "515/515 [==============================] - 0s 792us/sample - loss: 0.2914 - acc: 0.8932 - val_loss: 0.3805 - val_acc: 0.8992\n",
      "Epoch 222/500\n",
      "515/515 [==============================] - 0s 794us/sample - loss: 0.2947 - acc: 0.8913 - val_loss: 0.3575 - val_acc: 0.8915\n",
      "Epoch 223/500\n",
      "515/515 [==============================] - 0s 713us/sample - loss: 0.2981 - acc: 0.8913 - val_loss: 0.3411 - val_acc: 0.8992\n",
      "Epoch 224/500\n",
      "515/515 [==============================] - 0s 807us/sample - loss: 0.2840 - acc: 0.9049 - val_loss: 0.3380 - val_acc: 0.9225\n",
      "Epoch 225/500\n",
      "515/515 [==============================] - 0s 808us/sample - loss: 0.2874 - acc: 0.8990 - val_loss: 0.3679 - val_acc: 0.8605\n",
      "Epoch 226/500\n",
      "515/515 [==============================] - 0s 773us/sample - loss: 0.2938 - acc: 0.9068 - val_loss: 0.3652 - val_acc: 0.9070\n",
      "Epoch 227/500\n",
      "515/515 [==============================] - 0s 910us/sample - loss: 0.2876 - acc: 0.8990 - val_loss: 0.3658 - val_acc: 0.8915\n",
      "Epoch 228/500\n",
      "515/515 [==============================] - 0s 957us/sample - loss: 0.3078 - acc: 0.9010 - val_loss: 0.4057 - val_acc: 0.8837\n",
      "Epoch 229/500\n",
      "515/515 [==============================] - 0s 831us/sample - loss: 0.2991 - acc: 0.8757 - val_loss: 0.3572 - val_acc: 0.8760\n",
      "Epoch 230/500\n",
      "515/515 [==============================] - 0s 799us/sample - loss: 0.3014 - acc: 0.8971 - val_loss: 0.3384 - val_acc: 0.8915\n",
      "Epoch 231/500\n",
      "515/515 [==============================] - 0s 808us/sample - loss: 0.2960 - acc: 0.9068 - val_loss: 0.4047 - val_acc: 0.8992\n",
      "Epoch 232/500\n",
      "515/515 [==============================] - 0s 807us/sample - loss: 0.3243 - acc: 0.8854 - val_loss: 0.4313 - val_acc: 0.8605\n",
      "Epoch 233/500\n",
      "515/515 [==============================] - 0s 745us/sample - loss: 0.3013 - acc: 0.8757 - val_loss: 0.4350 - val_acc: 0.8605\n",
      "Epoch 234/500\n",
      "515/515 [==============================] - 0s 840us/sample - loss: 0.3372 - acc: 0.8738 - val_loss: 0.3946 - val_acc: 0.8605\n",
      "Epoch 235/500\n",
      "515/515 [==============================] - 0s 774us/sample - loss: 0.2969 - acc: 0.8932 - val_loss: 0.3411 - val_acc: 0.9070\n",
      "Epoch 236/500\n",
      "515/515 [==============================] - 0s 837us/sample - loss: 0.3075 - acc: 0.8971 - val_loss: 0.3891 - val_acc: 0.8837\n",
      "Epoch 237/500\n",
      "515/515 [==============================] - 0s 801us/sample - loss: 0.2840 - acc: 0.8913 - val_loss: 0.3986 - val_acc: 0.8527\n",
      "Epoch 238/500\n",
      "515/515 [==============================] - 0s 859us/sample - loss: 0.2865 - acc: 0.8990 - val_loss: 0.3824 - val_acc: 0.8605\n",
      "Epoch 239/500\n",
      "515/515 [==============================] - 0s 847us/sample - loss: 0.2688 - acc: 0.8951 - val_loss: 0.3575 - val_acc: 0.8915\n",
      "Epoch 240/500\n",
      "515/515 [==============================] - 0s 871us/sample - loss: 0.2975 - acc: 0.8874 - val_loss: 0.3384 - val_acc: 0.8915\n",
      "Epoch 241/500\n",
      "515/515 [==============================] - 0s 816us/sample - loss: 0.2986 - acc: 0.8835 - val_loss: 0.4042 - val_acc: 0.8992\n",
      "Epoch 242/500\n",
      "515/515 [==============================] - 0s 860us/sample - loss: 0.3290 - acc: 0.8835 - val_loss: 0.3602 - val_acc: 0.8837\n",
      "Epoch 243/500\n",
      "515/515 [==============================] - 0s 740us/sample - loss: 0.3118 - acc: 0.8835 - val_loss: 0.3778 - val_acc: 0.8682\n",
      "Epoch 244/500\n",
      "515/515 [==============================] - 0s 856us/sample - loss: 0.2778 - acc: 0.9029 - val_loss: 0.3523 - val_acc: 0.8915\n",
      "Epoch 245/500\n",
      "515/515 [==============================] - 0s 787us/sample - loss: 0.2908 - acc: 0.8777 - val_loss: 0.3385 - val_acc: 0.8527\n",
      "Epoch 246/500\n",
      "515/515 [==============================] - 0s 859us/sample - loss: 0.2844 - acc: 0.8990 - val_loss: 0.3370 - val_acc: 0.8915\n",
      "Epoch 247/500\n",
      "515/515 [==============================] - 0s 903us/sample - loss: 0.2964 - acc: 0.8893 - val_loss: 0.3319 - val_acc: 0.9070\n",
      "Epoch 248/500\n",
      "515/515 [==============================] - 0s 834us/sample - loss: 0.2737 - acc: 0.8874 - val_loss: 0.3552 - val_acc: 0.8837\n",
      "Epoch 249/500\n",
      "515/515 [==============================] - 0s 884us/sample - loss: 0.2884 - acc: 0.8971 - val_loss: 0.3599 - val_acc: 0.8760\n",
      "Epoch 250/500\n",
      "515/515 [==============================] - 0s 877us/sample - loss: 0.2929 - acc: 0.8854 - val_loss: 0.3688 - val_acc: 0.8837\n",
      "Epoch 251/500\n",
      "515/515 [==============================] - 0s 897us/sample - loss: 0.2946 - acc: 0.8913 - val_loss: 0.3554 - val_acc: 0.8682\n",
      "Epoch 252/500\n",
      "515/515 [==============================] - 0s 834us/sample - loss: 0.2819 - acc: 0.8893 - val_loss: 0.3766 - val_acc: 0.8837\n",
      "Epoch 253/500\n",
      "515/515 [==============================] - 0s 857us/sample - loss: 0.2746 - acc: 0.9049 - val_loss: 0.3479 - val_acc: 0.8915\n",
      "Epoch 254/500\n",
      "515/515 [==============================] - 0s 835us/sample - loss: 0.2736 - acc: 0.9010 - val_loss: 0.3355 - val_acc: 0.8760\n",
      "Epoch 255/500\n",
      "515/515 [==============================] - 0s 823us/sample - loss: 0.3105 - acc: 0.8951 - val_loss: 0.3501 - val_acc: 0.9070\n",
      "Epoch 256/500\n",
      "515/515 [==============================] - 0s 775us/sample - loss: 0.2742 - acc: 0.8835 - val_loss: 0.3625 - val_acc: 0.8450\n",
      "Epoch 257/500\n",
      "515/515 [==============================] - 0s 852us/sample - loss: 0.2930 - acc: 0.8913 - val_loss: 0.3794 - val_acc: 0.8837\n",
      "Epoch 258/500\n",
      "515/515 [==============================] - 0s 817us/sample - loss: 0.2885 - acc: 0.8932 - val_loss: 0.3563 - val_acc: 0.8992\n",
      "Epoch 259/500\n",
      "515/515 [==============================] - 0s 828us/sample - loss: 0.2653 - acc: 0.9029 - val_loss: 0.4088 - val_acc: 0.8682\n",
      "Epoch 260/500\n",
      "515/515 [==============================] - 0s 926us/sample - loss: 0.2999 - acc: 0.8854 - val_loss: 0.3697 - val_acc: 0.8915\n",
      "Epoch 261/500\n",
      "515/515 [==============================] - 0s 805us/sample - loss: 0.2962 - acc: 0.8913 - val_loss: 0.3856 - val_acc: 0.8760\n",
      "Epoch 262/500\n",
      "515/515 [==============================] - 0s 789us/sample - loss: 0.2797 - acc: 0.9049 - val_loss: 0.3541 - val_acc: 0.8915\n",
      "Epoch 263/500\n",
      "515/515 [==============================] - 0s 781us/sample - loss: 0.3010 - acc: 0.8913 - val_loss: 0.3644 - val_acc: 0.8915\n",
      "Epoch 264/500\n",
      "515/515 [==============================] - 0s 755us/sample - loss: 0.2608 - acc: 0.8913 - val_loss: 0.3439 - val_acc: 0.8837\n",
      "Epoch 265/500\n",
      "515/515 [==============================] - 0s 813us/sample - loss: 0.2813 - acc: 0.8893 - val_loss: 0.3331 - val_acc: 0.8992\n",
      "Epoch 266/500\n",
      "515/515 [==============================] - 0s 809us/sample - loss: 0.2661 - acc: 0.9010 - val_loss: 0.3401 - val_acc: 0.8915\n",
      "Epoch 267/500\n",
      "515/515 [==============================] - 0s 715us/sample - loss: 0.2527 - acc: 0.9068 - val_loss: 0.3402 - val_acc: 0.8915\n",
      "Epoch 268/500\n",
      "515/515 [==============================] - 0s 762us/sample - loss: 0.2709 - acc: 0.8990 - val_loss: 0.3720 - val_acc: 0.8527\n",
      "Epoch 269/500\n",
      "515/515 [==============================] - 0s 755us/sample - loss: 0.2606 - acc: 0.8951 - val_loss: 0.3333 - val_acc: 0.8915\n",
      "Epoch 270/500\n",
      "515/515 [==============================] - 0s 737us/sample - loss: 0.2617 - acc: 0.9010 - val_loss: 0.3497 - val_acc: 0.8992\n",
      "Epoch 271/500\n",
      "515/515 [==============================] - 0s 694us/sample - loss: 0.2818 - acc: 0.8951 - val_loss: 0.3537 - val_acc: 0.9070\n",
      "Epoch 272/500\n",
      "515/515 [==============================] - 0s 883us/sample - loss: 0.2632 - acc: 0.8990 - val_loss: 0.3372 - val_acc: 0.8915\n",
      "Epoch 273/500\n",
      "515/515 [==============================] - 0s 868us/sample - loss: 0.2583 - acc: 0.9068 - val_loss: 0.3347 - val_acc: 0.8682\n",
      "Epoch 274/500\n",
      "515/515 [==============================] - 0s 808us/sample - loss: 0.2833 - acc: 0.8796 - val_loss: 0.3700 - val_acc: 0.8605\n",
      "Epoch 275/500\n",
      "515/515 [==============================] - 0s 834us/sample - loss: 0.2828 - acc: 0.8990 - val_loss: 0.3297 - val_acc: 0.8992\n",
      "Epoch 276/500\n",
      "515/515 [==============================] - 0s 869us/sample - loss: 0.2671 - acc: 0.8990 - val_loss: 0.3569 - val_acc: 0.8682\n",
      "Epoch 277/500\n",
      "515/515 [==============================] - 0s 787us/sample - loss: 0.2549 - acc: 0.8951 - val_loss: 0.3265 - val_acc: 0.8682\n",
      "Epoch 278/500\n",
      "515/515 [==============================] - 0s 816us/sample - loss: 0.2525 - acc: 0.9107 - val_loss: 0.3246 - val_acc: 0.9225\n",
      "Epoch 279/500\n",
      "515/515 [==============================] - 0s 802us/sample - loss: 0.2739 - acc: 0.9010 - val_loss: 0.3760 - val_acc: 0.8837\n",
      "Epoch 280/500\n",
      "515/515 [==============================] - 0s 834us/sample - loss: 0.2588 - acc: 0.9107 - val_loss: 0.3419 - val_acc: 0.8992\n",
      "Epoch 281/500\n",
      "515/515 [==============================] - 0s 918us/sample - loss: 0.2553 - acc: 0.9010 - val_loss: 0.3266 - val_acc: 0.8837\n",
      "Epoch 282/500\n",
      "515/515 [==============================] - 0s 758us/sample - loss: 0.2409 - acc: 0.9126 - val_loss: 0.3212 - val_acc: 0.8915\n",
      "Epoch 283/500\n",
      "515/515 [==============================] - 0s 793us/sample - loss: 0.2666 - acc: 0.9087 - val_loss: 0.3269 - val_acc: 0.9147\n",
      "Epoch 284/500\n",
      "515/515 [==============================] - 0s 822us/sample - loss: 0.2824 - acc: 0.8913 - val_loss: 0.3313 - val_acc: 0.9070\n",
      "Epoch 285/500\n",
      "515/515 [==============================] - 0s 907us/sample - loss: 0.2349 - acc: 0.9165 - val_loss: 0.3262 - val_acc: 0.8837\n",
      "Epoch 286/500\n",
      "515/515 [==============================] - 0s 794us/sample - loss: 0.2591 - acc: 0.9146 - val_loss: 0.3295 - val_acc: 0.8915\n",
      "Epoch 287/500\n",
      "515/515 [==============================] - 0s 725us/sample - loss: 0.2818 - acc: 0.8913 - val_loss: 0.3465 - val_acc: 0.8760\n",
      "Epoch 288/500\n",
      "515/515 [==============================] - 0s 746us/sample - loss: 0.2746 - acc: 0.9010 - val_loss: 0.3320 - val_acc: 0.8992\n",
      "Epoch 289/500\n",
      "515/515 [==============================] - 0s 718us/sample - loss: 0.2723 - acc: 0.8932 - val_loss: 0.3540 - val_acc: 0.8915\n",
      "Epoch 290/500\n",
      "515/515 [==============================] - 0s 725us/sample - loss: 0.2416 - acc: 0.8951 - val_loss: 0.4167 - val_acc: 0.8915\n",
      "Epoch 291/500\n",
      "515/515 [==============================] - 0s 742us/sample - loss: 0.2822 - acc: 0.8893 - val_loss: 0.3453 - val_acc: 0.8837\n",
      "Epoch 292/500\n",
      "515/515 [==============================] - 0s 767us/sample - loss: 0.2548 - acc: 0.9010 - val_loss: 0.3205 - val_acc: 0.8992\n",
      "Epoch 293/500\n",
      "515/515 [==============================] - 0s 767us/sample - loss: 0.2541 - acc: 0.9010 - val_loss: 0.3112 - val_acc: 0.8915\n",
      "Epoch 294/500\n",
      "515/515 [==============================] - 0s 789us/sample - loss: 0.2774 - acc: 0.9010 - val_loss: 0.3128 - val_acc: 0.8915\n",
      "Epoch 295/500\n",
      "515/515 [==============================] - 0s 832us/sample - loss: 0.2654 - acc: 0.9010 - val_loss: 0.3731 - val_acc: 0.8527\n",
      "Epoch 296/500\n",
      "515/515 [==============================] - 1s 998us/sample - loss: 0.2481 - acc: 0.9107 - val_loss: 0.3557 - val_acc: 0.8837\n",
      "Epoch 297/500\n",
      "515/515 [==============================] - 0s 859us/sample - loss: 0.2656 - acc: 0.8990 - val_loss: 0.3343 - val_acc: 0.8837\n",
      "Epoch 298/500\n",
      "515/515 [==============================] - 0s 820us/sample - loss: 0.2872 - acc: 0.8990 - val_loss: 0.3341 - val_acc: 0.8760\n",
      "Epoch 299/500\n",
      "515/515 [==============================] - 0s 772us/sample - loss: 0.2606 - acc: 0.8932 - val_loss: 0.3252 - val_acc: 0.8837\n",
      "Epoch 300/500\n",
      "515/515 [==============================] - 0s 759us/sample - loss: 0.2893 - acc: 0.8893 - val_loss: 0.3664 - val_acc: 0.8837\n",
      "Epoch 301/500\n",
      "515/515 [==============================] - 0s 873us/sample - loss: 0.2671 - acc: 0.8951 - val_loss: 0.3529 - val_acc: 0.8837\n",
      "Epoch 302/500\n",
      "515/515 [==============================] - 0s 800us/sample - loss: 0.2553 - acc: 0.8913 - val_loss: 0.3849 - val_acc: 0.8682\n",
      "Epoch 303/500\n",
      "515/515 [==============================] - 0s 895us/sample - loss: 0.2545 - acc: 0.8951 - val_loss: 0.3457 - val_acc: 0.8915\n",
      "Epoch 304/500\n",
      "515/515 [==============================] - 0s 802us/sample - loss: 0.2571 - acc: 0.9068 - val_loss: 0.3413 - val_acc: 0.8837\n",
      "Epoch 305/500\n",
      "515/515 [==============================] - 0s 808us/sample - loss: 0.2303 - acc: 0.9087 - val_loss: 0.3479 - val_acc: 0.8837\n",
      "Epoch 306/500\n",
      "515/515 [==============================] - 0s 790us/sample - loss: 0.2650 - acc: 0.8932 - val_loss: 0.3502 - val_acc: 0.8915\n",
      "Epoch 307/500\n",
      "515/515 [==============================] - 0s 908us/sample - loss: 0.2642 - acc: 0.9029 - val_loss: 0.3270 - val_acc: 0.8915\n",
      "Epoch 308/500\n",
      "515/515 [==============================] - 0s 836us/sample - loss: 0.2400 - acc: 0.9107 - val_loss: 0.3702 - val_acc: 0.8682\n",
      "Epoch 309/500\n",
      "515/515 [==============================] - 0s 817us/sample - loss: 0.2476 - acc: 0.9010 - val_loss: 0.3648 - val_acc: 0.8682\n",
      "Epoch 310/500\n",
      "515/515 [==============================] - 0s 820us/sample - loss: 0.2460 - acc: 0.9049 - val_loss: 0.3417 - val_acc: 0.8837\n",
      "Epoch 311/500\n",
      "515/515 [==============================] - 0s 732us/sample - loss: 0.2624 - acc: 0.9010 - val_loss: 0.3547 - val_acc: 0.8992\n",
      "Epoch 312/500\n",
      "515/515 [==============================] - 0s 724us/sample - loss: 0.2681 - acc: 0.8893 - val_loss: 0.3735 - val_acc: 0.8760\n",
      "Epoch 313/500\n",
      "515/515 [==============================] - 0s 812us/sample - loss: 0.2633 - acc: 0.9107 - val_loss: 0.3765 - val_acc: 0.9070\n",
      "Epoch 314/500\n",
      "515/515 [==============================] - 0s 835us/sample - loss: 0.2374 - acc: 0.9107 - val_loss: 0.3155 - val_acc: 0.9070\n",
      "Epoch 315/500\n",
      "515/515 [==============================] - 0s 818us/sample - loss: 0.2399 - acc: 0.9029 - val_loss: 0.3436 - val_acc: 0.8837\n",
      "Epoch 316/500\n",
      "515/515 [==============================] - 0s 827us/sample - loss: 0.2526 - acc: 0.8971 - val_loss: 0.3331 - val_acc: 0.9070\n",
      "Epoch 317/500\n",
      "515/515 [==============================] - 0s 760us/sample - loss: 0.2467 - acc: 0.9049 - val_loss: 0.3257 - val_acc: 0.8992\n",
      "Epoch 318/500\n",
      "515/515 [==============================] - 0s 758us/sample - loss: 0.2511 - acc: 0.9068 - val_loss: 0.3662 - val_acc: 0.8605\n",
      "Epoch 319/500\n",
      "515/515 [==============================] - 0s 796us/sample - loss: 0.2866 - acc: 0.8816 - val_loss: 0.3356 - val_acc: 0.8837\n",
      "Epoch 320/500\n",
      "515/515 [==============================] - 0s 883us/sample - loss: 0.2481 - acc: 0.9068 - val_loss: 0.3168 - val_acc: 0.8915\n",
      "Epoch 321/500\n",
      "515/515 [==============================] - 0s 762us/sample - loss: 0.2548 - acc: 0.9165 - val_loss: 0.3355 - val_acc: 0.8837\n",
      "Epoch 322/500\n",
      "515/515 [==============================] - 0s 790us/sample - loss: 0.2917 - acc: 0.8990 - val_loss: 0.3584 - val_acc: 0.8992\n",
      "Epoch 323/500\n",
      "515/515 [==============================] - 0s 838us/sample - loss: 0.2649 - acc: 0.8951 - val_loss: 0.3448 - val_acc: 0.8760\n",
      "Epoch 324/500\n",
      "515/515 [==============================] - 0s 782us/sample - loss: 0.2793 - acc: 0.8835 - val_loss: 0.3052 - val_acc: 0.9070\n",
      "Epoch 325/500\n",
      "515/515 [==============================] - 0s 710us/sample - loss: 0.2502 - acc: 0.9049 - val_loss: 0.3339 - val_acc: 0.8760\n",
      "Epoch 326/500\n",
      "515/515 [==============================] - 0s 770us/sample - loss: 0.2406 - acc: 0.9107 - val_loss: 0.3443 - val_acc: 0.8915\n",
      "Epoch 327/500\n",
      "515/515 [==============================] - 0s 780us/sample - loss: 0.2481 - acc: 0.9107 - val_loss: 0.3332 - val_acc: 0.8915\n",
      "Epoch 328/500\n",
      "515/515 [==============================] - 0s 768us/sample - loss: 0.2390 - acc: 0.9107 - val_loss: 0.3375 - val_acc: 0.8915\n",
      "Epoch 329/500\n",
      "515/515 [==============================] - 0s 755us/sample - loss: 0.2659 - acc: 0.9107 - val_loss: 0.3443 - val_acc: 0.8992\n",
      "Epoch 330/500\n",
      "515/515 [==============================] - 0s 836us/sample - loss: 0.2508 - acc: 0.8951 - val_loss: 0.3613 - val_acc: 0.8760\n",
      "Epoch 331/500\n",
      "515/515 [==============================] - 0s 919us/sample - loss: 0.2714 - acc: 0.8951 - val_loss: 0.3178 - val_acc: 0.8915\n",
      "Epoch 332/500\n",
      "515/515 [==============================] - 0s 768us/sample - loss: 0.2731 - acc: 0.8951 - val_loss: 0.3410 - val_acc: 0.8760\n",
      "Epoch 333/500\n",
      "515/515 [==============================] - 0s 782us/sample - loss: 0.2762 - acc: 0.8951 - val_loss: 0.3170 - val_acc: 0.8760\n",
      "Epoch 334/500\n",
      "515/515 [==============================] - 0s 789us/sample - loss: 0.2552 - acc: 0.8913 - val_loss: 0.3087 - val_acc: 0.9147\n",
      "Epoch 335/500\n",
      "515/515 [==============================] - 0s 857us/sample - loss: 0.2730 - acc: 0.8951 - val_loss: 0.3862 - val_acc: 0.8992\n",
      "Epoch 336/500\n",
      "515/515 [==============================] - 0s 931us/sample - loss: 0.2622 - acc: 0.8932 - val_loss: 0.3206 - val_acc: 0.9070\n",
      "Epoch 337/500\n",
      "515/515 [==============================] - 0s 863us/sample - loss: 0.2436 - acc: 0.9029 - val_loss: 0.3200 - val_acc: 0.8992\n",
      "Epoch 338/500\n",
      "515/515 [==============================] - 0s 841us/sample - loss: 0.2503 - acc: 0.9029 - val_loss: 0.3084 - val_acc: 0.8915\n",
      "Epoch 339/500\n",
      "515/515 [==============================] - 0s 770us/sample - loss: 0.2894 - acc: 0.9029 - val_loss: 0.3709 - val_acc: 0.8915\n",
      "Epoch 340/500\n",
      "515/515 [==============================] - 0s 853us/sample - loss: 0.2803 - acc: 0.9087 - val_loss: 0.3666 - val_acc: 0.8992\n",
      "Epoch 341/500\n",
      "515/515 [==============================] - 0s 817us/sample - loss: 0.2613 - acc: 0.9029 - val_loss: 0.3463 - val_acc: 0.8915\n",
      "Epoch 342/500\n",
      "515/515 [==============================] - 0s 795us/sample - loss: 0.2582 - acc: 0.9029 - val_loss: 0.3319 - val_acc: 0.9225\n",
      "Epoch 343/500\n",
      "515/515 [==============================] - 0s 853us/sample - loss: 0.2627 - acc: 0.8990 - val_loss: 0.3455 - val_acc: 0.8682\n",
      "Epoch 344/500\n",
      "515/515 [==============================] - 0s 783us/sample - loss: 0.2741 - acc: 0.8990 - val_loss: 0.3253 - val_acc: 0.8915\n",
      "Epoch 345/500\n",
      "515/515 [==============================] - 0s 843us/sample - loss: 0.2640 - acc: 0.9029 - val_loss: 0.3343 - val_acc: 0.8915\n",
      "Epoch 346/500\n",
      "515/515 [==============================] - 0s 764us/sample - loss: 0.2889 - acc: 0.8854 - val_loss: 0.3348 - val_acc: 0.8992\n",
      "Epoch 347/500\n",
      "515/515 [==============================] - 0s 890us/sample - loss: 0.2798 - acc: 0.9049 - val_loss: 0.3264 - val_acc: 0.8992\n",
      "Epoch 348/500\n",
      "515/515 [==============================] - 0s 964us/sample - loss: 0.2526 - acc: 0.9010 - val_loss: 0.3067 - val_acc: 0.9070\n",
      "Epoch 349/500\n",
      "515/515 [==============================] - 0s 884us/sample - loss: 0.2401 - acc: 0.8990 - val_loss: 0.3119 - val_acc: 0.8992\n",
      "Epoch 350/500\n",
      "515/515 [==============================] - 0s 912us/sample - loss: 0.2412 - acc: 0.8951 - val_loss: 0.3125 - val_acc: 0.8915\n",
      "Epoch 351/500\n",
      "515/515 [==============================] - 0s 839us/sample - loss: 0.2472 - acc: 0.9010 - val_loss: 0.3377 - val_acc: 0.8760\n",
      "Epoch 352/500\n",
      "515/515 [==============================] - 0s 808us/sample - loss: 0.2606 - acc: 0.9029 - val_loss: 0.3061 - val_acc: 0.8837\n",
      "Epoch 353/500\n",
      "515/515 [==============================] - 0s 726us/sample - loss: 0.2516 - acc: 0.9029 - val_loss: 0.3543 - val_acc: 0.8915\n",
      "Epoch 354/500\n",
      "515/515 [==============================] - 0s 878us/sample - loss: 0.2514 - acc: 0.8971 - val_loss: 0.3181 - val_acc: 0.8837\n",
      "Epoch 355/500\n",
      "515/515 [==============================] - 0s 859us/sample - loss: 0.2482 - acc: 0.9068 - val_loss: 0.3247 - val_acc: 0.8837\n",
      "Epoch 356/500\n",
      "515/515 [==============================] - 0s 739us/sample - loss: 0.2530 - acc: 0.9010 - val_loss: 0.3281 - val_acc: 0.9070\n",
      "Epoch 357/500\n",
      "515/515 [==============================] - 0s 836us/sample - loss: 0.2301 - acc: 0.9087 - val_loss: 0.3655 - val_acc: 0.9070\n",
      "Epoch 358/500\n",
      "515/515 [==============================] - 0s 797us/sample - loss: 0.2371 - acc: 0.9010 - val_loss: 0.3062 - val_acc: 0.8837\n",
      "Epoch 359/500\n",
      "515/515 [==============================] - 0s 899us/sample - loss: 0.2617 - acc: 0.8971 - val_loss: 0.3210 - val_acc: 0.8992\n",
      "Epoch 360/500\n",
      "515/515 [==============================] - 0s 869us/sample - loss: 0.2325 - acc: 0.9165 - val_loss: 0.3095 - val_acc: 0.8760\n",
      "Epoch 361/500\n",
      "515/515 [==============================] - 1s 978us/sample - loss: 0.2527 - acc: 0.9029 - val_loss: 0.3097 - val_acc: 0.8915\n",
      "Epoch 362/500\n",
      "515/515 [==============================] - 0s 858us/sample - loss: 0.2482 - acc: 0.8990 - val_loss: 0.3376 - val_acc: 0.9147\n",
      "Epoch 363/500\n",
      "515/515 [==============================] - 0s 886us/sample - loss: 0.2328 - acc: 0.9087 - val_loss: 0.3175 - val_acc: 0.9070\n",
      "Epoch 364/500\n",
      "515/515 [==============================] - 0s 916us/sample - loss: 0.2394 - acc: 0.9087 - val_loss: 0.3287 - val_acc: 0.8915\n",
      "Epoch 365/500\n",
      "515/515 [==============================] - 0s 838us/sample - loss: 0.2395 - acc: 0.9068 - val_loss: 0.3827 - val_acc: 0.8837\n",
      "Epoch 366/500\n",
      "515/515 [==============================] - 0s 843us/sample - loss: 0.2835 - acc: 0.8796 - val_loss: 0.2809 - val_acc: 0.8992\n",
      "Epoch 367/500\n",
      "515/515 [==============================] - 0s 855us/sample - loss: 0.3003 - acc: 0.8893 - val_loss: 0.4507 - val_acc: 0.9147\n",
      "Epoch 368/500\n",
      "515/515 [==============================] - 0s 828us/sample - loss: 0.2755 - acc: 0.9126 - val_loss: 0.3168 - val_acc: 0.8837\n",
      "Epoch 369/500\n",
      "515/515 [==============================] - 0s 784us/sample - loss: 0.2783 - acc: 0.8854 - val_loss: 0.3658 - val_acc: 0.8682\n",
      "Epoch 370/500\n",
      "515/515 [==============================] - 0s 836us/sample - loss: 0.2451 - acc: 0.8990 - val_loss: 0.3643 - val_acc: 0.8837\n",
      "Epoch 371/500\n",
      "515/515 [==============================] - 0s 730us/sample - loss: 0.2513 - acc: 0.9068 - val_loss: 0.3085 - val_acc: 0.8915\n",
      "Epoch 372/500\n",
      "515/515 [==============================] - 0s 792us/sample - loss: 0.2331 - acc: 0.9146 - val_loss: 0.3260 - val_acc: 0.8837\n",
      "Epoch 373/500\n",
      "515/515 [==============================] - 0s 822us/sample - loss: 0.2586 - acc: 0.9107 - val_loss: 0.3873 - val_acc: 0.8837\n",
      "Epoch 374/500\n",
      "515/515 [==============================] - 0s 785us/sample - loss: 0.2258 - acc: 0.9126 - val_loss: 0.3216 - val_acc: 0.8915\n",
      "Epoch 375/500\n",
      "515/515 [==============================] - 0s 800us/sample - loss: 0.2312 - acc: 0.9087 - val_loss: 0.3423 - val_acc: 0.9147\n",
      "Epoch 376/500\n",
      "515/515 [==============================] - 0s 801us/sample - loss: 0.2561 - acc: 0.9049 - val_loss: 0.3083 - val_acc: 0.8837\n",
      "Epoch 377/500\n",
      "515/515 [==============================] - 0s 789us/sample - loss: 0.2288 - acc: 0.9049 - val_loss: 0.3254 - val_acc: 0.8837\n",
      "Epoch 378/500\n",
      "515/515 [==============================] - 0s 749us/sample - loss: 0.2229 - acc: 0.9184 - val_loss: 0.3412 - val_acc: 0.9147\n",
      "Epoch 379/500\n",
      "515/515 [==============================] - 0s 834us/sample - loss: 0.2272 - acc: 0.9146 - val_loss: 0.3303 - val_acc: 0.8992\n",
      "Epoch 380/500\n",
      "515/515 [==============================] - 0s 769us/sample - loss: 0.2395 - acc: 0.9087 - val_loss: 0.3422 - val_acc: 0.8915\n",
      "Epoch 381/500\n",
      "515/515 [==============================] - 0s 879us/sample - loss: 0.2642 - acc: 0.8971 - val_loss: 0.3497 - val_acc: 0.8915\n",
      "Epoch 382/500\n",
      "515/515 [==============================] - 0s 850us/sample - loss: 0.2731 - acc: 0.8971 - val_loss: 0.3489 - val_acc: 0.8915\n",
      "Epoch 383/500\n",
      "515/515 [==============================] - 0s 745us/sample - loss: 0.2371 - acc: 0.8971 - val_loss: 0.3149 - val_acc: 0.8915\n",
      "Epoch 384/500\n",
      "515/515 [==============================] - 0s 816us/sample - loss: 0.2377 - acc: 0.8990 - val_loss: 0.3280 - val_acc: 0.8760\n",
      "Epoch 385/500\n",
      "515/515 [==============================] - 0s 894us/sample - loss: 0.2204 - acc: 0.9165 - val_loss: 0.3071 - val_acc: 0.8992\n",
      "Epoch 386/500\n",
      "515/515 [==============================] - 0s 783us/sample - loss: 0.2316 - acc: 0.9243 - val_loss: 0.3385 - val_acc: 0.8915\n",
      "Epoch 387/500\n",
      "515/515 [==============================] - 0s 756us/sample - loss: 0.2274 - acc: 0.9049 - val_loss: 0.3389 - val_acc: 0.8915\n",
      "Epoch 388/500\n",
      "515/515 [==============================] - 0s 803us/sample - loss: 0.2286 - acc: 0.9049 - val_loss: 0.3462 - val_acc: 0.8915\n",
      "Epoch 389/500\n",
      "515/515 [==============================] - 0s 886us/sample - loss: 0.2465 - acc: 0.9068 - val_loss: 0.3179 - val_acc: 0.8837\n",
      "Epoch 390/500\n",
      "515/515 [==============================] - 0s 765us/sample - loss: 0.2525 - acc: 0.9107 - val_loss: 0.3493 - val_acc: 0.8915\n",
      "Epoch 391/500\n",
      "515/515 [==============================] - 0s 866us/sample - loss: 0.2372 - acc: 0.9165 - val_loss: 0.3291 - val_acc: 0.8915\n",
      "Epoch 392/500\n",
      "515/515 [==============================] - 0s 801us/sample - loss: 0.2290 - acc: 0.9107 - val_loss: 0.3379 - val_acc: 0.8837\n",
      "Epoch 393/500\n",
      "515/515 [==============================] - 0s 918us/sample - loss: 0.2230 - acc: 0.9184 - val_loss: 0.3416 - val_acc: 0.8837\n",
      "Epoch 394/500\n",
      "515/515 [==============================] - 0s 826us/sample - loss: 0.2532 - acc: 0.9029 - val_loss: 0.3035 - val_acc: 0.8915\n",
      "Epoch 395/500\n",
      "515/515 [==============================] - 0s 792us/sample - loss: 0.2269 - acc: 0.9068 - val_loss: 0.3334 - val_acc: 0.8915\n",
      "Epoch 396/500\n",
      "515/515 [==============================] - 0s 760us/sample - loss: 0.2576 - acc: 0.8913 - val_loss: 0.3487 - val_acc: 0.8682\n",
      "Epoch 397/500\n",
      "515/515 [==============================] - 0s 768us/sample - loss: 0.2432 - acc: 0.9165 - val_loss: 0.3382 - val_acc: 0.8992\n",
      "Epoch 398/500\n",
      "515/515 [==============================] - 0s 772us/sample - loss: 0.2392 - acc: 0.9087 - val_loss: 0.3534 - val_acc: 0.8837\n",
      "Epoch 399/500\n",
      "515/515 [==============================] - 0s 802us/sample - loss: 0.2397 - acc: 0.9029 - val_loss: 0.3359 - val_acc: 0.8915\n",
      "Epoch 400/500\n",
      "515/515 [==============================] - 0s 697us/sample - loss: 0.2182 - acc: 0.9107 - val_loss: 0.3226 - val_acc: 0.8992\n",
      "Epoch 401/500\n",
      "515/515 [==============================] - 0s 743us/sample - loss: 0.2221 - acc: 0.9029 - val_loss: 0.3500 - val_acc: 0.8992\n",
      "Epoch 402/500\n",
      "515/515 [==============================] - 0s 797us/sample - loss: 0.2447 - acc: 0.9029 - val_loss: 0.3418 - val_acc: 0.9070\n",
      "Epoch 403/500\n",
      "515/515 [==============================] - 0s 852us/sample - loss: 0.2265 - acc: 0.9146 - val_loss: 0.3227 - val_acc: 0.8837\n",
      "Epoch 404/500\n",
      "515/515 [==============================] - 0s 746us/sample - loss: 0.2242 - acc: 0.9223 - val_loss: 0.3475 - val_acc: 0.8837\n",
      "Epoch 405/500\n",
      "515/515 [==============================] - 0s 778us/sample - loss: 0.2483 - acc: 0.9010 - val_loss: 0.3621 - val_acc: 0.8605\n",
      "Epoch 406/500\n",
      "515/515 [==============================] - 0s 857us/sample - loss: 0.2238 - acc: 0.9068 - val_loss: 0.2942 - val_acc: 0.8992\n",
      "Epoch 407/500\n",
      "515/515 [==============================] - 0s 780us/sample - loss: 0.2321 - acc: 0.9126 - val_loss: 0.3131 - val_acc: 0.8915\n",
      "Epoch 408/500\n",
      "515/515 [==============================] - 0s 748us/sample - loss: 0.2465 - acc: 0.9126 - val_loss: 0.3479 - val_acc: 0.8837\n",
      "Epoch 409/500\n",
      "515/515 [==============================] - 0s 777us/sample - loss: 0.2321 - acc: 0.9146 - val_loss: 0.3364 - val_acc: 0.8915\n",
      "Epoch 410/500\n",
      "515/515 [==============================] - 0s 804us/sample - loss: 0.2494 - acc: 0.9068 - val_loss: 0.3160 - val_acc: 0.8915\n",
      "Epoch 411/500\n",
      "515/515 [==============================] - 0s 848us/sample - loss: 0.2276 - acc: 0.9184 - val_loss: 0.3305 - val_acc: 0.8915\n",
      "Epoch 412/500\n",
      "515/515 [==============================] - 0s 856us/sample - loss: 0.2370 - acc: 0.9029 - val_loss: 0.3260 - val_acc: 0.8760\n",
      "Epoch 413/500\n",
      "515/515 [==============================] - 0s 884us/sample - loss: 0.2519 - acc: 0.9029 - val_loss: 0.3200 - val_acc: 0.9147\n",
      "Epoch 414/500\n",
      "515/515 [==============================] - 0s 866us/sample - loss: 0.2281 - acc: 0.9087 - val_loss: 0.3673 - val_acc: 0.8837\n",
      "Epoch 415/500\n",
      "515/515 [==============================] - 0s 808us/sample - loss: 0.2412 - acc: 0.9049 - val_loss: 0.2951 - val_acc: 0.8837\n",
      "Epoch 416/500\n",
      "515/515 [==============================] - 0s 829us/sample - loss: 0.2342 - acc: 0.9282 - val_loss: 0.3141 - val_acc: 0.9070\n",
      "Epoch 417/500\n",
      "515/515 [==============================] - 0s 789us/sample - loss: 0.2381 - acc: 0.9107 - val_loss: 0.3375 - val_acc: 0.8992\n",
      "Epoch 418/500\n",
      "515/515 [==============================] - 0s 759us/sample - loss: 0.2815 - acc: 0.8971 - val_loss: 0.2942 - val_acc: 0.8915\n",
      "Epoch 419/500\n",
      "515/515 [==============================] - 0s 764us/sample - loss: 0.2331 - acc: 0.9010 - val_loss: 0.3512 - val_acc: 0.9070\n",
      "Epoch 420/500\n",
      "515/515 [==============================] - 0s 798us/sample - loss: 0.2633 - acc: 0.9010 - val_loss: 0.3544 - val_acc: 0.8837\n",
      "Epoch 421/500\n",
      "515/515 [==============================] - 0s 712us/sample - loss: 0.2928 - acc: 0.8893 - val_loss: 0.3253 - val_acc: 0.8760\n",
      "Epoch 422/500\n",
      "515/515 [==============================] - 0s 803us/sample - loss: 0.2437 - acc: 0.9029 - val_loss: 0.3528 - val_acc: 0.8760\n",
      "Epoch 423/500\n",
      "515/515 [==============================] - 0s 884us/sample - loss: 0.2276 - acc: 0.9010 - val_loss: 0.3148 - val_acc: 0.8992\n",
      "Epoch 424/500\n",
      "515/515 [==============================] - 0s 776us/sample - loss: 0.2129 - acc: 0.9107 - val_loss: 0.3125 - val_acc: 0.8837\n",
      "Epoch 425/500\n",
      "515/515 [==============================] - 0s 861us/sample - loss: 0.2301 - acc: 0.9049 - val_loss: 0.3170 - val_acc: 0.8837\n",
      "Epoch 426/500\n",
      "515/515 [==============================] - 0s 925us/sample - loss: 0.2181 - acc: 0.9126 - val_loss: 0.3113 - val_acc: 0.9070\n",
      "Epoch 427/500\n",
      "515/515 [==============================] - 0s 904us/sample - loss: 0.2512 - acc: 0.9068 - val_loss: 0.3173 - val_acc: 0.9225\n",
      "Epoch 428/500\n",
      "515/515 [==============================] - 0s 837us/sample - loss: 0.2315 - acc: 0.9184 - val_loss: 0.3434 - val_acc: 0.8915\n",
      "Epoch 429/500\n",
      "515/515 [==============================] - 0s 849us/sample - loss: 0.2199 - acc: 0.9223 - val_loss: 0.3243 - val_acc: 0.8915\n",
      "Epoch 430/500\n",
      "515/515 [==============================] - 0s 746us/sample - loss: 0.2128 - acc: 0.9184 - val_loss: 0.2843 - val_acc: 0.8992\n",
      "Epoch 431/500\n",
      "515/515 [==============================] - 0s 767us/sample - loss: 0.2293 - acc: 0.9107 - val_loss: 0.3442 - val_acc: 0.8682\n",
      "Epoch 432/500\n",
      "515/515 [==============================] - 0s 781us/sample - loss: 0.2289 - acc: 0.9029 - val_loss: 0.3228 - val_acc: 0.8915\n",
      "Epoch 433/500\n",
      "515/515 [==============================] - 0s 819us/sample - loss: 0.2272 - acc: 0.9107 - val_loss: 0.3132 - val_acc: 0.8760\n",
      "Epoch 434/500\n",
      "515/515 [==============================] - 0s 806us/sample - loss: 0.2237 - acc: 0.9146 - val_loss: 0.3281 - val_acc: 0.9147\n",
      "Epoch 435/500\n",
      "515/515 [==============================] - 0s 817us/sample - loss: 0.2518 - acc: 0.9049 - val_loss: 0.3509 - val_acc: 0.8992\n",
      "Epoch 436/500\n",
      "515/515 [==============================] - 0s 717us/sample - loss: 0.2329 - acc: 0.9165 - val_loss: 0.3046 - val_acc: 0.8915\n",
      "Epoch 437/500\n",
      "515/515 [==============================] - 0s 828us/sample - loss: 0.2165 - acc: 0.9126 - val_loss: 0.3391 - val_acc: 0.8837\n",
      "Epoch 438/500\n",
      "515/515 [==============================] - 0s 892us/sample - loss: 0.2242 - acc: 0.9165 - val_loss: 0.3134 - val_acc: 0.8760\n",
      "Epoch 439/500\n",
      "515/515 [==============================] - 0s 818us/sample - loss: 0.2112 - acc: 0.9165 - val_loss: 0.3156 - val_acc: 0.8915\n",
      "Epoch 440/500\n",
      "515/515 [==============================] - 0s 839us/sample - loss: 0.2020 - acc: 0.9223 - val_loss: 0.3089 - val_acc: 0.8837\n",
      "Epoch 441/500\n",
      "515/515 [==============================] - 0s 800us/sample - loss: 0.2249 - acc: 0.9029 - val_loss: 0.3503 - val_acc: 0.8915\n",
      "Epoch 442/500\n",
      "515/515 [==============================] - 0s 824us/sample - loss: 0.2172 - acc: 0.9204 - val_loss: 0.3284 - val_acc: 0.8605\n",
      "Epoch 443/500\n",
      "515/515 [==============================] - 0s 781us/sample - loss: 0.2410 - acc: 0.9126 - val_loss: 0.3368 - val_acc: 0.9070\n",
      "Epoch 444/500\n",
      "515/515 [==============================] - 0s 827us/sample - loss: 0.2278 - acc: 0.9107 - val_loss: 0.3743 - val_acc: 0.8837\n",
      "Epoch 445/500\n",
      "515/515 [==============================] - 0s 753us/sample - loss: 0.2267 - acc: 0.9049 - val_loss: 0.3552 - val_acc: 0.8992\n",
      "Epoch 446/500\n",
      "515/515 [==============================] - 0s 863us/sample - loss: 0.2265 - acc: 0.9184 - val_loss: 0.3267 - val_acc: 0.8915\n",
      "Epoch 447/500\n",
      "515/515 [==============================] - 0s 850us/sample - loss: 0.2678 - acc: 0.9029 - val_loss: 0.3081 - val_acc: 0.8760\n",
      "Epoch 448/500\n",
      "515/515 [==============================] - 0s 857us/sample - loss: 0.2383 - acc: 0.9029 - val_loss: 0.3017 - val_acc: 0.8915\n",
      "Epoch 449/500\n",
      "515/515 [==============================] - 0s 783us/sample - loss: 0.2328 - acc: 0.9165 - val_loss: 0.3153 - val_acc: 0.8837\n",
      "Epoch 450/500\n",
      "515/515 [==============================] - 0s 774us/sample - loss: 0.2233 - acc: 0.9223 - val_loss: 0.3234 - val_acc: 0.8992\n",
      "Epoch 451/500\n",
      "515/515 [==============================] - 0s 875us/sample - loss: 0.2151 - acc: 0.9204 - val_loss: 0.3252 - val_acc: 0.8760\n",
      "Epoch 452/500\n",
      "515/515 [==============================] - 0s 824us/sample - loss: 0.2106 - acc: 0.9204 - val_loss: 0.2883 - val_acc: 0.8915\n",
      "Epoch 453/500\n",
      "515/515 [==============================] - 0s 752us/sample - loss: 0.2198 - acc: 0.9087 - val_loss: 0.3025 - val_acc: 0.8915\n",
      "Epoch 454/500\n",
      "515/515 [==============================] - 0s 738us/sample - loss: 0.2134 - acc: 0.9049 - val_loss: 0.3247 - val_acc: 0.8760\n",
      "Epoch 455/500\n",
      "515/515 [==============================] - 0s 861us/sample - loss: 0.2492 - acc: 0.9107 - val_loss: 0.3221 - val_acc: 0.8992\n",
      "Epoch 456/500\n",
      "515/515 [==============================] - 0s 757us/sample - loss: 0.2327 - acc: 0.9126 - val_loss: 0.3205 - val_acc: 0.8837\n",
      "Epoch 457/500\n",
      "515/515 [==============================] - 0s 727us/sample - loss: 0.2159 - acc: 0.9223 - val_loss: 0.2927 - val_acc: 0.8992\n",
      "Epoch 458/500\n",
      "515/515 [==============================] - 0s 790us/sample - loss: 0.2132 - acc: 0.9243 - val_loss: 0.3377 - val_acc: 0.8682\n",
      "Epoch 459/500\n",
      "515/515 [==============================] - 0s 779us/sample - loss: 0.2611 - acc: 0.9010 - val_loss: 0.3512 - val_acc: 0.8760\n",
      "Epoch 460/500\n",
      "515/515 [==============================] - 0s 814us/sample - loss: 0.2291 - acc: 0.9029 - val_loss: 0.3053 - val_acc: 0.8992\n",
      "Epoch 461/500\n",
      "515/515 [==============================] - 0s 906us/sample - loss: 0.2848 - acc: 0.9068 - val_loss: 0.4222 - val_acc: 0.8450\n",
      "Epoch 462/500\n",
      "515/515 [==============================] - 0s 821us/sample - loss: 0.3072 - acc: 0.8932 - val_loss: 0.3196 - val_acc: 0.9147\n",
      "Epoch 463/500\n",
      "515/515 [==============================] - 0s 884us/sample - loss: 0.3074 - acc: 0.8874 - val_loss: 0.3272 - val_acc: 0.8915\n",
      "Epoch 464/500\n",
      "515/515 [==============================] - 0s 801us/sample - loss: 0.2496 - acc: 0.9107 - val_loss: 0.3141 - val_acc: 0.8992\n",
      "Epoch 465/500\n",
      "515/515 [==============================] - 0s 788us/sample - loss: 0.2805 - acc: 0.8990 - val_loss: 0.3284 - val_acc: 0.8837\n",
      "Epoch 466/500\n",
      "515/515 [==============================] - 0s 719us/sample - loss: 0.2551 - acc: 0.9029 - val_loss: 0.3192 - val_acc: 0.8837\n",
      "Epoch 467/500\n",
      "515/515 [==============================] - 0s 850us/sample - loss: 0.2538 - acc: 0.9010 - val_loss: 0.3417 - val_acc: 0.8837\n",
      "Epoch 468/500\n",
      "515/515 [==============================] - 0s 834us/sample - loss: 0.2221 - acc: 0.9126 - val_loss: 0.2912 - val_acc: 0.8915\n",
      "Epoch 469/500\n",
      "515/515 [==============================] - 0s 824us/sample - loss: 0.2477 - acc: 0.9068 - val_loss: 0.2945 - val_acc: 0.8992\n",
      "Epoch 470/500\n",
      "515/515 [==============================] - 0s 857us/sample - loss: 0.2380 - acc: 0.9049 - val_loss: 0.2990 - val_acc: 0.8837\n",
      "Epoch 471/500\n",
      "515/515 [==============================] - 0s 847us/sample - loss: 0.2207 - acc: 0.9068 - val_loss: 0.3316 - val_acc: 0.8915\n",
      "Epoch 472/500\n",
      "515/515 [==============================] - 0s 915us/sample - loss: 0.2418 - acc: 0.8971 - val_loss: 0.3111 - val_acc: 0.8992\n",
      "Epoch 473/500\n",
      "515/515 [==============================] - 0s 872us/sample - loss: 0.2218 - acc: 0.9146 - val_loss: 0.3078 - val_acc: 0.9147\n",
      "Epoch 474/500\n",
      "515/515 [==============================] - 0s 865us/sample - loss: 0.2325 - acc: 0.9087 - val_loss: 0.3075 - val_acc: 0.8915\n",
      "Epoch 475/500\n",
      "515/515 [==============================] - 0s 896us/sample - loss: 0.2309 - acc: 0.9126 - val_loss: 0.2942 - val_acc: 0.8760\n",
      "Epoch 476/500\n",
      "515/515 [==============================] - 0s 914us/sample - loss: 0.2263 - acc: 0.9107 - val_loss: 0.2973 - val_acc: 0.8992\n",
      "Epoch 477/500\n",
      "515/515 [==============================] - 0s 929us/sample - loss: 0.2408 - acc: 0.9049 - val_loss: 0.3715 - val_acc: 0.8527\n",
      "Epoch 478/500\n",
      "515/515 [==============================] - 0s 860us/sample - loss: 0.2182 - acc: 0.9126 - val_loss: 0.2952 - val_acc: 0.8992\n",
      "Epoch 479/500\n",
      "515/515 [==============================] - 0s 831us/sample - loss: 0.2045 - acc: 0.9223 - val_loss: 0.3489 - val_acc: 0.8992\n",
      "Epoch 480/500\n",
      "515/515 [==============================] - 0s 810us/sample - loss: 0.2238 - acc: 0.9165 - val_loss: 0.3039 - val_acc: 0.8915\n",
      "Epoch 481/500\n",
      "515/515 [==============================] - 0s 775us/sample - loss: 0.2340 - acc: 0.9068 - val_loss: 0.2921 - val_acc: 0.8837\n",
      "Epoch 482/500\n",
      "515/515 [==============================] - 0s 885us/sample - loss: 0.2147 - acc: 0.9107 - val_loss: 0.3246 - val_acc: 0.8915\n",
      "Epoch 483/500\n",
      "515/515 [==============================] - 0s 803us/sample - loss: 0.2400 - acc: 0.9068 - val_loss: 0.3480 - val_acc: 0.8915\n",
      "Epoch 484/500\n",
      "515/515 [==============================] - 0s 736us/sample - loss: 0.2397 - acc: 0.9087 - val_loss: 0.3205 - val_acc: 0.8915\n",
      "Epoch 485/500\n",
      "515/515 [==============================] - 0s 811us/sample - loss: 0.2173 - acc: 0.9146 - val_loss: 0.3878 - val_acc: 0.8760\n",
      "Epoch 486/500\n",
      "515/515 [==============================] - 0s 816us/sample - loss: 0.2249 - acc: 0.9107 - val_loss: 0.3443 - val_acc: 0.8837\n",
      "Epoch 487/500\n",
      "515/515 [==============================] - 0s 814us/sample - loss: 0.2259 - acc: 0.9087 - val_loss: 0.3338 - val_acc: 0.8837\n",
      "Epoch 488/500\n",
      "515/515 [==============================] - 0s 818us/sample - loss: 0.2220 - acc: 0.9049 - val_loss: 0.3253 - val_acc: 0.8915\n",
      "Epoch 489/500\n",
      "515/515 [==============================] - 0s 772us/sample - loss: 0.2148 - acc: 0.9223 - val_loss: 0.3083 - val_acc: 0.8992\n",
      "Epoch 490/500\n",
      "515/515 [==============================] - 0s 841us/sample - loss: 0.2241 - acc: 0.9087 - val_loss: 0.3038 - val_acc: 0.8915\n",
      "Epoch 491/500\n",
      "515/515 [==============================] - 0s 807us/sample - loss: 0.2250 - acc: 0.9165 - val_loss: 0.3322 - val_acc: 0.9070\n",
      "Epoch 492/500\n",
      "515/515 [==============================] - 0s 795us/sample - loss: 0.2479 - acc: 0.9049 - val_loss: 0.3209 - val_acc: 0.8915\n",
      "Epoch 493/500\n",
      "515/515 [==============================] - 0s 757us/sample - loss: 0.2316 - acc: 0.9087 - val_loss: 0.3099 - val_acc: 0.8915\n",
      "Epoch 494/500\n",
      "515/515 [==============================] - 0s 817us/sample - loss: 0.2251 - acc: 0.9068 - val_loss: 0.3158 - val_acc: 0.8837\n",
      "Epoch 495/500\n",
      "515/515 [==============================] - 0s 806us/sample - loss: 0.2510 - acc: 0.9262 - val_loss: 0.3126 - val_acc: 0.8915\n",
      "Epoch 496/500\n",
      "515/515 [==============================] - 0s 746us/sample - loss: 0.2439 - acc: 0.8971 - val_loss: 0.3236 - val_acc: 0.8837\n",
      "Epoch 497/500\n",
      "515/515 [==============================] - 0s 753us/sample - loss: 0.2012 - acc: 0.9146 - val_loss: 0.3186 - val_acc: 0.8992\n",
      "Epoch 498/500\n",
      "515/515 [==============================] - 0s 780us/sample - loss: 0.2249 - acc: 0.8951 - val_loss: 0.3105 - val_acc: 0.8992\n",
      "Epoch 499/500\n",
      "515/515 [==============================] - 0s 737us/sample - loss: 0.2308 - acc: 0.9204 - val_loss: 0.3105 - val_acc: 0.8992\n",
      "Epoch 500/500\n",
      "515/515 [==============================] - 0s 788us/sample - loss: 0.2073 - acc: 0.9068 - val_loss: 0.3272 - val_acc: 0.8915\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=16,\n",
    "                    epochs=500,\n",
    "\n",
    "                    validation_data=(x_vl, y_vl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "KqMl5V5y0qeB",
    "outputId": "e4291c24-57b6-4069-d79b-87fc1fa683ac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "N14_-C010qeD",
    "outputId": "6702d389-3a1d-48d3-f4ed-fe9f5f7421c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276/276 [==============================] - 1s 2ms/sample - loss: 0.4183 - acc: 0.8587\n",
      "\n",
      "m=3, test=C\n",
      " test loss: 0.4182543778333111\n",
      "  test acc: 0.8586956262588501\n"
     ]
    }
   ],
   "source": [
    "ts_x=np.array(ts_x).reshape(ts_x.shape[0],7,1)\n",
    "results1=model.evaluate(ts_x, ts_y, batch_size=32)\n",
    "print('\\nm=3, test=C\\n test loss: {}\\n  test acc: {}'.format(results1[0],results1[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Q9gBF63g0qeF",
    "outputId": "647098b3-32e5-4bb9-f4c1-793459137888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695/695 [==============================] - 0s 542us/sample - loss: 0.2521 - acc: 0.9209\n",
      "\n",
      "m=3, test=D\n",
      " test loss: 0.2521416136418744\n",
      "  test acc: 0.9208633303642273\n"
     ]
    }
   ],
   "source": [
    "ts_x2=np.array(ts_x2).reshape(ts_x2.shape[0],7,1)\n",
    "results2=model.evaluate(ts_x2, ts_y2, batch_size=32)\n",
    "print('\\nm=3, test=D\\n test loss: {}\\n  test acc: {}'.format(results2[0],results2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFYFLr6u0qeH"
   },
   "outputs": [],
   "source": [
    "## check where model did not predict correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "a5zto9F3RQL6",
    "outputId": "7fa22b26-bfa5-4af0-c2f6-2b214591da5f"
   },
   "outputs": [],
   "source": [
    "_, _, ts_x_df, ts_y_lbl, ts_x2_df, ts_y2_lbl = generate_tr_ts(df1=central, df2=site, m=4, method=None, h=3000, seed=2019, normalize=False,scaling_method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nt61WyvfRQL8"
   },
   "outputs": [],
   "source": [
    "def prediction(encoder, model, test_x):\n",
    "    pred=model.predict(test_x)\n",
    "    return encoder.inverse_transform(np.round(pred))\n",
    "def return_predict(encoder, model, test_x, test_y):\n",
    "    pred=prediction(encoder, model, test_x)\n",
    "    results=[pred==true for pred, true in list(zip(pred,test_y))]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T-sA6a81RQL-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSUM</th>\n",
       "      <th>SUMDIAM</th>\n",
       "      <th>PCBSD</th>\n",
       "      <th>NADIR</th>\n",
       "      <th>ACNSD</th>\n",
       "      <th>PCNSD</th>\n",
       "      <th>NEWLSN</th>\n",
       "      <th>Label</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>34</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-47.058824</td>\n",
       "      <td>19</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>88</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-72.727273</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>PD</td>\n",
       "      <td>CR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>147</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-56.462585</td>\n",
       "      <td>82</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>60</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-43.333333</td>\n",
       "      <td>35</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>111</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-45.045045</td>\n",
       "      <td>111</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-45</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>46</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-21.739130</td>\n",
       "      <td>46</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>183</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-61.748634</td>\n",
       "      <td>75</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>1</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>180</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-29.444444</td>\n",
       "      <td>180</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-29</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>PR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>85</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-34.117647</td>\n",
       "      <td>59</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>107</td>\n",
       "      <td>180.0</td>\n",
       "      <td>68.224299</td>\n",
       "      <td>107</td>\n",
       "      <td>73.0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>85</td>\n",
       "      <td>113.0</td>\n",
       "      <td>32.941176</td>\n",
       "      <td>85</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>73</td>\n",
       "      <td>132.0</td>\n",
       "      <td>80.821918</td>\n",
       "      <td>73</td>\n",
       "      <td>59.0</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>35</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-11.428571</td>\n",
       "      <td>35</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>1</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>68</td>\n",
       "      <td>103.0</td>\n",
       "      <td>51.470588</td>\n",
       "      <td>68</td>\n",
       "      <td>35.0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>75</td>\n",
       "      <td>121.0</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>75</td>\n",
       "      <td>46.0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>15</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>32</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-21.875000</td>\n",
       "      <td>32</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>30</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>52</td>\n",
       "      <td>70.0</td>\n",
       "      <td>34.615385</td>\n",
       "      <td>52</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>247</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-61.538462</td>\n",
       "      <td>247</td>\n",
       "      <td>-152.0</td>\n",
       "      <td>-62</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>90</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-48.888889</td>\n",
       "      <td>51</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-10</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>146</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-58.904110</td>\n",
       "      <td>58</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>99</td>\n",
       "      <td>119.0</td>\n",
       "      <td>20.202020</td>\n",
       "      <td>99</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>138</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-34.057971</td>\n",
       "      <td>97</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>47</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-19.148936</td>\n",
       "      <td>34</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>30</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-29</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>85</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3429.411765</td>\n",
       "      <td>85</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NE</td>\n",
       "      <td>NE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>64</td>\n",
       "      <td>79.0</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>64</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>39</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-46.153846</td>\n",
       "      <td>25</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>21</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-76.190476</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-17</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>147</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-62.585034</td>\n",
       "      <td>64</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>17</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-52.941176</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>CR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>52</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>221</td>\n",
       "      <td>255.0</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>221</td>\n",
       "      <td>34.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>111</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-57.657658</td>\n",
       "      <td>50</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>193</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-52.331606</td>\n",
       "      <td>106</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-13</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>71</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-16.901408</td>\n",
       "      <td>71</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-17</td>\n",
       "      <td>1</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>50</td>\n",
       "      <td>55.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>15.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>191</td>\n",
       "      <td>155.0</td>\n",
       "      <td>-18.848168</td>\n",
       "      <td>191</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-19</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>85</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-44.705882</td>\n",
       "      <td>59</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-20</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>168</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-45.833333</td>\n",
       "      <td>83</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>35</td>\n",
       "      <td>40.0</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>12</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-17</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>CR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>56</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-64.285714</td>\n",
       "      <td>12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>146</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-60.273973</td>\n",
       "      <td>74</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>37</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-62.162162</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>CR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>123</td>\n",
       "      <td>180.0</td>\n",
       "      <td>46.341463</td>\n",
       "      <td>123</td>\n",
       "      <td>57.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>45</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>35</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-54.285714</td>\n",
       "      <td>35</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-54</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>147</td>\n",
       "      <td>138.0</td>\n",
       "      <td>-6.122449</td>\n",
       "      <td>147</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>240</td>\n",
       "      <td>157.0</td>\n",
       "      <td>-34.583333</td>\n",
       "      <td>149</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>102</td>\n",
       "      <td>154.0</td>\n",
       "      <td>50.980392</td>\n",
       "      <td>102</td>\n",
       "      <td>52.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>35</td>\n",
       "      <td>46.0</td>\n",
       "      <td>31.428571</td>\n",
       "      <td>35</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>91</td>\n",
       "      <td>153.0</td>\n",
       "      <td>68.131868</td>\n",
       "      <td>91</td>\n",
       "      <td>62.0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>34</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-5.882353</td>\n",
       "      <td>34</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>88</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-68.181818</td>\n",
       "      <td>88</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-68</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>126</td>\n",
       "      <td>138.0</td>\n",
       "      <td>9.523810</td>\n",
       "      <td>124</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>143</td>\n",
       "      <td>191.0</td>\n",
       "      <td>33.566434</td>\n",
       "      <td>143</td>\n",
       "      <td>48.0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>46</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BSUM  SUMDIAM        PCBSD  NADIR  ACNSD  PCNSD  NEWLSN Label Pred  \\\n",
       "154    34     18.0   -47.058824     19   -1.0     -5       0    PR   PR   \n",
       "809    88     24.0   -72.727273     19    5.0     26       0    PD   CR   \n",
       "821   147     64.0   -56.462585     82  -18.0    -22       0    PR   PR   \n",
       "845    60     34.0   -43.333333     35   -1.0     -3       1    PR   PR   \n",
       "430   111     61.0   -45.045045    111  -50.0    -45       0    PR   PR   \n",
       "435    46     36.0   -21.739130     46  -10.0    -22       0    SD   SD   \n",
       "97    183     70.0   -61.748634     75   -5.0     -7       1    PR   PR   \n",
       "191   180    127.0   -29.444444    180  -53.0    -29       0    SD   PR   \n",
       "81     85     56.0   -34.117647     59   -3.0     -5       1    PR   PR   \n",
       "150   107    180.0    68.224299    107   73.0     68       1    PD   PD   \n",
       "310    85    113.0    32.941176     85   28.0     33       1    PD   PD   \n",
       "18     73    132.0    80.821918     73   59.0     81       1    PD   PD   \n",
       "772    35     31.0   -11.428571     35   -4.0    -11       1    SD   SD   \n",
       "635    68    103.0    51.470588     68   35.0     51       1    PD   PD   \n",
       "217    75    121.0    61.333333     75   46.0     61       1    PD   PD   \n",
       "752    15     17.0    13.333333     14    3.0     21       1    SD   SD   \n",
       "457    32     25.0   -21.875000     32   -7.0    -22       0    SD   SD   \n",
       "726    30     15.0   -50.000000     12    3.0     25       1    CR   CR   \n",
       "917    52     70.0    34.615385     52   18.0     35       1    PD   PD   \n",
       "203   247     95.0   -61.538462    247 -152.0    -62       0    PR   PR   \n",
       "535    90     46.0   -48.888889     51   -5.0    -10       0    PR   PR   \n",
       "743   146     60.0   -58.904110     58    2.0      3       0    PR   PR   \n",
       "800    99    119.0    20.202020     99   20.0     20       1    PD   PD   \n",
       "449   138     91.0   -34.057971     97   -6.0     -6       0    PR   PR   \n",
       "667    47     38.0   -19.148936     34    4.0     12       0    SD   SD   \n",
       "665    30     15.0   -50.000000     21   -6.0    -29       0    PR   PR   \n",
       "309    85   3000.0  3429.411765     85   31.5      0       0    NE   NE   \n",
       "879    64     79.0    23.437500     64   15.0     23       0    PD   PD   \n",
       "88     39     21.0   -46.153846     25   -4.0    -16       0    PR   PR   \n",
       "641    21      5.0   -76.190476      6   -1.0    -17       0    CR   CR   \n",
       "..    ...      ...          ...    ...    ...    ...     ...   ...  ...   \n",
       "822   147     55.0   -62.585034     64   -9.0    -14       0    PR   PR   \n",
       "577    17      8.0   -52.941176      7    1.0     14       0    PR   CR   \n",
       "655    52     52.0     0.000000     49    3.0      6       1    SD   SD   \n",
       "475   221    255.0    15.384615    221   34.0     15       0    SD   SD   \n",
       "432   111     47.0   -57.657658     50   -3.0     -6       0    PR   PR   \n",
       "628   193     92.0   -52.331606    106  -14.0    -13       0    PR   PR   \n",
       "789    71     59.0   -16.901408     71  -12.0    -17       1    SD   SD   \n",
       "284    50     55.0    10.000000     40   15.0     38       0    PD   PD   \n",
       "792   191    155.0   -18.848168    191  -36.0    -19       0    SD   SD   \n",
       "375    85     47.0   -44.705882     59  -12.0    -20       0    PR   PR   \n",
       "133   168     91.0   -45.833333     83    8.0     10       0    PR   PR   \n",
       "690    35     40.0    14.285714     35    5.0     14       1    SD   SD   \n",
       "12     30     10.0   -66.666667     12   -2.0    -17       0    PR   CR   \n",
       "595    56     20.0   -64.285714     12    8.0     67       0    PD   PD   \n",
       "741   146     58.0   -60.273973     74  -16.0    -22       0    PR   PR   \n",
       "199    37     14.0   -62.162162     12    2.0     17       0    PR   CR   \n",
       "176   123    180.0    46.341463    123   57.0     46       0    PD   PD   \n",
       "16     45     15.0   -66.666667     15    0.0      0       0    CR   CR   \n",
       "106    56      0.0  -100.000000      0    0.0      0       0    CR   CR   \n",
       "396    35     16.0   -54.285714     35  -19.0    -54       0    PR   PR   \n",
       "271   147    138.0    -6.122449    147   -9.0     -6       0    SD   SD   \n",
       "797   240    157.0   -34.583333    149    8.0      5       1    PR   PR   \n",
       "24    102    154.0    50.980392    102   52.0     51       0    PD   PD   \n",
       "758    35     46.0    31.428571     35   11.0     31       0    PD   PD   \n",
       "190    91    153.0    68.131868     91   62.0     68       1    PD   PD   \n",
       "728    34     32.0    -5.882353     34   -2.0     -6       0    SD   SD   \n",
       "805    88     28.0   -68.181818     88  -60.0    -68       0    PR   PR   \n",
       "159   126    138.0     9.523810    124   14.0     11       1    SD   SD   \n",
       "370   143    191.0    33.566434    143   48.0     34       1    PD   PD   \n",
       "72     46     23.0   -50.000000     24   -1.0     -4       0    PR   PR   \n",
       "\n",
       "     Correct  \n",
       "154     True  \n",
       "809    False  \n",
       "821     True  \n",
       "845     True  \n",
       "430     True  \n",
       "435     True  \n",
       "97      True  \n",
       "191    False  \n",
       "81      True  \n",
       "150     True  \n",
       "310     True  \n",
       "18      True  \n",
       "772     True  \n",
       "635     True  \n",
       "217     True  \n",
       "752     True  \n",
       "457     True  \n",
       "726     True  \n",
       "917     True  \n",
       "203     True  \n",
       "535     True  \n",
       "743     True  \n",
       "800     True  \n",
       "449     True  \n",
       "667     True  \n",
       "665     True  \n",
       "309     True  \n",
       "879     True  \n",
       "88      True  \n",
       "641     True  \n",
       "..       ...  \n",
       "822     True  \n",
       "577    False  \n",
       "655     True  \n",
       "475     True  \n",
       "432     True  \n",
       "628     True  \n",
       "789     True  \n",
       "284     True  \n",
       "792     True  \n",
       "375     True  \n",
       "133     True  \n",
       "690     True  \n",
       "12     False  \n",
       "595     True  \n",
       "741     True  \n",
       "199    False  \n",
       "176     True  \n",
       "16      True  \n",
       "106     True  \n",
       "396     True  \n",
       "271     True  \n",
       "797     True  \n",
       "24      True  \n",
       "758     True  \n",
       "190     True  \n",
       "728     True  \n",
       "805     True  \n",
       "159     True  \n",
       "370     True  \n",
       "72      True  \n",
       "\n",
       "[276 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_x_df['Label']=ts_y_lbl['TRGRESP']\n",
    "ts_x_df['Pred']=prediction(encoder, model, ts_x)\n",
    "ts_x_df['Correct']=return_predict(encoder, model, ts_x, ts_y_lbl['TRGRESP'])\n",
    "ts_x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMav1ZBNRQMC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSUM</th>\n",
       "      <th>SUMDIAM</th>\n",
       "      <th>PCBSD</th>\n",
       "      <th>NADIR</th>\n",
       "      <th>ACNSD</th>\n",
       "      <th>PCNSD</th>\n",
       "      <th>NEWLSN</th>\n",
       "      <th>Label</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>101.886792</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-43.243243</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-43</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-51.351351</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>59.090909</td>\n",
       "      <td>44.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-60</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PD</td>\n",
       "      <td>CR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-67</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>18.918919</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>37.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>24.324324</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>40.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>312.500000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>313</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>40.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>317.500000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>195.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>-17.435897</td>\n",
       "      <td>195.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>-17</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>195.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>-8.717949</td>\n",
       "      <td>161.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>195.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>-1.538462</td>\n",
       "      <td>161.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>PD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>84.8</td>\n",
       "      <td>118.5</td>\n",
       "      <td>39.740566</td>\n",
       "      <td>84.8</td>\n",
       "      <td>33.7</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>200.7</td>\n",
       "      <td>382.7</td>\n",
       "      <td>90.682611</td>\n",
       "      <td>200.7</td>\n",
       "      <td>182.0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>99.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>64.646465</td>\n",
       "      <td>99.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>79.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>-1.265823</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>79.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>-1.265823</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>103.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-52.427184</td>\n",
       "      <td>103.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-52</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>103.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-56.310680</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>103.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-66.019417</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>131.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>15.267176</td>\n",
       "      <td>131.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>206.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-62.621359</td>\n",
       "      <td>206.0</td>\n",
       "      <td>-129.0</td>\n",
       "      <td>-63</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>206.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-63.592233</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>62.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-56.451613</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-56</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>37.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-5.405405</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.405405</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>34.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>47.058824</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>PD</td>\n",
       "      <td>PD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>85.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-57.647059</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-58</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>77.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>77.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>77.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-15.584416</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>77.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-38.961039</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-28</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>77.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-40.259740</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>90.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-43.333333</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-43</td>\n",
       "      <td>0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.985075</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>157.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>5.732484</td>\n",
       "      <td>157.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>695 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BSUM  SUMDIAM       PCBSD  NADIR  ACNSD  PCNSD  NEWLSN Label Pred  \\\n",
       "0     53.0    107.0  101.886792   53.0   54.0    102       1    PD   PD   \n",
       "1     37.0     21.0  -43.243243   37.0  -16.0    -43       0    PR   PR   \n",
       "2     37.0     18.0  -51.351351   21.0   -3.0    -14       0    PR   PR   \n",
       "3     37.0      0.0 -100.000000    5.0   -5.0   -100       0    CR   CR   \n",
       "4     37.0      0.0 -100.000000    0.0    0.0      0       0    CR   CR   \n",
       "5     37.0      0.0 -100.000000    0.0    0.0      0       0    CR   CR   \n",
       "6     44.0     70.0   59.090909   44.0   26.0     59       1    PD   PD   \n",
       "7     30.0     12.0  -60.000000   30.0  -18.0    -60       0    PR   PR   \n",
       "8     30.0      0.0 -100.000000   12.0  -12.0   -100       0    CR   CR   \n",
       "9     30.0     15.0  -50.000000    0.0   15.0      0       0    PD   CR   \n",
       "10    15.0      5.0  -66.666667   15.0  -10.0    -67       0    CR   CR   \n",
       "11    15.0      5.0  -66.666667    5.0    0.0      0       0    CR   CR   \n",
       "12    15.0      5.0  -66.666667    5.0    0.0      0       0    CR   CR   \n",
       "13    15.0      5.0  -66.666667    5.0    0.0      0       0    CR   CR   \n",
       "14    15.0      0.0 -100.000000    8.0   -8.0   -100       0    CR   CR   \n",
       "15    37.0     44.0   18.918919   37.0    7.0     19       0    SD   SD   \n",
       "16    37.0     46.0   24.324324   37.0    9.0     24       1    PD   PD   \n",
       "17    15.0      5.0  -66.666667    5.0    0.0      0       0    CR   CR   \n",
       "18    15.0      5.0  -66.666667    5.0    0.0      0       0    CR   CR   \n",
       "19    15.0      5.0  -66.666667    5.0    0.0      0       0    CR   CR   \n",
       "20    15.0      5.0  -66.666667    5.0    0.0      0       0    CR   CR   \n",
       "21    15.0      5.0  -66.666667    5.0    0.0      0       0    CR   CR   \n",
       "22    15.0      5.0  -66.666667    5.0    0.0      0       0    CR   CR   \n",
       "23    15.0      5.0  -66.666667    5.0    0.0      0       1    CR   CR   \n",
       "24    15.0      5.0  -66.666667    5.0    0.0      0       0    CR   CR   \n",
       "25    40.0    165.0  312.500000   40.0  125.0    313       1    PD   PD   \n",
       "26    40.0    167.0  317.500000   40.0  127.0    318       1    PD   PD   \n",
       "27   195.0    161.0  -17.435897  195.0  -34.0    -17       0    SD   SD   \n",
       "28   195.0    178.0   -8.717949  161.0   17.0     11       0    SD   SD   \n",
       "29   195.0    192.0   -1.538462  161.0   31.0     19       0    SD   PD   \n",
       "..     ...      ...         ...    ...    ...    ...     ...   ...  ...   \n",
       "665   84.8    118.5   39.740566   84.8   33.7     40       1    PD   PD   \n",
       "666  200.7    382.7   90.682611  200.7  182.0     91       0    PD   PD   \n",
       "667   99.0    163.0   64.646465   99.0   64.0     65       1    PD   PD   \n",
       "668   79.0     79.0    0.000000   79.0    0.0      0       0    SD   SD   \n",
       "669   79.0     78.0   -1.265823   79.0   -1.0     -1       0    SD   SD   \n",
       "670   79.0     78.0   -1.265823   78.0    0.0      0       0    SD   SD   \n",
       "671  103.0     49.0  -52.427184  103.0  -54.0    -52       0    PR   PR   \n",
       "672  103.0     45.0  -56.310680   49.0   -4.0     -8       0    PR   PR   \n",
       "673  103.0     35.0  -66.019417   45.0  -10.0    -22       0    PR   PR   \n",
       "674   30.0     38.0   26.666667   30.0    8.0     27       1    PD   PD   \n",
       "675  131.0    151.0   15.267176  131.0   20.0     15       0    SD   SD   \n",
       "676  206.0     77.0  -62.621359  206.0 -129.0    -63       0    PR   PR   \n",
       "677  206.0     75.0  -63.592233   77.0   -2.0     -3       0    PR   PR   \n",
       "678   62.0     27.0  -56.451613   62.0  -35.0    -56       0    PR   PR   \n",
       "679   37.0     35.0   -5.405405   37.0   -2.0     -5       0    SD   SD   \n",
       "680   37.0     39.0    5.405405   35.0    4.0     11       1    SD   SD   \n",
       "681   34.0     50.0   47.058824   34.0   16.0     47       1    PD   PD   \n",
       "682   32.0      0.0 -100.000000   32.0  -32.0   -100       0    CR   CR   \n",
       "683   32.0      0.0 -100.000000    0.0    0.0      0       0    CR   CR   \n",
       "684   85.0     36.0  -57.647059   85.0  -49.0    -58       0    PR   PR   \n",
       "685   77.0     84.0    9.090909   77.0    7.0      9       0    SD   SD   \n",
       "686   77.0     65.0  -15.584416   77.0  -12.0    -16       0    SD   SD   \n",
       "687   77.0     47.0  -38.961039   65.0  -18.0    -28       0    PR   PR   \n",
       "688   77.0     46.0  -40.259740   47.0   -1.0     -2       0    PR   PR   \n",
       "689   90.0     51.0  -43.333333   90.0  -39.0    -43       0    PR   PR   \n",
       "690   67.0     69.0    2.985075   67.0    2.0      3       0    SD   SD   \n",
       "691   27.0     30.0   11.111111   27.0    3.0     11       0    SD   SD   \n",
       "692   27.0     30.0   11.111111   27.0    3.0     11       0    SD   SD   \n",
       "693  157.0    166.0    5.732484  157.0    9.0      6       1    SD   SD   \n",
       "694   15.0     17.0   13.333333   15.0    2.0     13       0    SD   SD   \n",
       "\n",
       "     Correct  \n",
       "0       True  \n",
       "1       True  \n",
       "2       True  \n",
       "3       True  \n",
       "4       True  \n",
       "5       True  \n",
       "6       True  \n",
       "7       True  \n",
       "8       True  \n",
       "9      False  \n",
       "10      True  \n",
       "11      True  \n",
       "12      True  \n",
       "13      True  \n",
       "14      True  \n",
       "15      True  \n",
       "16      True  \n",
       "17      True  \n",
       "18      True  \n",
       "19      True  \n",
       "20      True  \n",
       "21      True  \n",
       "22      True  \n",
       "23      True  \n",
       "24      True  \n",
       "25      True  \n",
       "26      True  \n",
       "27      True  \n",
       "28      True  \n",
       "29     False  \n",
       "..       ...  \n",
       "665     True  \n",
       "666     True  \n",
       "667     True  \n",
       "668     True  \n",
       "669     True  \n",
       "670     True  \n",
       "671     True  \n",
       "672     True  \n",
       "673     True  \n",
       "674     True  \n",
       "675     True  \n",
       "676     True  \n",
       "677     True  \n",
       "678     True  \n",
       "679     True  \n",
       "680     True  \n",
       "681     True  \n",
       "682     True  \n",
       "683     True  \n",
       "684     True  \n",
       "685     True  \n",
       "686     True  \n",
       "687     True  \n",
       "688     True  \n",
       "689     True  \n",
       "690     True  \n",
       "691     True  \n",
       "692     True  \n",
       "693     True  \n",
       "694     True  \n",
       "\n",
       "[695 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_x2_df['Label']=ts_y2_lbl['TRGRESP']\n",
    "ts_x2_df['Pred']=prediction(encoder, model, ts_x2)\n",
    "ts_x2_df['Correct']=return_predict(encoder, model, ts_x2, ts_y2_lbl['TRGRESP'])\n",
    "ts_x2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "07-dual-cnn-tumor_prediction-sites-central-google-cola.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
